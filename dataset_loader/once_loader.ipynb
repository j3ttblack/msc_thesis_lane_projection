{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aee29b9",
   "metadata": {},
   "source": [
    "## ONCE-3DLanes Data Loader\n",
    "Created by Jett Penner<br>\n",
    "December 2025 <br>\n",
    "\n",
    "\n",
    "Load the dataset and convert it into the readable form by the reusable thesis code. This also converts the 3D ground truth lane positions into 2D-3D ground truth pairs, and organizes all of the data into an easily-accessible format for the main thesis code. <br>\n",
    "\n",
    "<br><br>\n",
    "Note: The current code is setup to look in train/val/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f84eb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d34cbf",
   "metadata": {},
   "source": [
    "### Dataset Loading\n",
    "Search for matching sequence ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f2a89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Matching 20 sequence IDs and paths:\n",
      "sequence id: 000027\t\t# frames: 1147\n",
      "sequence id: 000028\t\t# frames: 485\n",
      "sequence id: 000034\t\t# frames: 810\n",
      "sequence id: 000076\t\t# frames: 1028\n",
      "sequence id: 000077\t\t# frames: 610\n",
      "sequence id: 000080\t\t# frames: 961\n",
      "sequence id: 000092\t\t# frames: 583\n",
      "sequence id: 000104\t\t# frames: 615\n",
      "sequence id: 000112\t\t# frames: 1225\n",
      "sequence id: 000113\t\t# frames: 946\n",
      "sequence id: 000121\t\t# frames: 857\n",
      "sequence id: 000168\t\t# frames: 771\n",
      "sequence id: 000200\t\t# frames: 1049\n",
      "sequence id: 000201\t\t# frames: 468\n",
      "sequence id: 000273\t\t# frames: 960\n",
      "sequence id: 000275\t\t# frames: 747\n",
      "sequence id: 000303\t\t# frames: 923\n",
      "sequence id: 000318\t\t# frames: 770\n",
      "sequence id: 000322\t\t# frames: 766\n",
      "sequence id: 000334\t\t# frames: 524\n",
      "Total frames: 16245\n"
     ]
    }
   ],
   "source": [
    "# Open config\n",
    "config_path = \"config.yaml\"\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Match candidate sequence IDs (between ONCE and ONCE-3DLanes)\n",
    "once_3dlanes_data_base = config[\"once_3dlanes_data\"]\n",
    "once_cam_data_base = config[\"once_data\"][\"cam_data\"]\n",
    "once_lidar_data_base = config[\"once_data\"][\"lidar_data\"]\n",
    "once_annot_base = config[\"once_data\"][\"annotation\"]\n",
    "\n",
    "def get_split_df(split_path, split, dict):\n",
    "    if os.path.exists(split_path):\n",
    "        seq_ids = [seq for seq in os.listdir(split_path)\n",
    "                   if os.path.isdir(os.path.join(split_path, seq))]\n",
    "        for seq in seq_ids:\n",
    "            dict[seq] = split\n",
    "    else:\n",
    "        print(f\"Split '{split}' does not exist at path {split_path}\")\n",
    "  \n",
    "splits = [\"train\", \"val\", \"test\"] # search in these splits\n",
    "lanes_seq_dict = {}\n",
    "cam_seq_dict = {}\n",
    "lidar_seq_dict = {}\n",
    "annot_seq_dict = {}\n",
    "for split in splits:\n",
    "    # ONCE-3DLanes dataset search\n",
    "    get_split_df(\n",
    "        os.path.join(once_3dlanes_data_base, split), \n",
    "        split, \n",
    "        lanes_seq_dict\n",
    "    )\n",
    "    # ONCE dataset search\n",
    "    embedded_split = os.path.join(split, \"data\") # hardcoded filepath\n",
    "    get_split_df(\n",
    "        os.path.join(once_cam_data_base, embedded_split), \n",
    "        embedded_split, \n",
    "        cam_seq_dict\n",
    "    )\n",
    "    get_split_df(\n",
    "        os.path.join(once_lidar_data_base, embedded_split), \n",
    "        embedded_split, \n",
    "        lidar_seq_dict\n",
    "    )\n",
    "    get_split_df(\n",
    "        os.path.join(once_annot_base, embedded_split), \n",
    "        embedded_split, \n",
    "        annot_seq_dict\n",
    "    )\n",
    "matching_sequence_ids = sorted(set(lanes_seq_dict) & set(cam_seq_dict) & set(lidar_seq_dict) & set(annot_seq_dict))\n",
    "\n",
    "# Generate matches, getting sequences and frames\n",
    "@dataclass\n",
    "class SequenceMatch:\n",
    "    sequence_id: str\n",
    "    match_count: int\n",
    "    match_ids: any\n",
    "    sequence_info_path: str\n",
    "    cam_folder_path: str\n",
    "    lane_folder_path: str\n",
    "    lidar_folder_path: str\n",
    "\n",
    "def count_matching_frames(match):\n",
    "    lane_ids = {os.path.splitext(f)[0] for f in os.listdir(match.lane_folder_path)\n",
    "                if f.endswith(\".json\")}\n",
    "    cam_ids = {os.path.splitext(f)[0] for f in os.listdir(match.cam_folder_path)\n",
    "               if f.endswith(\".jpg\")}\n",
    "    lidar_ids = {os.path.splitext(f)[0] for f in os.listdir(match.lidar_folder_path)\n",
    "                 if f.endswith(\".bin\")}\n",
    "    \n",
    "    matching_ids = cam_ids & lane_ids & lidar_ids\n",
    "    count = len(matching_ids)\n",
    "    \n",
    "    return count, matching_ids\n",
    "\n",
    "matched_sequences = []\n",
    "for seq_id in matching_sequence_ids:\n",
    "    lane_folder_path = os.path.join(once_3dlanes_data_base, lanes_seq_dict[seq_id], seq_id, \"cam01\")\n",
    "    cam_folder_path = os.path.join(once_cam_data_base, cam_seq_dict[seq_id], seq_id, \"cam01\")\n",
    "    lidar_folder_path = os.path.join(once_lidar_data_base, lidar_seq_dict[seq_id], seq_id, \"lidar_roof\")\n",
    "    sequence_info_path = os.path.join(once_annot_base, annot_seq_dict[seq_id], seq_id, f\"{seq_id}.json\")\n",
    "\n",
    "    missing_files = [f for f in [lane_folder_path, cam_folder_path, lidar_folder_path, sequence_info_path] if not os.path.exists(f)]\n",
    "    if missing_files:\n",
    "        print(\"The following files could not be loaded:\")\n",
    "        for f in missing_files:\n",
    "            print(f\"  -\", f)\n",
    "\n",
    "    match = SequenceMatch(\n",
    "        sequence_id=seq_id,\n",
    "        match_count=-1,\n",
    "        match_ids=None,\n",
    "        sequence_info_path=sequence_info_path,\n",
    "        cam_folder_path=cam_folder_path,\n",
    "        lane_folder_path=lane_folder_path,\n",
    "        lidar_folder_path=lidar_folder_path\n",
    "    )\n",
    "    match_count, match_ids = count_matching_frames(match)\n",
    "    match.match_count = match_count\n",
    "    match.match_ids = sorted(match_ids, key=int)\n",
    "    matched_sequences.append(match)\n",
    "\n",
    "print(f\"Matching {len(matched_sequences)} sequence IDs and paths:\")\n",
    "for match in matched_sequences:\n",
    "    print(f\"sequence id: {match.sequence_id}\\t\\t# frames: {match.match_count}\")\n",
    "\n",
    "print(f\"Total frames: {sum(m.match_count for m in matched_sequences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f9b6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preload variables \n",
    "base_folder = config[\"output\"][\"base_folder\"]\n",
    "os.makedirs(base_folder, exist_ok=True)\n",
    "output_images_folder = config[\"output\"][\"images\"]\n",
    "output_lidar_folder = config[\"output\"][\"lidar\"]\n",
    "output_detections_2d_folder = config[\"output\"][\"detections_2d\"]\n",
    "output_detections_3d_folder = config[\"output\"][\"detections_3d\"]\n",
    "\n",
    "ransac_a_priori_sensor_height = config[\"ground_plane_ransac\"][\"camera_height\"]\n",
    "ransac_prefilter_band_half_width =  config[\"ground_plane_ransac\"][\"prefilter_band_half_width\"]\n",
    "snap_curvature_threshold = config[\"projection_mapping\"][\"snap_curvature_threshold\"]\n",
    "\n",
    "override_existing_output = config[\"output\"][\"override_existing_output\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88064b10",
   "metadata": {},
   "source": [
    "### Math Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730cb76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefilter_ground_plane(points, sensor_height=1.5, height_range=None, vertical_axis=0):\n",
    "    \"\"\"\n",
    "    Prefilter a point cloud to keep only points near the expected ground plane height.\n",
    "\n",
    "    Args:\n",
    "        points (N,3) np array: Input 3D point cloud.\n",
    "        sensor_height (float): Expected height of the sensor above the ground plane (approximate).\n",
    "        height_range (float, optional): Acceptable deviation (±) from the expected ground level. Default to half sensor height.\n",
    "        vertical_axis (int): Axis index representing \"up\" direction (0=x, 1=y, 2=z).\n",
    "\n",
    "    Returns:\n",
    "       (M,3) np array, the filtered point cloud containing only points near ground level.\n",
    "    \"\"\"\n",
    "    if points is None or len(points) == 0:\n",
    "        return np.empty((0, 3), dtype=np.float32)\n",
    "    \n",
    "    if height_range is None:\n",
    "        height_range = sensor_height/2\n",
    "\n",
    "    # Compute ground height range relative to sensor\n",
    "    min_height = -sensor_height - height_range\n",
    "    max_height = -sensor_height + height_range\n",
    "\n",
    "    # Select points whose coordinate along the vertical axis is within range\n",
    "    mask = (points[:, vertical_axis] >= min_height) & (points[:, vertical_axis] <= max_height)\n",
    "    filtered_points = points[mask]\n",
    "\n",
    "    return filtered_points.astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "def estimate_ground_plane(\n",
    "    points,\n",
    "    config,\n",
    "    vertical_axis=0,\n",
    "    random_state=None\n",
    "):\n",
    "    '''\n",
    "    Estimate the ground plane from 3D points using a band filter + RANSAC + least-squares refit.\n",
    "\n",
    "    Args:\n",
    "        points (N,3) np array: Input 3D point cloud.\n",
    "        config (dict): Configuration file.\n",
    "        vertical_axis (int, optional): Axis index representing \"up\" direction. Default is 0 (x-axis).\n",
    "        random_state (int, optional): Seed for random generator. Default is seedless.\n",
    "\n",
    "    Returns:\n",
    "        (3,) np array, plane normal unit vector.\n",
    "        (float), plane offset d in n·x + d = 0.\n",
    "        (N,3) np array, mask of inlier points.\n",
    "    '''\n",
    "\n",
    "    sensor_height = config[\"ground_plane_ransac\"][\"camera_height\"]\n",
    "    band_half_width = config[\"ground_plane_ransac\"][\"band_half_width\"]\n",
    "    ransac_iters = config[\"ground_plane_ransac\"][\"ransac_iters\"]\n",
    "    inlier_threshold = config[\"ground_plane_ransac\"][\"inlier_threshold\"]\n",
    "    min_inliers_for_accept = config[\"ground_plane_ransac\"][\"min_inliers_for_accept\"]\n",
    "    inlier_fallback_range_mult = config[\"ground_plane_ransac\"][\"inlier_fallback_range_mult\"]\n",
    "    plane_norm_degenerate_threshold = float(config[\"ground_plane_ransac\"][\"plane_norm_degenerate_threshold\"])\n",
    "\n",
    "    if random_state is None:\n",
    "        rng = np.random.default_rng()\n",
    "    else:\n",
    "        rng = np.random.default_rng(random_state)\n",
    "\n",
    "    pts = np.asarray(points)\n",
    "\n",
    "    ground_coord = -sensor_height\n",
    "    use_fallback_plane=False\n",
    "\n",
    "    if pts.size == 0:\n",
    "        use_fallback_plane=True\n",
    "        print(\"[Error]: No points in lidar ransac around ground coordinate after prefunction filter\")\n",
    "    else:\n",
    "\n",
    "        # Pre-filter: keep points within a vertical band around expected ground\n",
    "        vert_vals = pts[:, vertical_axis]\n",
    "        band_mask = np.logical_and(vert_vals >= (ground_coord - band_half_width),\n",
    "                                vert_vals <= (ground_coord + band_half_width))\n",
    "\n",
    "        candidate_idx = np.nonzero(band_mask)[0]\n",
    "        if candidate_idx.size < min_inliers_for_accept:\n",
    "            # too few candidates - relax band slightly (quick fallback)\n",
    "            band_mask = np.logical_and(vert_vals >= (ground_coord - inlier_fallback_range_mult * band_half_width),\n",
    "                                    vert_vals <= (ground_coord + inlier_fallback_range_mult * band_half_width))\n",
    "            candidate_idx = np.nonzero(band_mask)[0]\n",
    "\n",
    "        \n",
    "        if candidate_idx.size < 3:\n",
    "            # not enough points to fit a plane\n",
    "            use_fallback_plane=True\n",
    "            print(f\"[Error]: Not enough candidate points for lidar ransac around ground coordinate after infunction filter: need 3, got {candidate_idx.size}\")\n",
    "\n",
    "    if not use_fallback_plane:\n",
    "        cand_pts = pts[candidate_idx]\n",
    "\n",
    "        best_inliers = None\n",
    "        best_count = 0\n",
    "\n",
    "        # RANSAC loop: sample 3 points, form plane, count inliers\n",
    "        M = cand_pts.shape[0]\n",
    "        for _ in range(ransac_iters):\n",
    "            # pick 3 distinct random indices from candidates\n",
    "            ids = rng.choice(M, size=3, replace=False)\n",
    "            p0, p1, p2 = cand_pts[ids]\n",
    "\n",
    "            # compute plane normal via cross product\n",
    "            v1 = p1 - p0\n",
    "            v2 = p2 - p0\n",
    "            n = np.cross(v1, v2)\n",
    "            norm_n = np.linalg.norm(n)\n",
    "            if norm_n < plane_norm_degenerate_threshold:\n",
    "                continue  # degenerate sample, skip\n",
    "\n",
    "            n = n / norm_n\n",
    "            d = -np.dot(n, p0)\n",
    "\n",
    "            # point-to-plane distances for candidate points\n",
    "            distances = np.abs(cand_pts.dot(n) + d)\n",
    "\n",
    "            # count inliers\n",
    "            mask_in = distances <= inlier_threshold\n",
    "            count = int(mask_in.sum())\n",
    "\n",
    "            if count > best_count:\n",
    "                best_count = count\n",
    "                best_inliers = candidate_idx[mask_in]\n",
    "\n",
    "    if use_fallback_plane or best_count < min_inliers_for_accept: # failure case or not enough inliers\n",
    "\n",
    "        # print appropriate error\n",
    "        if best_count < min_inliers_for_accept:\n",
    "            print(f\"[Warning]: Not enough points on best ground plane to surpass the min_inliers threshold: needed {min_inliers_for_accept}, got {best_count}\")\n",
    "        print(\"[Warning]: Using fallback constant-height plane\")\n",
    "        \n",
    "        # not confident, return fallback: use median around band as ground level with vertical normal\n",
    "        # create default flat plane normal pointing up\n",
    "        fallback_n = np.zeros(3)\n",
    "        fallback_n[vertical_axis] = 1.0\n",
    "        fallback_d = -ground_coord\n",
    "        if pts.size == 0:\n",
    "            inlier_mask = np.zeros(0, dtype=bool)\n",
    "        else:\n",
    "            inlier_mask = band_mask  # treat band as inliers\n",
    "        return fallback_n, fallback_d, inlier_mask\n",
    "\n",
    "\n",
    "    # non-degenerate: refit plane with all best inliers using LLS SVD\n",
    "    inlier_pts = pts[best_inliers]\n",
    "    centroid = inlier_pts.mean(axis=0)\n",
    "    cov = inlier_pts - centroid\n",
    "    _, _, vh = np.linalg.svd(cov, full_matrices=False)\n",
    "    normal = vh.T[:, -1]\n",
    "    # enforce normal to point up (positive along vertical axis), structure prior\n",
    "    if normal[vertical_axis] < 0:\n",
    "        normal = -normal\n",
    "    d = -np.dot(normal, centroid)\n",
    "\n",
    "    # compute final inlier mask (on the whole cloud) using threshold\n",
    "    distances_all = np.abs(pts.dot(normal) + d)\n",
    "    inlier_mask = distances_all <= inlier_threshold\n",
    "\n",
    "    if d > 0:\n",
    "        normal = -normal\n",
    "        d = -d\n",
    "\n",
    "    return normal, d, inlier_mask\n",
    "\n",
    "\n",
    "\n",
    "def snap_points_to_plane_and_fit_line(points, plane_normal, plane_offset, curvature_threshold=0.05):\n",
    "    \"\"\"\n",
    "    Projects 3D points onto a plane, fits a line (or a quadratic curve if curvature is high),\n",
    "    and returns the closest points on the fitted model to each input point.\n",
    "\n",
    "    Args:\n",
    "        points (N,3) np array: input 3D points.\n",
    "        plane_normal (3,) np array: plane normal.\n",
    "        plane_offset (float): d in plane equation n·x + d = 0.\n",
    "        curvature_threshold (float): RMS distance above which to switch to quadratic model (in m).\n",
    "\n",
    "    Returns:\n",
    "        (N,3) np array, points on best-fit line or curve.\n",
    "        (str), model type, either \"linear\" or \"quadratic\".\n",
    "        (dict), model coefficients and direction vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    # project points on plane\n",
    "    pts = np.asarray(points)\n",
    "    n = plane_normal / np.linalg.norm(plane_normal)\n",
    "    distances = (pts @ n + plane_offset)\n",
    "    projected_pts = pts - np.outer(distances, n)\n",
    "\n",
    "    # make local 2D coordinate system on the plane \n",
    "    arbitrary = np.array([1, 0, 0]) if abs(n[0]) < 0.9 else np.array([0, 1, 0])\n",
    "    plane_x = np.cross(n, arbitrary)\n",
    "    plane_x /= np.linalg.norm(plane_x)\n",
    "    plane_y = np.cross(n, plane_x)\n",
    "\n",
    "    origin = projected_pts.mean(axis=0)\n",
    "    local_2d = np.stack([\n",
    "        (projected_pts - origin) @ plane_x,\n",
    "        (projected_pts - origin) @ plane_y\n",
    "    ], axis=1)\n",
    "    x, y = local_2d[:, 0], local_2d[:, 1]\n",
    "\n",
    "    # try linear model y = a*x + b\n",
    "    A = np.vstack([x, np.ones_like(x)]).T\n",
    "    a, b = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "    dir_2d = np.array([1, a])\n",
    "    dir_2d /= np.linalg.norm(dir_2d)\n",
    "\n",
    "    # project points to linear model\n",
    "    snapped_linear = []\n",
    "    for p in local_2d:\n",
    "        p_vec = p - np.array([0, b])\n",
    "        t = np.dot(p_vec, dir_2d)\n",
    "        proj_2d = np.array([t, a * t + b])\n",
    "        proj_3d = origin + proj_2d[0]*plane_x + proj_2d[1]*plane_y\n",
    "        snapped_linear.append(proj_3d)\n",
    "    snapped_linear = np.vstack(snapped_linear)\n",
    "\n",
    "    #  RMS residual error for linear model\n",
    "    linear_rms_error = np.sqrt(np.mean(np.sum((projected_pts - snapped_linear)**2, axis=1)))\n",
    "\n",
    "    # large linear error, use quadratic model y=a*(x^2) + b*x + c\n",
    "    if linear_rms_error > curvature_threshold:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore', np.RankWarning)\n",
    "            coeffs = np.polyfit(x, y, 2)\n",
    "        a2, b2, c2 = coeffs\n",
    "\n",
    "        ts = np.linspace(x.min(), x.max(), 400)\n",
    "        curve_pts = np.stack([ts, a2*ts**2 + b2*ts + c2], axis=1)\n",
    "        snapped_quadratic = []\n",
    "        for p in local_2d:\n",
    "            idx = np.argmin(np.sum((curve_pts - p)**2, axis=1))\n",
    "            proj_2d = curve_pts[idx]\n",
    "            proj_3d = origin + proj_2d[0]*plane_x + proj_2d[1]*plane_y\n",
    "            snapped_quadratic.append(proj_3d)\n",
    "        snapped_quadratic = np.vstack(snapped_quadratic)\n",
    "        quadratic_rms_error = np.sqrt(np.mean(np.sum((projected_pts - snapped_quadratic)**2, axis=1)))\n",
    "\n",
    "        model_type = \"quadratic\"\n",
    "        model_params = {\n",
    "            \"coeffs\": (a2, b2, c2),\n",
    "            \"plane_x\": plane_x,\n",
    "            \"plane_y\": plane_y,\n",
    "            \"plane_origin\": origin,\n",
    "            \"linear_rms_error\": linear_rms_error,\n",
    "            \"quadratic_rms_error\": quadratic_rms_error\n",
    "        }\n",
    "        return snapped_quadratic, model_type, model_params\n",
    "\n",
    "    else:\n",
    "        model_type = \"linear\"\n",
    "        line_dir = dir_2d[0]*plane_x + dir_2d[1]*plane_y\n",
    "        line_dir /= np.linalg.norm(line_dir)\n",
    "        model_params = {\n",
    "            \"a\": a,\n",
    "            \"b\": b,\n",
    "            \"line_origin\": origin + b*plane_y,\n",
    "            \"line_dir\": line_dir,\n",
    "            \"linear_rms_error\": linear_rms_error,\n",
    "        }\n",
    "        return snapped_linear, model_type, model_params\n",
    "\n",
    "\n",
    "\n",
    "def project_detections_onto_image(projection, lane):\n",
    "    \"\"\"\n",
    "    Project a 3D lane to 2D image pixels using a 3x4 projection matrix.\n",
    "    \n",
    "    Args:\n",
    "        projection (3,4) np array: projection matrix (P = K [I|0])\n",
    "        lane (N,3) np array: 3D points in camera coordinates (in m).\n",
    "    \n",
    "    Returns:\n",
    "        (N,2) np array, pixel coordinates (u,v).\n",
    "        (N,) np array, depth values (Z in camera frame)\n",
    "    \"\"\"\n",
    "\n",
    "    lane_h = np.hstack([lane, np.ones((lane.shape[0], 1))])\n",
    "\n",
    "    proj = (projection @ lane_h.T).T\n",
    "    u = proj[:, 0] / proj[:, 2]\n",
    "    v = proj[:, 1] / proj[:, 2]\n",
    "    pixels = np.stack([u, v], axis=1)\n",
    "    \n",
    "    depths = lane[:, 2]\n",
    "    \n",
    "    return pixels, depths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967ca55a",
   "metadata": {},
   "source": [
    "### Main Processing Pipeline\n",
    "\n",
    "Loop through all matched sequence ids and generate necessary data.\n",
    "\n",
    "Preserves current state through override flag (can stop and return if no overriding). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70bb63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing match_ids: 100%|██████████| 16245/16245 [1:23:50<00:00,  3.23it/s]\n"
     ]
    }
   ],
   "source": [
    "total_ids = sum(len(match.match_ids) for match in matched_sequences)\n",
    "with tqdm(total=total_ids, desc=\"Processing match_ids\") as inner_bar:\n",
    "    for match in matched_sequences:\n",
    "\n",
    "        # generate output folders\n",
    "        seq_output_images_folder = os.path.join(base_folder, match.sequence_id, output_images_folder)\n",
    "        seq_output_lidar_folder = os.path.join(base_folder, match.sequence_id, output_lidar_folder)\n",
    "        seq_output_detections_2d_folder = os.path.join(base_folder, match.sequence_id, output_detections_2d_folder)\n",
    "        seq_output_detections_3d_folder = os.path.join(base_folder, match.sequence_id, output_detections_3d_folder)\n",
    "        for folder in [seq_output_images_folder, seq_output_lidar_folder, seq_output_detections_2d_folder, seq_output_detections_3d_folder]:\n",
    "            os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "        # extract sequence calibration parameters\n",
    "        with open(match.sequence_info_path, \"r\") as f:\n",
    "            seq_info = json.load(f)\n",
    "        image_size = seq_info[\"meta_info\"][\"image_size\"]\n",
    "        img_width, img_height = image_size[0], image_size[1]\n",
    "        cam01_calib = seq_info[\"calib\"][\"cam01\"]\n",
    "        T_camera_lidar = np.array(cam01_calib[\"cam_to_velo\"], dtype=np.float64)\n",
    "        cam_intrinsic = np.array(cam01_calib[\"cam_intrinsic\"], dtype=np.float64)\n",
    "        fx = cam_intrinsic[0, 0]\n",
    "        fy = cam_intrinsic[1, 1]\n",
    "        cx = cam_intrinsic[0, 2]\n",
    "        cy = cam_intrinsic[1, 2]\n",
    "        distortion = np.array(cam01_calib[\"distortion\"], dtype=np.float64)\n",
    "        weather = seq_info[\"meta_info\"][\"weather\"]\n",
    "        tod = seq_info[\"meta_info\"][\"period\"]\n",
    "\n",
    "\n",
    "        # create calib file \n",
    "        T_applanix_lidar = np.eye(4, dtype=float)\n",
    "        calibration_data = {\n",
    "            \"T_camera_lidar\": T_camera_lidar.tolist(),\n",
    "            \"T_applanix_lidar\": T_applanix_lidar.tolist(),\n",
    "            \"camera_intrinsics\": {\n",
    "                \"fx\": fx,\n",
    "                \"fy\": fy,\n",
    "                \"cx\": cx,\n",
    "                \"cy\": cy,\n",
    "                \"distortion\": distortion.tolist() if isinstance(distortion, np.ndarray) else distortion\n",
    "            },\n",
    "            \"image_params\": {\n",
    "                \"width\": img_width,\n",
    "                \"height\": img_height\n",
    "            },\n",
    "            \"weather\": weather,\n",
    "            \"period\": tod\n",
    "        }\n",
    "        with open(os.path.join(base_folder, match.sequence_id, \"calibration.json\"), 'w') as f:\n",
    "            json.dump(calibration_data, f, indent=4)\n",
    "\n",
    "\n",
    "        for id in match.match_ids:\n",
    "            # load data\n",
    "            lidar_out_path = os.path.join(seq_output_lidar_folder, f\"{id}.bin\")\n",
    "            img_out_path = os.path.join(seq_output_images_folder, f\"{id}.png\")\n",
    "            detections_2d_path = os.path.join(seq_output_detections_2d_folder, f\"{id}.txt\")\n",
    "            detections_3d_files = glob.glob(os.path.join(seq_output_detections_3d_folder, f\"{id}_*.pcd\"))\n",
    "            if not override_existing_output:\n",
    "                # skip existing output files\n",
    "                existing_files = [lidar_out_path, img_out_path, detections_2d_path] + detections_3d_files\n",
    "                if all(os.path.exists(f) for f in existing_files):\n",
    "                    inner_bar.update(1)\n",
    "                    continue\n",
    "\n",
    "            # copy lidar to the output file, make 6 column for input formatting\n",
    "            lidar_path = os.path.join(match.lidar_folder_path, f\"{id}.bin\")\n",
    "            if not os.path.exists(lidar_path):\n",
    "                print(f\"Error: lidar path is not found: {lidar_path}\")\n",
    "            points = np.fromfile(lidar_path, dtype=np.float32).reshape(-1, 4)\n",
    "            N = points.shape[0]\n",
    "            ring_col = np.zeros((N, 1), dtype=np.float32)\n",
    "            time_col = np.zeros((N, 1), dtype=np.float32)\n",
    "            points_6d = np.hstack([points, ring_col, time_col])\n",
    "            points_6d.tofile(lidar_out_path)\n",
    "\n",
    "\n",
    "            # recreate images in output as png\n",
    "            img_path = os.path.join(match.cam_folder_path, f\"{id}.jpg\")\n",
    "            if not os.path.exists(img_path):\n",
    "                print(f\"Error: image path is not found {img_path}\")\n",
    "            img = Image.open(img_path)\n",
    "            img.save(img_out_path, \"PNG\")\n",
    "\n",
    "\n",
    "            # 2D inputs + 3D ground truths\n",
    "                # data loading\n",
    "            detections_path = os.path.join(match.lane_folder_path, f\"{id}.json\")\n",
    "            if not os.path.exists(detections_path):\n",
    "                print(f\"Error: detections path is not found {detections_path}\")\n",
    "            \n",
    "            with open(detections_path, 'r') as f:\n",
    "                det = json.load(f)\n",
    "            projection = np.array(det[\"calibration\"], dtype=np.float64)\n",
    "\n",
    "                # RANSAC (for correction)\n",
    "            points_lidar_hom = np.hstack((points[:,:3], np.ones((points[:,:3].shape[0], 1))))\n",
    "            points_lidar_camera = (T_camera_lidar @ points_lidar_hom.T).T[:,:3]\n",
    "            perfiltered_points = prefilter_ground_plane(\n",
    "                points_lidar_camera,\n",
    "                -ransac_a_priori_sensor_height,\n",
    "                ransac_prefilter_band_half_width,\n",
    "                vertical_axis=1\n",
    "            )\n",
    "            plane_normal, plane_offset, ground_plane_mask = estimate_ground_plane(\n",
    "                perfiltered_points,\n",
    "                config,\n",
    "                vertical_axis=0,\n",
    "            )\n",
    "\n",
    "            with open(detections_2d_path, 'w') as f:\n",
    "                filepath_idx = 0\n",
    "                for lane_points in det[\"lanes\"]:\n",
    "\n",
    "                    # fit to plane and line of best fit\n",
    "                    lane = np.array(lane_points, dtype=np.float64)\n",
    "                    lane_snapped, model_type, model_params = snap_points_to_plane_and_fit_line(\n",
    "                        lane,\n",
    "                        plane_normal,\n",
    "                        plane_offset,\n",
    "                        curvature_threshold=snap_curvature_threshold\n",
    "                    )\n",
    "\n",
    "                    # filter incorrect pixels (and corresponding 3d points)\n",
    "                    pixels, _ = project_detections_onto_image(projection, lane_snapped)\n",
    "                    mask = (pixels[:, 0] >= 0) & (pixels[:, 0] <= img_width) & (pixels[:, 1] >= 0) & (pixels[:, 1] <= img_height)\n",
    "                    filtered_pixels = pixels[mask]\n",
    "                    filtered_points = lane_snapped[mask]\n",
    "\n",
    "                    # need at least 2 pixels\n",
    "                    if filtered_pixels.shape[0] < 2:\n",
    "                        # empty 2D file, no 3D file\n",
    "                        continue\n",
    "\n",
    "                    # write 3D\n",
    "                    pcd_filename = os.path.join(seq_output_detections_3d_folder, f\"{id}_{filepath_idx}.pcd\")\n",
    "                    pcd = o3d.geometry.PointCloud()\n",
    "                    pcd.points = o3d.utility.Vector3dVector(filtered_points)\n",
    "                    o3d.io.write_point_cloud(pcd_filename, pcd, write_ascii=True)\n",
    "\n",
    "                    # write 2D\n",
    "                    lane_str = ' '.join([f\"{x:.2f},{y:.2f}\" for x, y in filtered_pixels])\n",
    "                    f.write(f\"{lane_str} confidence: 0.9999\\n\")\n",
    "\n",
    "                    filepath_idx += 1\n",
    "\n",
    "\n",
    "            inner_bar.update(1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b68049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
