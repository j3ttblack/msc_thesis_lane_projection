{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a5b64a5",
   "metadata": {},
   "source": [
    "## 2D-to-3D Lanes Outline Postfilter\n",
    "Created by Jett Penner<br>\n",
    "December 2025 <br>\n",
    "\n",
    "\n",
    "Runs a postprocessing filter operation on the dataset, determining potential solution outliers (stemming from incorrect data loads or preprocessing). While this could be detected before the main running pipeline, the current configuration allows analysis of input failure cases. Output is a json of outliers (does not natively remove outliers).\n",
    "\n",
    "First run the `ONCE-3DLanes Data Loader` for data loading and preprocessing. Then, run the `2D-to-3D Lanes Pipeline` for pipeline output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d2a461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import open3d as o3d\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93a5b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration data and log\n",
    "with open(\"once\" + \"_config.yaml\", \"r\") as f:\n",
    "    once_config = yaml.safe_load(f)\n",
    "\n",
    "from logger import setup_logger, switch_log_file\n",
    "main_logger = setup_logger(\"analytics_builder_log\")\n",
    "switch_log_file(main_logger, once_config[\"output\"][\"base_path\"])\n",
    "main_logger.info(\"Starting Program\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c289df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pointcloud_from_bin(file_path):\n",
    "    '''\n",
    "    Load a point cloud from a .bin file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the .bin file.\n",
    "\n",
    "    Returns:\n",
    "        (N,3) np array: Points in the file (XYZ), or None if invalid file.\n",
    "    '''\n",
    "    if not os.path.exists(file_path):\n",
    "        main_logger.error(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        points = np.fromfile(file_path, dtype=np.float32)\n",
    "        if points.size % 3 != 0:\n",
    "            main_logger.error(f\"Invalid point cloud size in file {file_path} ({points.size} floats).\")\n",
    "            return None\n",
    "        return points.reshape(-1, 3)\n",
    "    except Exception as e:\n",
    "        main_logger.error(f\"Failed to load point cloud from {file_path}: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "\n",
    "def load_pointcloud_from_pcd(pcd_path):\n",
    "    '''\n",
    "    Load a point cloud from a .pcd file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the .pcd file.\n",
    "\n",
    "    Returns:\n",
    "        (N,3) np array: Points in the file (XYZ), or None if invalid file.\n",
    "    '''\n",
    "    pcd = o3d.io.read_point_cloud(str(pcd_path))\n",
    "    \n",
    "    if not pcd.has_points():\n",
    "        main_logger.warning(f\"No points found in PCD file: {pcd_path}\")\n",
    "        return np.empty((0, 3), dtype=np.float32)\n",
    "    \n",
    "    return np.asarray(pcd.points, dtype=np.float32)\n",
    "\n",
    "\n",
    "\n",
    "def is_point_error(P_sol, P_gt):\n",
    "    '''\n",
    "    Determines if the point is an outlier.\n",
    "\n",
    "    Args:\n",
    "        P_sol (3,) np array: Solution point.\n",
    "        P_gt (3,) np array: Ground truth point.\n",
    "\n",
    "    Returns:\n",
    "        (bool): whether the point is an outlier.\n",
    "    '''\n",
    "    diff = P_sol - P_gt\n",
    "    sq_dist = np.dot(diff, diff)      # squared Euclidean distance\n",
    "    return sq_dist > once_config[\"result_analytics\"][\"max_eucl_dist\"] ** 2\n",
    "\n",
    "\n",
    "\n",
    "def get_seqs():\n",
    "    '''\n",
    "    Get all of the run / sequence ids.\n",
    "\n",
    "    Returns:\n",
    "        (arr): An array of all of the ids.\n",
    "    '''\n",
    "    base_path = once_config[\"output\"][\"base_path\"]\n",
    "    seq_id = once_config[\"runtime\"][\"seq_id\"]\n",
    "    seq_ids = []\n",
    "    if seq_id is None:\n",
    "        # Get all sequences\n",
    "        for name in os.listdir(base_path):\n",
    "            full_path = os.path.join(base_path, name)\n",
    "            if os.path.isdir(full_path):\n",
    "                seq_ids.append(name)\n",
    "        \n",
    "        main_logger.info(f\"Running all run ids: {len(seq_ids)} found.\\n\\n\\n\\n\")\n",
    "    else:\n",
    "        full_path = os.path.join(base_path, seq_id)\n",
    "        if os.path.exists(full_path) and os.path.isdir(full_path):\n",
    "            seq_ids.append(seq_id)\n",
    "            main_logger.info(f\"Running prespecified run id: {seq_id}\")\n",
    "        else:\n",
    "            main_logger.error(f\"Prespecified run id {seq_id} is not found, or not a run folder.\")\n",
    "            sys.exit(1)\n",
    "    return seq_ids\n",
    "\n",
    "\n",
    "\n",
    "def map_files_by_frame(files):\n",
    "    '''\n",
    "    Groups files by GPS time (aka frame).\n",
    "\n",
    "    Args:\n",
    "        files (arr[Path]): a list of candidate files.\n",
    "\n",
    "    Returns:\n",
    "        mapping (dict): a mapping dictionary of   frameid: {laneid: filepath}\n",
    "    \n",
    "    '''\n",
    "    mapping = defaultdict(dict)\n",
    "    for fp in files:\n",
    "        stem = fp.stem  # expected <frameid>_<laneid>\n",
    "        if \"_\" not in stem:\n",
    "            mapping[stem][None] = str(fp)\n",
    "            continue\n",
    "        frameid, laneid_str = stem.rsplit('_', 1)\n",
    "        try:\n",
    "            laneid = int(laneid_str)\n",
    "        except ValueError:\n",
    "            laneid = laneid_str\n",
    "        mapping[frameid][laneid] = str(fp)\n",
    "    return mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5028d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = once_config[\"output\"][\"base_path\"]\n",
    "\n",
    "ground_truth_base_folder = once_config[\"data\"][\"base_path\"]\n",
    "ground_truth_folder = once_config[\"data\"][\"lane_position_ground_truth_folder_path\"]\n",
    "\n",
    "out_path = Path(os.path.join(base_path, once_config[\"result_analytics\"][\"posfilter_eval_path\"] + \".json\"))\n",
    "if out_path.exists() and not once_config[\"result_analytics\"][\"override_existing_output\"]:\n",
    "    with open(out_path, 'r') as f:\n",
    "        print(\"File already exists.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "error_registry = {\"lanes\": set(), \"points\": set()}\n",
    "\n",
    "seq_ids = get_seqs()\n",
    "\n",
    "for seq_id in tqdm(seq_ids, desc=\"Processing all run ids\"):\n",
    "    gt_folder = Path(os.path.join(ground_truth_base_folder, seq_id, ground_truth_folder))\n",
    "    solution_folder = Path(os.path.join(base_path, seq_id, once_config[\"output\"][\"thesis_solution_path\"]))\n",
    "    \n",
    "    sol_files = sorted(solution_folder.glob(\"*.bin\"))\n",
    "    gt_files = sorted(gt_folder.glob(\"*.pcd\"))\n",
    "\n",
    "    sol_map = map_files_by_frame(sol_files)\n",
    "    gt_map = map_files_by_frame(gt_files)\n",
    "    frame_ids = sorted(set(sol_map.keys()) & set(gt_map.keys()))\n",
    "\n",
    "    for frame_id in frame_ids:\n",
    "        solution_files_for_frame = sol_map.get(frame_id, {})\n",
    "        gt_files_for_frame = gt_map.get(frame_id, {})\n",
    "\n",
    "        lane_ids = sorted(set(solution_files_for_frame.keys()) & set(gt_files_for_frame.keys()))\n",
    "        for lane_id in lane_ids:\n",
    "            solution_filepath = solution_files_for_frame[lane_id]\n",
    "            gt_filepath = gt_files_for_frame[lane_id]\n",
    "\n",
    "            lane_ids = sorted(set(solution_files_for_frame.keys()) & set(gt_files_for_frame.keys()))\n",
    "\n",
    "            sol_pts = load_pointcloud_from_bin(solution_filepath)\n",
    "            gt_pts  = load_pointcloud_from_pcd(gt_filepath)       \n",
    "\n",
    "            if sol_pts is None or gt_pts is None:\n",
    "                error_registry[\"lanes\"].add((seq_id, frame_id, lane_id))\n",
    "                continue\n",
    "\n",
    "            sol_pts = np.asarray(sol_pts, dtype=float)\n",
    "            gt_pts  = np.asarray(gt_pts, dtype=float)\n",
    "\n",
    "            if sol_pts.shape != gt_pts.shape or sol_pts.ndim != 2 or sol_pts.shape[1] != 3:\n",
    "                error_registry[\"lanes\"].add((seq_id, frame_id, lane_id))\n",
    "                continue\n",
    "\n",
    "            N = sol_pts.shape[0]\n",
    "            invalid_point_indices = [i for i in range(N) if is_point_error(sol_pts[i], gt_pts[i])]\n",
    "            if len(invalid_point_indices) == N:\n",
    "                # All points are invalid, mark the lane\n",
    "                error_registry[\"lanes\"].add((seq_id, frame_id, lane_id))\n",
    "            else:\n",
    "                # Only some points are invalid, mark individual points\n",
    "                for i in invalid_point_indices:\n",
    "                    error_registry[\"points\"].add((seq_id, frame_id, lane_id, i))\n",
    "\n",
    "\n",
    "# Save JSON of invalid\n",
    "serializable_registry = {\n",
    "    \"lanes\": list(error_registry[\"lanes\"]),\n",
    "    \"points\": list(error_registry[\"points\"])\n",
    "}\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(out_path, 'w') as f:\n",
    "    json.dump(serializable_registry, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6868a4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
