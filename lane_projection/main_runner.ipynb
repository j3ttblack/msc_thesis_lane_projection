{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cb3985c",
   "metadata": {},
   "source": [
    "## 2D-to-3D Lanes Pipeline\n",
    "Created by Jett Penner<br>\n",
    "December 2025 <br>\n",
    "\n",
    "\n",
    "Run the custom 2d-to-3d rotation code and/or alternate rotations. Code currently set up for the ONCE-3DLanes dataset (with filetypes, etc); easy to modify to other datasets by changing data loaders.\n",
    "\n",
    "Run after the `ONCE-3DLanes Data Loader`, and ensure that the config files match. Alter this config file to choose which type of thesis code to run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83684f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import open3d as o3d\n",
    "import cv2\n",
    "import json\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from scipy.interpolate import PchipInterpolator\n",
    "from scipy.optimize import minimize_scalar\n",
    "from logger import setup_logger, start_timer, stop_timer, switch_log_file\n",
    "\n",
    "# Force single threading for accurate runtime analysis\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bb7b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logger, global variable in other functions\n",
    "with open(\"once\" + \"_config.yaml\", \"r\") as f:\n",
    "    once_config = yaml.safe_load(f)\n",
    "\n",
    "logger = setup_logger(\"per_run_logger\")\n",
    "main_logger = setup_logger(\"summary_log\")\n",
    "switch_log_file(main_logger, once_config[\"output\"][\"base_path\"])\n",
    "main_logger.info(\"Starting Program\\n\")\n",
    "log_specifics = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3303445b",
   "metadata": {},
   "source": [
    "### File Setup Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77561b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_calibration(calibration_path, log=True):\n",
    "    '''\n",
    "    Load calibration parameters from a JSON file.\n",
    "\n",
    "    Args:\n",
    "        calibration_path (str): Path to calibration JSON file.\n",
    "        log (bool): True if log information (set to false if not established, ie from other file).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (\n",
    "            T_camera_lidar (4,4) np array, \n",
    "            T_applanix_lidar (4,4) np array,\n",
    "            fx, fy, cx, cy (float),\n",
    "            img_width, img_height (int),\n",
    "            distortion (5,) np array\n",
    "        )\n",
    "    '''\n",
    "    try:\n",
    "        with open(calibration_path, 'r') as f:\n",
    "            calibration_data = json.load(f)\n",
    "        if log and log_specifics:\n",
    "            logger.info(f\"Loaded calibration file: {calibration_path}\")\n",
    "\n",
    "        # Parse transformation matrices\n",
    "        T_camera_lidar = np.array(calibration_data[\"T_camera_lidar\"], dtype=float)\n",
    "        T_applanix_lidar = np.array(calibration_data[\"T_applanix_lidar\"], dtype=float)\n",
    "\n",
    "        # Parse intrinsics\n",
    "        intrinsics = calibration_data[\"camera_intrinsics\"]\n",
    "        fx = float(intrinsics[\"fx\"])\n",
    "        fy = float(intrinsics[\"fy\"])\n",
    "        cx = float(intrinsics[\"cx\"])\n",
    "        cy = float(intrinsics[\"cy\"])\n",
    "        distortion = np.array(intrinsics[\"distortion\"], dtype=float)\n",
    "\n",
    "        # Parse image parameters\n",
    "        img_params = calibration_data[\"image_params\"]\n",
    "        img_width = int(img_params[\"width\"])\n",
    "        img_height = int(img_params[\"height\"])\n",
    "\n",
    "        return (\n",
    "            T_camera_lidar,\n",
    "            T_applanix_lidar,\n",
    "            fx, fy, cx, cy,\n",
    "            img_width, img_height,\n",
    "            distortion\n",
    "        )\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        if log and log_specifics:\n",
    "            logger.error(f\"Calibration file not found: {calibration_path}\")\n",
    "        else:\n",
    "            print(f\"Calibration file not found: {calibration_path}\")\n",
    "        sys.exit(1)\n",
    "    except KeyError as e:\n",
    "        if log and log_specifics:\n",
    "            logger.error(f\"Missing key in calibration file ({e}) — check structure of {calibration_path}\")\n",
    "        else:\n",
    "            print(f\"Missing key in calibration file ({e}) — check structure of {calibration_path}\")\n",
    "        sys.exit(1)\n",
    "    except Exception as e:\n",
    "        if log and log_specifics:\n",
    "            logger.error(f\"Error reading calibration file {calibration_path}: {e}\")\n",
    "        else:\n",
    "            print(f\"Error reading calibration file {calibration_path}: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "\n",
    "def load_2d_lanes(lane_detection_path, config, img_width, img_height, flip_y=True, log=True):\n",
    "    '''\n",
    "    Load and convert 2D lane detections from a .txt file into pixel coordinates.\n",
    "\n",
    "    Args:\n",
    "        lane_detection_path (str): Path to the lane detection .txt file.\n",
    "        config (dict): Configuration file.\n",
    "        img_width, img_height (int): Camera mage width and height.\n",
    "        flip_y (bool, optional): If true, flips y-coordinates to image origin (top-left).\n",
    "        log (bool): True if log information (set to false if not established, ie from other file).\n",
    "\n",
    "    Returns:\n",
    "        list[np array]: Each element is an (N,2) np array of integer pixel coordinates [x, y] for one lane.\n",
    "    '''\n",
    "    detection_width = config[\"lane_detection_config\"][\"detection_width\"]\n",
    "    detection_height = config[\"lane_detection_config\"][\"detection_height\"]\n",
    "    if detection_width is None or detection_height is None:\n",
    "        if detection_width is None and detection_height is None:\n",
    "            detection_width = img_width\n",
    "            detection_height = img_height\n",
    "    scale_x = img_width / detection_width\n",
    "    scale_y = img_height / detection_height\n",
    "    lanes = []\n",
    "    try:\n",
    "        with open(lane_detection_path, \"r\") as f:\n",
    "            for l in f:\n",
    "                l = l.strip()\n",
    "                if \" confidence:\" in l:\n",
    "                    parts = l.rsplit(\" confidence:\", 1)\n",
    "                    lane_coords = [(float(x), float(y)) for x, y in (pair.split(',') for pair in parts[0].split())]\n",
    "                    lane_x, lane_y = zip(*lane_coords)\n",
    "                    lane_x = [float(x * scale_x) for x in lane_x]\n",
    "                    lane_y = [float(y * scale_y) for y in lane_y]\n",
    "                    lane_x = np.asarray(lane_x, dtype=int)\n",
    "                    lane_y = np.asarray(lane_y, dtype=int)\n",
    "                    if np.any(lane_x < 0) or np.any(lane_y < 0):\n",
    "                        if log and log_specifics:\n",
    "                            logger.error(\"Lane anchors have a negative pixel coordinate, error from ONCE\")\n",
    "                        else:\n",
    "                            print(\"Lane anchors have a negative pixel coordinate, error from ONCE\")\n",
    "                        sys.exit(1)\n",
    "                    if flip_y:\n",
    "                        lane_y = img_height - lane_y\n",
    "                    lanes.append(np.hstack([lane_x.reshape(-1,1), lane_y.reshape(-1,1)]))\n",
    "    except FileNotFoundError:\n",
    "        if log and log_specifics:\n",
    "            logger.warning(f\"lane detection file not found: {lane_detection_path}\")\n",
    "\n",
    "    return lanes\n",
    "\n",
    "\n",
    "\n",
    "def get_lidar_points(lidar_file_path):\n",
    "    '''\n",
    "    Load a LiDAR binary file and extract point data.\n",
    "\n",
    "    Args:\n",
    "        lidar_file_path (str): Path to LiDAR .bin file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (\n",
    "            points_xyz (N,3) np array,\n",
    "            intensity (N,) np array,\n",
    "            ring (N,) np array,\n",
    "            time (N,) np array\n",
    "        )\n",
    "    '''\n",
    "    points = np.fromfile(lidar_file_path, dtype=np.float32).reshape(-1, 6)\n",
    "    x, y, z, intensity, ring, time = points.T\n",
    "    points_xyz = np.vstack((x, y, z)).T\n",
    "\n",
    "    return points_xyz, intensity, ring, time\n",
    "\n",
    "\n",
    "\n",
    "def prefilter_ground_plane(points, sensor_height=1.5, height_range=None, vertical_axis=0):\n",
    "    \"\"\"\n",
    "    Prefilter a point cloud to keep only points near the expected ground plane height.\n",
    "\n",
    "    Args:\n",
    "        points (N,3) np array: Input 3D point cloud.\n",
    "        sensor_height (float): Expected height of the sensor above the ground plane (approximate).\n",
    "        height_range (float): Acceptable deviation (±) from the expected ground level.\n",
    "        vertical_axis (int): Axis index representing \"up\" direction (0=x, 1=y, 2=z).\n",
    "\n",
    "    Returns:\n",
    "        (M,3) np array: Filtered point cloud containing only points near ground level.\n",
    "    \"\"\"\n",
    "    if points is None or len(points) == 0:\n",
    "        return np.empty((0, 3), dtype=np.float32)\n",
    "    \n",
    "    if height_range is None:\n",
    "        height_range = sensor_height/2\n",
    "\n",
    "    min_height = -sensor_height - height_range\n",
    "    max_height = -sensor_height + height_range\n",
    "\n",
    "    # Select points whose coordinate along the vertical axis is within range\n",
    "    mask = (points[:, vertical_axis] >= min_height) & (points[:, vertical_axis] <= max_height)\n",
    "    filtered_points = points[mask]\n",
    "\n",
    "    return filtered_points.astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "def estimate_ground_plane(\n",
    "    points,\n",
    "    config,\n",
    "    vertical_axis=0,\n",
    "    random_state=None\n",
    "):\n",
    "    '''\n",
    "    Estimate the ground plane from 3D points using a band filter + RANSAC + least-squares refit.\n",
    "\n",
    "    Args:\n",
    "        points (N,3) np array: Input 3D point cloud.\n",
    "        config (dict): Configuration file.\n",
    "        vertical_axis (int, optional): Axis index representing up direction. Default is 0 (x-axis).\n",
    "        random_state (int, optional): Seed for random generator.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (\n",
    "            plane_normal (3,) np array: Unit normal vector.\n",
    "            plane_offset (float): Plane offset d in n·x + d = 0.\n",
    "            inlier_mask (N,3) np array[bool]: Mask of inlier points.\n",
    "        )\n",
    "    '''\n",
    "\n",
    "    sensor_height = config[\"ground_plane_ransac\"][\"camera_height\"]\n",
    "    band_half_width = config[\"ground_plane_ransac\"][\"band_half_width\"]\n",
    "    ransac_iters = config[\"ground_plane_ransac\"][\"ransac_iters\"]\n",
    "    inlier_threshold = config[\"ground_plane_ransac\"][\"inlier_threshold\"]\n",
    "    min_inliers_for_accept = config[\"ground_plane_ransac\"][\"min_inliers_for_accept\"]\n",
    "    inlier_fallback_range_mult = config[\"ground_plane_ransac\"][\"inlier_fallback_range_mult\"]\n",
    "    plane_norm_degenerate_threshold = float(config[\"ground_plane_ransac\"][\"plane_norm_degenerate_threshold\"])\n",
    "\n",
    "    if random_state is None:\n",
    "        rng = np.random.default_rng()\n",
    "    else:\n",
    "        rng = np.random.default_rng(random_state)\n",
    "\n",
    "    pts = np.asarray(points)\n",
    "\n",
    "    # expected ground coordinate value is  -sensor_height.\n",
    "    ground_coord = -sensor_height\n",
    "\n",
    "    use_fallback_plane=False\n",
    "\n",
    "    if pts.size == 0:\n",
    "        use_fallback_plane=True\n",
    "        logger.error(\"No points in lidar ransac around ground coordinate after prefunction filter\")\n",
    "    else:\n",
    "\n",
    "        # Pre-filter: keep points within a vertical band around expected ground\n",
    "        vert_vals = pts[:, vertical_axis]\n",
    "        band_mask = np.logical_and(vert_vals >= (ground_coord - band_half_width),\n",
    "                                vert_vals <= (ground_coord + band_half_width))\n",
    "\n",
    "        candidate_idx = np.nonzero(band_mask)[0]\n",
    "        if candidate_idx.size < min_inliers_for_accept:\n",
    "            # too few candidates - relax band slightly (quick fallback)\n",
    "            band_mask = np.logical_and(vert_vals >= (ground_coord - inlier_fallback_range_mult * band_half_width),\n",
    "                                    vert_vals <= (ground_coord + inlier_fallback_range_mult * band_half_width))\n",
    "            candidate_idx = np.nonzero(band_mask)[0]\n",
    "\n",
    "        \n",
    "        if candidate_idx.size < 3:\n",
    "            # not enough points to fit a plane\n",
    "            use_fallback_plane=True\n",
    "            logger.error(f\"Not enough candidate points for lidar ransac around ground coordinate after infunction filter: need 3, got {candidate_idx.size}\")\n",
    "\n",
    "    if not use_fallback_plane:\n",
    "        cand_pts = pts[candidate_idx]\n",
    "\n",
    "        best_inliers = None\n",
    "        best_count = 0\n",
    "\n",
    "        # RANSAC loop: sample 3 points, form plane, count inliers\n",
    "        M = cand_pts.shape[0]\n",
    "        for _ in range(ransac_iters):\n",
    "            ids = rng.choice(M, size=3, replace=False)\n",
    "            p0, p1, p2 = cand_pts[ids]\n",
    "\n",
    "            v1 = p1 - p0\n",
    "            v2 = p2 - p0\n",
    "            n = np.cross(v1, v2)\n",
    "            norm_n = np.linalg.norm(n)\n",
    "            if norm_n < plane_norm_degenerate_threshold:\n",
    "                continue  # degenerate sample, skip\n",
    "\n",
    "            n = n / norm_n\n",
    "            d = -np.dot(n, p0)\n",
    "\n",
    "            distances = np.abs(cand_pts.dot(n) + d)\n",
    "\n",
    "            # count inliers\n",
    "            mask_in = distances <= inlier_threshold\n",
    "            count = int(mask_in.sum())\n",
    "\n",
    "            if count > best_count:\n",
    "                best_count = count\n",
    "                best_inliers = candidate_idx[mask_in]  # indices into original pts\n",
    "\n",
    "    # require minimum inliers or not confident\n",
    "    if use_fallback_plane or best_count < min_inliers_for_accept:\n",
    "        if best_count < min_inliers_for_accept:\n",
    "            logger.warning(f\"Not enough points on best ground plane to surpass the min_inliers threshold: needed {min_inliers_for_accept}, got {best_count}\")\n",
    "        logger.warning(\"Using fallback constant-height plane\")\n",
    "        # return fallback: default flat plane normal pointing up\n",
    "        fallback_n = np.zeros(3)\n",
    "        fallback_n[vertical_axis] = 1.0\n",
    "        fallback_d = -ground_coord\n",
    "        if pts.size == 0:\n",
    "            inlier_mask = np.zeros(0, dtype=bool)\n",
    "        else:\n",
    "            inlier_mask = band_mask  # treat band as inliers\n",
    "        return fallback_n, fallback_d, inlier_mask\n",
    "\n",
    "\n",
    "    # Refit plane with all best inliers using SVD\n",
    "    inlier_pts = pts[best_inliers]\n",
    "    centroid = inlier_pts.mean(axis=0)\n",
    "    cov = inlier_pts - centroid\n",
    "    _, _, vh = np.linalg.svd(cov, full_matrices=False)\n",
    "    normal = vh.T[:, -1]\n",
    "    # enforce normal to point up (structure priors)\n",
    "    if normal[vertical_axis] < 0:\n",
    "        normal = -normal\n",
    "    d = -np.dot(normal, centroid)\n",
    "\n",
    "    # compute final inlier mask (on the whole cloud) using threshold\n",
    "    distances_all = np.abs(pts.dot(normal) + d)\n",
    "    inlier_mask = distances_all <= inlier_threshold\n",
    "\n",
    "    if d > 0:\n",
    "        normal = -normal\n",
    "        d = -d\n",
    "\n",
    "    return normal, d, inlier_mask\n",
    "\n",
    "\n",
    "\n",
    "def filter_and_clip_points(\n",
    "    points_camera,\n",
    "    fx, fy, cx, cy,\n",
    "    img_width, img_height,\n",
    "    config,\n",
    "    distortion=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Projects 3D camera-frame points into image plane and filters only those that fall \n",
    "    inside the camera's (distorted) field of view.\n",
    "\n",
    "    Args:\n",
    "        points_camera (N,3) np array: 3D points in camera frame.\n",
    "        fx, fy, cx, cy (float): Intrinsic parameters.\n",
    "        img_width, img_height (int): Image dimensions.\n",
    "        config (dict): Configuration file.\n",
    "        distortion (5,) optional np array: [k1, k2, p1, p2, k3] distortion coefficients.\n",
    "\n",
    "    Returns:\n",
    "        u (M,) np array: x-pixel coordinates visible on the distorted FOV.\n",
    "        v (M,) np array: y-pixel coordinates visible on the distorted FOV.\n",
    "        d (M,) np array: depths along the viewing ray.\n",
    "        points_3d_visible (M,3) np array: Corresponding 3D points visible in the distorted FOV.\n",
    "    \"\"\"\n",
    "    depth_cutoff_min = config[\"depth_map\"][\"depth_cutoff_min\"]\n",
    "    depth_cutoff_max = config[\"depth_map\"][\"depth_cutoff_max\"]\n",
    "    depth_max_point_scaling_distance = config[\"depth_map\"][\"depth_max_point_scaling_distance\"]\n",
    "    lidar_point_size_min = config[\"depth_map\"][\"lidar_point_size_min\"]\n",
    "    lidar_point_size_max = config[\"depth_map\"][\"lidar_point_size_max\"]\n",
    "\n",
    "    X, Y, Z = points_camera[:, 0], points_camera[:, 1], points_camera[:, 2]\n",
    "    Z = np.maximum(Z, 1e-6)  # avoid divide-by-zero\n",
    "\n",
    "    K = np.array([[fx, 0, cx],\n",
    "                  [0, fy, cy],\n",
    "                  [0,  0, 1]], dtype=np.float64)\n",
    "\n",
    "    # Project with distortion\n",
    "    rvec = np.zeros((3, 1), dtype=np.float64)\n",
    "    tvec = np.zeros((3, 1), dtype=np.float64)\n",
    "    points_2d, _ = cv2.projectPoints(points_camera, rvec, tvec, K, distortion)\n",
    "    points_2d = points_2d.reshape(-1, 2)\n",
    "    u, v = points_2d[:, 0], points_2d[:, 1]\n",
    "\n",
    "    # Visibility mask\n",
    "    mask = (\n",
    "        (Z > 0) &\n",
    "        (u >= 0) & (u < img_width) &\n",
    "        (v >= 0) & (v < img_height) &\n",
    "        (Z >= depth_cutoff_min) & (Z <= depth_cutoff_max)\n",
    "    )\n",
    "    points_3d_visible = points_camera[mask]\n",
    "    points_2d_visible = points_2d[mask]\n",
    "    c = Z[mask]\n",
    "    u = points_2d_visible[:, 0]\n",
    "    v = points_2d_visible[:, 1]\n",
    "    v_flipped = img_height - v\n",
    "\n",
    "    depth_clipped = np.clip(c, depth_cutoff_min, depth_max_point_scaling_distance)  # Clip to fixed range\n",
    "    depth_normalized = (depth_clipped - depth_cutoff_min) / (depth_max_point_scaling_distance - depth_cutoff_min)\n",
    "    sizes = lidar_point_size_max - (depth_normalized * (lidar_point_size_max - lidar_point_size_min))  # Linear interpolation\n",
    "\n",
    "    return u, v_flipped, c, sizes, points_3d_visible\n",
    "\n",
    "\n",
    "\n",
    "def create_spatial_bins(u, v, r, depth, pts, cell_size):\n",
    "    '''\n",
    "    Create spatial bins (grid cells) for 2D pixel / depth data for fast searching.\n",
    "\n",
    "    Args:\n",
    "        u (N,) np array: x pixel coordinates.\n",
    "        v (N,) np array: y pixel coordinates.\n",
    "        r (N,) np array: Point render radius (px)\n",
    "        depth (N,) np array: Point depth.\n",
    "        pts (N,3) np array: Associated 3D points.\n",
    "        cell_size (float): Size of each grid cell.\n",
    "\n",
    "    Returns:\n",
    "        dict: {\n",
    "            bins (dict): the dictionary of bins.\n",
    "            \n",
    "            All inputs.\n",
    "        }\n",
    "    '''\n",
    "    # Create integer grid keys for each point\n",
    "    cell_x = np.floor(u / cell_size).astype(int)\n",
    "    cell_y = np.floor(v / cell_size).astype(int)\n",
    "\n",
    "    bins = defaultdict(list)\n",
    "\n",
    "    for i in range(len(u)):\n",
    "        bins[(cell_x[i], cell_y[i])].append(i)\n",
    "\n",
    "    return {\n",
    "        \"bins\": bins,\n",
    "        \"u\": u,\n",
    "        \"v\": v,\n",
    "        \"r\": r,\n",
    "        \"depth\": depth,\n",
    "        \"pts\": pts,\n",
    "        \"cell_size\": cell_size\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def fit_line_on_plane_precalc(plane_normal, plane_offset):\n",
    "    '''\n",
    "    Precompute plane basis vectors and origin for efficient repeated line fitting.\n",
    "\n",
    "    Args:\n",
    "        plane_normal (3,) np array: Unit normal vector.\n",
    "        plane_offset (float): Plane offset d in n·x + d = 0.\n",
    "\n",
    "    Returns:\n",
    "        dict: {\n",
    "            plane_x (3,) np array: Orthonormal basis (unit) vector lying on the x axis.\n",
    "            plane_y (3,) np array: Orthonormal basis (unit) vector lying on the y axis.\n",
    "            origin (3,) np array: 3D point lying on the plane (satisfies n·origin + d = 0).\n",
    "        }\n",
    "    '''\n",
    "    n = plane_normal / np.linalg.norm(plane_normal)\n",
    "    # Create local 2D basis vectors\n",
    "    arbitrary = np.array([1, 0, 0]) if abs(n[0]) < 0.9 else np.array([0, 1, 0])\n",
    "    plane_x = np.cross(n, arbitrary)\n",
    "    plane_x /= np.linalg.norm(plane_x)\n",
    "    plane_y = np.cross(n, plane_x)\n",
    "\n",
    "\n",
    "    origin = -plane_offset * n  # any point that satisfies n·x + d = 0\n",
    "\n",
    "    return {\n",
    "        \"plane_x\": plane_x, \n",
    "        \"plane_y\": plane_y, \n",
    "        \"origin\": origin\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151d3a89",
   "metadata": {},
   "source": [
    "### Per Line Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bac6d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pure_intrinsic_projection(\n",
    "    u, v,\n",
    "    fx, fy, cx, cy, \n",
    "    config,\n",
    "    distortion = None,\n",
    "    height_cam = None,\n",
    "    plane_normal = None,\n",
    "    plane_offset = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Project pixels (u, v) to 3D positions in camera frame, either onto a flat ground or an arbitrary plane.\n",
    "\n",
    "    Args:\n",
    "        u (N,) np array: x pixel coordinates.\n",
    "        v (N,) np array: y pixel coordinates.\n",
    "        fx, fy, cx, cy (float): Intrinsic parameters.\n",
    "        distortion (5,) optional np array: [k1, k2, p1, p2, k3] distortion coefficients.\n",
    "        \n",
    "        Need either:\n",
    "            1) height_cam (float, optional): if given, project rays onto flat ground at Y = -height_cam.\n",
    "            2) plane_normal (3,) optional np array: if given, project rays onto unit normal of plane.\n",
    "               plane_offset (float, optional): Plane offset d in n·x + d = 0.\n",
    "\n",
    "    Returns:\n",
    "        points_3d (N,3) np array: 3D points in camera frame.\n",
    "    \"\"\"\n",
    "    if height_cam is None and (plane_normal is None or plane_offset is None):\n",
    "        if log_specifics:\n",
    "            logger.error(\"Must provide either height_cam or plane_normal + plane_offset\")\n",
    "        else:\n",
    "            print(\"Must provide either height_cam or plane_normal + plane_offset\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    parallel_plane_thresh = float(config[\"intrinsic_plane_projection\"][\"parallel_plane_thresh\"])\n",
    "    u = np.asarray(u, dtype=np.float64)\n",
    "    v = np.asarray(v, dtype=np.float64)\n",
    "\n",
    "    # Pinhole\n",
    "    x = (u - cx) / fx\n",
    "    y = (v - cy) / fy\n",
    "\n",
    "    # Distortion (manual, proof of working math for thesis)\n",
    "    if distortion is not None:\n",
    "        k1, k2, p1, p2, k3 = distortion[:5]\n",
    "        r2 = x**2 + y**2\n",
    "        radial = 1 + k1*r2 + k2*r2**2 + k3*r2**3\n",
    "        x_distorted = x * radial + 2*p1*x*y + p2*(r2 + 2*x**2)\n",
    "        y_distorted = y * radial + p1*(r2 + 2*y**2) + 2*p2*x*y\n",
    "        x, y = x_distorted, y_distorted\n",
    "\n",
    "    rays = np.stack([x, y, np.ones_like(x)], axis=-1)\n",
    "    points_3d = np.zeros_like(rays)\n",
    "\n",
    "    if height_cam is not None:\n",
    "        # Flat ground at Y = -height_cam\n",
    "        denom = rays[:, 1]  # cam frame, Y is vertical axis\n",
    "        valid = np.abs(denom) > parallel_plane_thresh\n",
    "        num_invalid = np.count_nonzero(~valid)\n",
    "        if num_invalid > 0:\n",
    "            logger.error(f\"Intrinsic proj to plane:{num_invalid} invalid (parallel) rays\")\n",
    "        s = np.zeros_like(denom)\n",
    "        s[valid] = -height_cam / denom[valid]\n",
    "        points_3d[valid] = rays[valid] * s[valid, None]\n",
    "        points_3d[~valid] = np.nan  # ray parallel to ground\n",
    "    else:\n",
    "        # Arbitrary plane: plane_normal · X + plane_offset = 0\n",
    "        plane_normal = np.asarray(plane_normal, dtype=np.float64)\n",
    "        denom = rays @ plane_normal\n",
    "        valid = np.abs(denom) > parallel_plane_thresh\n",
    "        num_invalid = np.count_nonzero(~valid)\n",
    "        if num_invalid > 0:\n",
    "            logger.error(f\"Intrinsic proj to plane:{num_invalid} invalid (parallel) rays\")\n",
    "        s = np.zeros_like(denom)\n",
    "        s[valid] = -plane_offset / denom[valid]\n",
    "        points_3d[valid] = rays[valid] * s[valid, None]\n",
    "        points_3d[~valid] = np.nan  # ray parallel to plane\n",
    "\n",
    "    return points_3d\n",
    "\n",
    "\n",
    "\n",
    "def fit_line_on_plane(points, precalc_values, curvature_threshold=0.05):\n",
    "    \"\"\"\n",
    "    Fit a 3D line (or quadratic curve if curvature is high) through points known to lie on a plane.\n",
    "\n",
    "    Args:\n",
    "        points (N,3) np array: 3D points (already on plane).\n",
    "        precalc_values (dict): dict containing plane_x, plane_y, origin (see fit_line_on_plane_precalc()).\n",
    "        curvature_threshold (float, optional): RMS threshold to switch to quadratic fitting. Default is 0.05.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (\n",
    "            model_type (str): the used fitting model, either \"linear\" or \"quadratic\",\n",
    "            model_params (dict): {\n",
    "                coeffs (tuple) of floats: \n",
    "                    Linear: (a,b) satisfying a·x + b = 0,\n",
    "                    Quadratic: (a,b,c) satisfying a·x^2 + b·x + c = 0.\n",
    "                z_intercept (3,) np array: 3D point on plane for the y-intercept.\n",
    "                \n",
    "                line_dir:\n",
    "                    Linear: (3,) np array: Unit direction vector along the fitted line.\n",
    "                    Quadratic: None\n",
    "                quad_firstorder_dir:\n",
    "                    Linear: None\n",
    "                    Quadratic: (3,) np array: Unit direction vector for first-order change along the fitted line.\n",
    "                quad_secondorder_dir:\n",
    "                    Linear: None\n",
    "                    Quadratic: (3,) np array: Unit direction vector for second-order change along the fitted line.\n",
    "            }\n",
    "        )\n",
    "    \"\"\"\n",
    "    plane_x = precalc_values[\"plane_x\"]\n",
    "    plane_y = precalc_values[\"plane_y\"]\n",
    "    origin = precalc_values[\"origin\"]\n",
    "\n",
    "    # Convert points to 2D local coordinates on plane\n",
    "    pts = np.asarray(points)\n",
    "    local_pts = pts - origin\n",
    "    x = local_pts @ plane_x\n",
    "    y = local_pts @ plane_y\n",
    "\n",
    "    # Fit linear model y = a*x + b\n",
    "    A = np.vstack([x, np.ones_like(x)]).T\n",
    "    a, b = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "    y_pred = a * x + b\n",
    "    linear_rms = np.sqrt(np.mean((y - y_pred) ** 2))\n",
    "\n",
    "    # Quadratic fallback if large rms error\n",
    "    if linear_rms > curvature_threshold:\n",
    "        a2, b2, c2 = np.polyfit(x, y, 2)\n",
    "\n",
    "        # Fit quadratic model y = a*(x^2) + b*x + c\n",
    "        quad_origin = origin + c2 * plane_y\n",
    "        quad_firstorder_dir = plane_x + b2 * plane_y\n",
    "        quad_secondorder_dir = a2 * plane_y\n",
    "\n",
    "        if np.dot(quad_firstorder_dir, np.array([0, 0, 1])) < 0:\n",
    "            quad_firstorder_dir *= -1\n",
    "\n",
    "        if np.dot(quad_secondorder_dir, np.array([0, 0, 1])) < 0:\n",
    "            quad_secondorder_dir *= -1\n",
    "\n",
    "        return \"quadratic\", {\n",
    "            \"coeffs\": (a2, b2, c2),\n",
    "            \"z_intercept\": quad_origin,\n",
    "            \"line_dir\": None,\n",
    "            \"quad_firstorder_dir\": quad_firstorder_dir,\n",
    "            \"quad_secondorder_dir\": quad_secondorder_dir\n",
    "        }\n",
    "\n",
    "    # Return linear\n",
    "    line_dir = plane_x + a * plane_y\n",
    "    if np.dot(line_dir, np.array([0, 0, 1])) < 0:\n",
    "        line_dir *= -1\n",
    "    line_origin = origin + b * plane_y\n",
    "\n",
    "    return \"linear\", {\n",
    "        \"coeffs\": (a, b),\n",
    "        \"z_intercept\": line_origin,\n",
    "        \"line_dir\": line_dir / np.linalg.norm(line_dir),\n",
    "        \"quad_firstorder_dir\": None,\n",
    "        \"quad_secondorder_dir\": None\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def query_nearest_depth_from_bins(bins_info, x, y, bin_search_range=5):\n",
    "    \"\"\"\n",
    "    Query the nearest (u, v, depth, point) for the given pixel (x, y)\n",
    "    by expanding search radius across bins until a match is found.\n",
    "\n",
    "    Args:\n",
    "        bins_info (dict): dict containing bins, cell_size, u, v, depth, pts (see create_spatial_bins()).\n",
    "        x (float): x pixel coordinate to query.\n",
    "        y (float): y pixel coordinate to query.\n",
    "        bin_search_range: how many neighboring bins (in Manhattan distance) to search outward from the current bin. \n",
    "            If None, expands outward until a match is found.\n",
    "\n",
    "    Returns:\n",
    "        tuple (\n",
    "            u_match (float): x pixel coordinate of match, \n",
    "            v_match (float): y pixel coordinate of match,\n",
    "            depth_match (float): Depth value of match,\n",
    "            pt_match (3,) np array: 3D point coordinate of match\n",
    "        )\n",
    "        or (None, None, None, None) if no match found.\n",
    "    \"\"\"\n",
    "    bins = bins_info[\"bins\"]\n",
    "    cell_size = bins_info[\"cell_size\"]\n",
    "    u = bins_info[\"u\"]\n",
    "    v = bins_info[\"v\"]\n",
    "    depth = bins_info[\"depth\"]\n",
    "    pts = bins_info[\"pts\"]\n",
    "\n",
    "    if not bins:\n",
    "        if log_specifics:\n",
    "            logger.error(\"Bins is undefined on access\")\n",
    "        else: \n",
    "            print(\"Bins is undefined on access\")\n",
    "        return None, None, None, None\n",
    "\n",
    "    # Identify base bin cell\n",
    "    key_x = int(np.floor(x / cell_size))\n",
    "    key_y = int(np.floor(y / cell_size))\n",
    "\n",
    "    best_idx = None\n",
    "    best_dist2 = np.inf\n",
    "\n",
    "    # Determine if infinite search (only for alt solutions)\n",
    "    infinite_search = bin_search_range is None\n",
    "    if infinite_search:\n",
    "        bin_search_range = 0  # start at current bin\n",
    "\n",
    "    visited_bins = set()\n",
    "    search_r = 0 if infinite_search else 1\n",
    "    while True:\n",
    "        matched_any = False\n",
    "        for dx in range(-search_r, search_r + 1):\n",
    "            for dy in range(-search_r, search_r + 1):\n",
    "                # Skip inner bins for r > 0\n",
    "                if search_r > 0 and abs(dx) < search_r and abs(dy) < search_r:\n",
    "                    continue\n",
    "\n",
    "                cell_key = (key_x + dx, key_y + dy)\n",
    "                if cell_key in visited_bins or cell_key not in bins:\n",
    "                    continue\n",
    "                visited_bins.add(cell_key)\n",
    "\n",
    "                indices = bins[cell_key]\n",
    "                if not indices:\n",
    "                    continue\n",
    "\n",
    "                matched_any = True\n",
    "                u_i = u[indices]\n",
    "                v_i = v[indices]\n",
    "                dists2 = (u_i - x) ** 2 + (v_i - y) ** 2\n",
    "\n",
    "                min_local_idx = np.argmin(dists2)\n",
    "                if dists2[min_local_idx] < best_dist2:\n",
    "                    best_dist2 = dists2[min_local_idx]\n",
    "                    best_idx = indices[min_local_idx]\n",
    "\n",
    "        # Stop when any match found\n",
    "        if matched_any and best_idx is not None:\n",
    "            break\n",
    "\n",
    "        if infinite_search:\n",
    "            # Stop when we've checked all bins\n",
    "            if len(visited_bins) == len(bins):\n",
    "                break\n",
    "        else:\n",
    "            # Stop when we've checked all bins in max range\n",
    "            if search_r >= bin_search_range:\n",
    "                break\n",
    "\n",
    "        # Expand search radius\n",
    "        search_r += 1\n",
    "\n",
    "    if best_idx is None:\n",
    "        if infinite_search and len(visited_bins) == len(bins):\n",
    "            if log_specifics:\n",
    "                logger.error(\"All bins checked, no matched points\")\n",
    "            else:\n",
    "                print (\"All bins checked, no matched points\")\n",
    "        return None, None, None, None\n",
    "\n",
    "    return (\n",
    "        float(u[best_idx]),\n",
    "        float(v[best_idx]),\n",
    "        float(depth[best_idx]),\n",
    "        pts[best_idx],\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def project_pixel_to_depth(u, v, d, fx, fy, cx, cy, distortion=None):\n",
    "    \"\"\"\n",
    "    Backproject pixel coordinates (u, v) with depth d into 3D camera coordinates.\n",
    "    Undistorts pixels when distortion coefficients are provided.\n",
    "\n",
    "    Args:\n",
    "        u (float or (N,) np array): x pixel coordinate(s).\n",
    "        v (float or (N,) np array): y pixel coordinate(s).\n",
    "        d (float or (N,) np array): Depth value(s).\n",
    "        fx, fy, cx, cy (float): Intrinsic parameters.\n",
    "        distortion (5,) optional np array: [k1, k2, p1, p2, k3] distortion coefficients.\n",
    "\n",
    "    Returns:\n",
    "        points_3d (float or (N,3) np array): 3D point(s) in camera frame.\n",
    "    \"\"\"\n",
    "    # Convert inputs to 1D arrays\n",
    "    u = np.atleast_1d(np.asarray(u, dtype=np.float64))\n",
    "    v = np.atleast_1d(np.asarray(v, dtype=np.float64))\n",
    "    d = np.atleast_1d(np.asarray(d, dtype=np.float64))\n",
    "\n",
    "    if not (u.shape == v.shape == d.shape):\n",
    "        raise ValueError(\"u, v, d must have the same shape\")\n",
    "\n",
    "    N = u.size\n",
    "    if N == 0:\n",
    "        return np.zeros((0, 3), dtype=np.float64)\n",
    "\n",
    "    # Build points array in shape (N,1,2)\n",
    "    pts = np.stack([u, v], axis=-1).astype(np.float64)\n",
    "    pts_cv = pts.reshape(-1, 1, 2)\n",
    "\n",
    "    if distortion is not None:\n",
    "        K = np.array([[fx, 0, cx],\n",
    "                      [0, fy, cy],\n",
    "                      [0,  0, 1]], dtype=np.float64)\n",
    "        undist = cv2.undistortPoints(pts_cv, K, distortion, P=K)\n",
    "        undist = undist.reshape(-1, 2)\n",
    "        x = (undist[:, 0] - cx) / fx\n",
    "        y = (undist[:, 1] - cy) / fy\n",
    "    else:\n",
    "        x = (u - cx) / fx\n",
    "        y = (v - cy) / fy\n",
    "\n",
    "    # Backproject to 3D (camera frame)\n",
    "    X = x * d\n",
    "    Y = y * d\n",
    "    Z = d\n",
    "\n",
    "    pts3d = np.stack((X, Y, Z), axis=-1)\n",
    "\n",
    "    return pts3d\n",
    "\n",
    "\n",
    "\n",
    "def query_depth_from_bins(bins_info, x, y, get_all_depths=False, prioritize_closest=True):\n",
    "    '''\n",
    "    Query nearby binned points for a given pixel location. Only looks in the pixel's bin.\n",
    "\n",
    "    Args:\n",
    "        bins_info (dict): dict containing bins, cell_size, u, v, depth, pts (see create_spatial_bins()).\n",
    "        x (float): x pixel coordinate to query.\n",
    "        y (float): y pixel coordinate to query.\n",
    "        get_all_depths (bool, optional): If True, return all matched depths and points. \n",
    "            Default is False, going to prioritize_closest logic.\n",
    "        prioritize_closest (bool, optional): If True, prefer the match nearest in 2D distance; otherwise, by smallest depth.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (\n",
    "            x pixel coordinate(s) (float or (N,) np array),\n",
    "            y pixel coordinate(s) (float or (N,) np array),\n",
    "            Depth value(s) (float or (N,) np array),\n",
    "            3D matched point(s) ((3,) or (N,3) np array)\n",
    "        )\n",
    "        or (None, None, None, None) if no match found.\n",
    "    '''\n",
    "    bins = bins_info[\"bins\"]\n",
    "    cell_size = bins_info[\"cell_size\"]\n",
    "    u = bins_info[\"u\"]\n",
    "    v = bins_info[\"v\"]\n",
    "    r = bins_info[\"r\"]\n",
    "    depth = bins_info[\"depth\"]\n",
    "    pts = bins_info[\"pts\"]\n",
    "\n",
    "    # Identify which grid cell (x,y) lies in\n",
    "    key_x = int(np.floor(x / cell_size))\n",
    "    key_y = int(np.floor(y / cell_size))\n",
    "\n",
    "    matched_depths = []\n",
    "    matched_points = []\n",
    "    us = []\n",
    "    vs = []\n",
    "\n",
    "    # Search the 3x3 neighborhood\n",
    "    for dx in (-1, 0, 1):\n",
    "        for dy in (-1, 0, 1):\n",
    "            cell_key = (key_x + dx, key_y + dy)\n",
    "            if cell_key not in bins:\n",
    "                continue\n",
    "\n",
    "            indices = bins[cell_key]\n",
    "            if not indices:\n",
    "                continue\n",
    "\n",
    "            u_i = u[indices]\n",
    "            v_i = v[indices]\n",
    "            r_i = r[indices]\n",
    "\n",
    "            # Box test\n",
    "            dxs = np.abs(u_i - x)\n",
    "            dys = np.abs(v_i - y)\n",
    "            mask_box = (dxs <= r_i) & (dys <= r_i)\n",
    "            if not np.any(mask_box):\n",
    "                continue\n",
    "\n",
    "            # Circle membership test\n",
    "            dxs = dxs[mask_box]\n",
    "            dys = dys[mask_box]\n",
    "            r_i = r_i[mask_box]\n",
    "\n",
    "            mask_circle = (dxs**2 + dys**2) <= r_i**2\n",
    "            if not np.any(mask_circle):\n",
    "                continue\n",
    "\n",
    "            matched_depths.extend(depth[indices][mask_box][mask_circle])\n",
    "            matched_points.extend(pts[indices][mask_box][mask_circle])\n",
    "            us.extend(u_i[mask_box][mask_circle])\n",
    "            vs.extend(v_i[mask_box][mask_circle])\n",
    "\n",
    "    if not matched_depths:\n",
    "            return None, None, None, None\n",
    "\n",
    "    if get_all_depths:\n",
    "        return us, vs, matched_depths, matched_points\n",
    "\n",
    "    matched_depths = np.array(matched_depths)\n",
    "    us = np.array(us)\n",
    "    vs = np.array(vs)\n",
    "\n",
    "    if prioritize_closest:\n",
    "        # Choose the match with the smallest 2D distance to (x, y)\n",
    "        dists2 = (np.array(us) - x)**2 + (np.array(vs) - y)**2\n",
    "        min_idx = np.argmin(dists2)\n",
    "    else:\n",
    "        # Choose the match with smallest depth (closest to camera)\n",
    "        min_idx = np.argmin(matched_depths)\n",
    "\n",
    "    return us[min_idx], vs[min_idx], float(matched_depths[min_idx]), matched_points[min_idx]\n",
    "\n",
    "\n",
    "\n",
    "def verify_with_intrinsic_projection(\n",
    "    u, v,\n",
    "    fx, fy, cx, cy, \n",
    "    config,\n",
    "    plane_normal,\n",
    "    plane_offset,\n",
    "    verify_depth,\n",
    "    distortion=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Determine if a depth is valid, thus non-parallel and within a maximum allowable range.\n",
    "\n",
    "    Args:\n",
    "        u (float): x pixel coordinate.\n",
    "        v (float): y pixel coordinate.\n",
    "        fx, fy, cx, cy (float): Intrinsic parameters.\n",
    "        config (dict): Configuration file.\n",
    "        plane_normal (3,) np array: Unit normal vector.\n",
    "        plane_offset (float): Plane offset d in n·x + d = 0.\n",
    "        verify_depth (float): The depth value to verify.\n",
    "        distortion (5,) optional np array: [k1, k2, p1, p2, k3] distortion coefficients.\n",
    "\n",
    "    Returns:\n",
    "        (float): the verified depth, or the intrinsic depth if it failed the threshold check.\n",
    "    \"\"\"\n",
    "    parallel_plane_thresh = float(config[\"intrinsic_plane_projection\"][\"parallel_plane_thresh\"])\n",
    "    max_deviation = config[\"depth_map\"][\"max_deviation_from_intr\"]\n",
    "\n",
    "    x = (u - cx) / fx\n",
    "    y = (v - cy) / fy\n",
    "\n",
    "    if distortion is not None:\n",
    "        k1, k2, p1, p2, k3 = distortion[:5]\n",
    "        r2 = x**2 + y**2\n",
    "        radial = 1 + k1*r2 + k2*r2**2 + k3*r2**3\n",
    "        x = x * radial + 2*p1*x*y + p2*(r2 + 2*x**2)\n",
    "        y = y * radial + p1*(r2 + 2*y**2) + 2*p2*x*y\n",
    "\n",
    "    ray = np.array([x, y, 1.0], dtype=np.float64)\n",
    "    denom = ray @ np.asarray(plane_normal, dtype=np.float64)\n",
    "    \n",
    "    if np.abs(denom) <= parallel_plane_thresh:\n",
    "        return verify_depth\n",
    "\n",
    "    s = abs(-plane_offset / denom)\n",
    "\n",
    "    if verify_depth > s * (1 + max_deviation):\n",
    "        return s\n",
    "    \n",
    "    return verify_depth\n",
    "\n",
    "\n",
    "\n",
    "def cumulative_lengths_2d(pts2d):\n",
    "    '''\n",
    "    Compute cumulative arc lengths along a 2D polyline.\n",
    "\n",
    "    Args:\n",
    "        pts2d (N,2) np array: 2D points.\n",
    "\n",
    "    Returns:\n",
    "        Cumulative lengths (N,) np array with first element = 0.0.\n",
    "    '''\n",
    "    diffs = np.diff(pts2d, axis=0)\n",
    "    seglen = np.linalg.norm(diffs, axis=1)\n",
    "    return np.concatenate(([0.0], np.cumsum(seglen)))\n",
    "\n",
    "\n",
    "\n",
    "def project_point_to_2d_polyline(pt, poly):\n",
    "    '''\n",
    "    Project a 2D point onto a 2D polyline.\n",
    "\n",
    "    Args:\n",
    "        pt (2,) np array: 2D point.\n",
    "        poly (N,2) np array: Polyline points.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (\n",
    "            Cumulative distance along polyline at projection (float),\n",
    "            Projected point on polyline (2,) np array,\n",
    "            Index of segment used (int),\n",
    "            Fractional position along the segment (float),\n",
    "            Euclidean distance from point to projection (float)\n",
    "        )\n",
    "    '''\n",
    "    best_dist = np.inf\n",
    "    best = None\n",
    "    cum = cumulative_lengths_2d(poly)\n",
    "    seg_starts = poly[:-1]\n",
    "    seg_ends = poly[1:]\n",
    "    seg_vecs = seg_ends - seg_starts\n",
    "    seg_lens2 = np.sum(seg_vecs**2, axis=1)\n",
    "    for i, (p0, v, L2) in enumerate(zip(seg_starts, seg_vecs, seg_lens2)):\n",
    "        if L2 == 0:\n",
    "            frac = 0.0\n",
    "            proj = p0\n",
    "        else:\n",
    "            t = np.dot(pt - p0, v) / L2\n",
    "            frac = np.clip(t, 0.0, 1.0)\n",
    "            proj = p0 + frac * v\n",
    "        d = np.linalg.norm(pt - proj)\n",
    "        s_here = cum[i] + frac * np.sqrt(L2)\n",
    "        if d < best_dist:\n",
    "            best_dist = d\n",
    "            best = (s_here, proj, i, frac, d)\n",
    "    return best\n",
    "\n",
    "\n",
    "\n",
    "def lane_point_linear_model(linear_intercept, linear_dir, t):\n",
    "    '''\n",
    "    Compute 3D lane points along a linear parametric model: P(t) = linear_intercept + t * linear_dir.\n",
    "\n",
    "    Args:\n",
    "        linear_intercept (3,) np array: 3D origin point of the lane in the reference frame.\n",
    "        linear_dir (3,) np array: Unit direction vector of the lane.\n",
    "        t (float (N,) np array): Scalar(s) representing distance parameter along the lane.\n",
    "\n",
    "    Returns:\n",
    "        3D lane points corresponding to t ((3,) or (N,3) np array)\n",
    "    '''\n",
    "    t = np.asarray(t)    # t can be scalar or array\n",
    "    return linear_intercept + np.outer(t, linear_dir)\n",
    "\n",
    "\n",
    "\n",
    "def lane_point_quadratic_model(quadratic_intercept, quadratic_firstorder_dir, quadratic_secondorder_dir, t):\n",
    "    '''\n",
    "    Compute 3D lane points along a quadratic parametric model: P(t) = quadratic_intercept \n",
    "        + t * quadratic_firstorder_dir + t² * quadratic_secondorder_dir.\n",
    "\n",
    "    Args:\n",
    "        quadratic_intercept (3,) np array: 3D base point of the lane curve.\n",
    "        quadratic_firstorder_dir (3,) np array: First-order unit direction vector.\n",
    "        quadratic_secondorder_dir (3,) np array: Second-order unit curvature vector/\n",
    "        t (float (N,) np array): Scalar(s) representing distance parameter along the lane.\n",
    "\n",
    "    Returns:\n",
    "        3D lane points corresponding to t ((3,) or (N,3) np array)\n",
    "    '''\n",
    "    t = np.asarray(t)\n",
    "    return quadratic_intercept + np.outer(t, quadratic_firstorder_dir) + np.outer(t*t, quadratic_secondorder_dir)\n",
    "\n",
    "\n",
    "\n",
    "def compute_t_for_3d_point(\n",
    "    P, \n",
    "    model_type, \n",
    "    config,\n",
    "    z_intercept,\n",
    "    linear_dir=None,\n",
    "    quadratic_firstorder_dir=None, \n",
    "    quadratic_secondorder_dir=None,\n",
    "    t_bounds=None\n",
    "):\n",
    "    '''\n",
    "    Compute the scalar lane parameter t corresponding to the projection of a 3D point \n",
    "    onto a linear or quadratic lane model.\n",
    "\n",
    "    Args:\n",
    "        P (3,) np array: 3D point to project.\n",
    "        model_type (str): the used fitting model, either \"linear\" or \"quadratic\".\n",
    "        config (dict): Configuration file.\n",
    "        z_intercept (3,) np array: 3D point on plane for the y-intercept.\n",
    "\n",
    "        Either:\n",
    "            1) Linear:\n",
    "                linear_dir (3,) np array: Unit direction vector along the fitted line.\n",
    "                quadratic_firstorder_dir, quadratic_secondorder_dir = None\n",
    "            2) Quadratic:\n",
    "                linear_dir = None             \n",
    "                quadratic_firstorder_dir (3,) np array: Unit direction vector for first-order change along the fitted line.\n",
    "                quadratic_secondorder_dir (3,) np array: Unit direction vector for second-order change along the fitted line.\n",
    "        \n",
    "        t_bounds (tuple[float, float], optional): Lower and upper bounds for the optimizer search range on t.\n",
    "            Defaults to config file settings.\n",
    "\n",
    "    Returns:\n",
    "        Parametric distance along lane line (float).\n",
    "    '''\n",
    "    P = np.asarray(P)\n",
    "    p0 = z_intercept\n",
    "    if model_type == \"linear\":\n",
    "        # use linear_intercept and linear_dir\n",
    "        a = linear_dir\n",
    "        t = float(np.dot(P - p0, a))\n",
    "        return t\n",
    "    elif model_type == \"quadratic\":\n",
    "        a = quadratic_firstorder_dir\n",
    "        b = quadratic_secondorder_dir\n",
    "        def f(t):\n",
    "            X = p0 + a * t + b * (t*t)\n",
    "            return np.sum((X - P)**2)\n",
    "        # initial guess from projection onto a\n",
    "        t0 = float(np.dot(P - p0, a))\n",
    "        if t_bounds is None:\n",
    "            hi = config[\"projection_mapping\"][\"curve_optimizer_fallback_search_range\"]\n",
    "            lo = -hi\n",
    "        else:\n",
    "            lo, hi = t_bounds\n",
    "        short_range = config[\"projection_mapping\"][\"curve_optimizer_short_search_range\"]\n",
    "        lo_try = max(lo, t0 - short_range)\n",
    "        hi_try = min(hi, t0 + short_range)\n",
    "        if lo_try >= hi_try:\n",
    "            lo_try, hi_try = lo, hi\n",
    "        res = minimize_scalar(\n",
    "            f, \n",
    "            bounds=(lo_try, hi_try), \n",
    "            method='bounded', \n",
    "            options={'xatol':float(config[\"projection_mapping\"][\"curve_optimizer_precise_xatol\"])}\n",
    "        )\n",
    "        if not res.success:\n",
    "            res = minimize_scalar(\n",
    "                f, \n",
    "                bounds=(lo, hi), \n",
    "                method='bounded', \n",
    "                options={'xatol':float(config[\"projection_mapping\"][\"curve_optimizer_fallback_xatol\"])}\n",
    "            )\n",
    "        return float(res.x)\n",
    "    else:\n",
    "        if log_specifics:\n",
    "            logger.error(\"Unsupported model_type: must be 'linear' or 'quadratic'\")\n",
    "        else:\n",
    "            print(\"Unsupported model_type: must be 'linear' or 'quadratic'\")\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "\n",
    "def learn_pixel_to_t_mapping_for_lane(\n",
    "    s1_points,               \n",
    "    model_type,             \n",
    "    config,\n",
    "    z_intercept,            \n",
    "    img_height, fx, fy, cx, cy, distortion=None,\n",
    "    linear_dir=None,         \n",
    "    quadratic_firstorder_dir=None,\n",
    "    quadratic_secondorder_dir=None\n",
    "):\n",
    "    '''\n",
    "    Learn a mapping between pixel-space arc length (s_pixel) and lane parameter t \n",
    "    for a given lane, based on known 2D-3D correspondences.\n",
    "\n",
    "    Args:\n",
    "        s1_points (N,3) np array: points (u, v, d) to learn mapping.\n",
    "        model_type (str): the used fitting model, either \"linear\" or \"quadratic\".\n",
    "        config (dict): Configuration file.\n",
    "        z_intercept (3,) np array: 3D point on plane for the y-intercept.\n",
    "        img_height (float): Height of image (px).\n",
    "        fx, fy, cx, cy (float): Intrinsic parameters.\n",
    "        distortion (5,) optional np array: [k1, k2, p1, p2, k3] distortion coefficients.\n",
    "\n",
    "        Either:\n",
    "            1) Linear:\n",
    "                linear_dir (3,) np array: Unit direction vector along the fitted line.\n",
    "                quadratic_firstorder_dir, quadratic_secondorder_dir = None\n",
    "            2) Quadratic:\n",
    "                linear_dir = None             \n",
    "                quadratic_firstorder_dir (3,) np array: Unit direction vector for first-order change along the fitted line.\n",
    "                quadratic_secondorder_dir (3,) np array: Unit direction vector for second-order change along the fitted line.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (\n",
    "            PchipInterpolator (function), pixel arc-length s_pixel → lane parameter t,\n",
    "            Sorted 2D pixel polyline (u,v) along increasing t (N,2) np array,\n",
    "            Cumulative 2D pixel arc-lengths (N,) np array,\n",
    "            Corresponding lane parameters (N,) np array,\n",
    "            Corresponding 3D points along the lane (N,3) np array\n",
    "        )\n",
    "    '''\n",
    "    # Convert to 2D to 3D\n",
    "    u = s1_points[:,0]; v = s1_points[:,1]; d = s1_points[:,2]\n",
    "    P3 = project_pixel_to_depth(u, img_height-v, d, fx, fy, cx, cy, distortion)\n",
    "\n",
    "    # Compute t_i for each 3D point\n",
    "    N = P3.shape[0]\n",
    "    t_vals = np.zeros(N, dtype=float)\n",
    "    max_range = np.linalg.norm(P3 - z_intercept, axis=1).max()\n",
    "    range_mult = config[\"projection_mapping\"][\"curve_optimizer_full_search_range_mult\"]\n",
    "    t_bounds = (-max_range*range_mult - 1.0, max_range*range_mult + 1.0)\n",
    "    for i in range(N):\n",
    "        P = P3[i]\n",
    "        if model_type == \"linear\":\n",
    "            t_vals[i] = compute_t_for_3d_point(\n",
    "                P, model_type, config, z_intercept,\n",
    "                linear_dir=linear_dir,\n",
    "                t_bounds=t_bounds\n",
    "            )\n",
    "        else:\n",
    "            t_vals[i] = compute_t_for_3d_point(\n",
    "                P, model_type, config, z_intercept,\n",
    "                quadratic_firstorder_dir=quadratic_firstorder_dir,\n",
    "                quadratic_secondorder_dir=quadratic_secondorder_dir,\n",
    "                t_bounds=t_bounds\n",
    "            )\n",
    "\n",
    "    # Sort by t to get along-lane order\n",
    "    order = np.argsort(t_vals)\n",
    "    t_sorted = t_vals[order]\n",
    "    s1_sorted = s1_points[order]\n",
    "    P3_sorted = P3[order]\n",
    "    pixel2d_sorted = s1_sorted[:, :2]\n",
    "\n",
    "    # compute s_pixel (cumulative pixel arc-length along the sorted S1 polyline)\n",
    "    s_pixel_sorted = cumulative_lengths_2d(pixel2d_sorted)\n",
    "\n",
    "    # Fit robust 1D mapping s_pixel to t\n",
    "    mask_valid = np.isfinite(s_pixel_sorted) & np.isfinite(t_sorted)\n",
    "    s_fit = s_pixel_sorted[mask_valid]\n",
    "    t_fit = t_sorted[mask_valid]\n",
    "    if len(s_fit) < 3:      # min number points needed for PCHIP\n",
    "        if log_specifics:\n",
    "            logger.error(\"Need >= 3 S1 points to learn mapping for this lane.\")\n",
    "        else:\n",
    "            print(\"Need >= 3 S1 points to learn mapping for this lane.\")\n",
    "        sys.exit(1)\n",
    "    # quick linear resid-based outlier removal (MAD)\n",
    "    A = np.vstack([s_fit, np.ones_like(s_fit)]).T\n",
    "    lin_coef, lin_intercept = np.linalg.lstsq(A, t_fit, rcond=None)[0]\n",
    "    resid = np.abs(t_fit - (lin_coef * s_fit + lin_intercept))\n",
    "    med = np.median(resid)\n",
    "    mad = np.median(np.abs(resid - med)) + 1e-9\n",
    "    outlier_mask = resid > (mad * config[\"projection_mapping\"][\"median_absolute_deviation_multiplier\"])\n",
    "    keep_mask = ~outlier_mask\n",
    "    if np.sum(keep_mask) < max(3, int(len(keep_mask) * config[\"projection_mapping\"][\"percent_min_points_remaining\"])):\n",
    "        keep_mask = np.ones_like(keep_mask, dtype=bool)\n",
    "    s_fit2 = s_fit[keep_mask]\n",
    "    t_fit2 = t_fit[keep_mask]\n",
    "\n",
    "    order2 = np.argsort(s_fit2)\n",
    "    s_fit_sorted = s_fit2[order2]\n",
    "    t_fit_sorted = t_fit2[order2]\n",
    "    # jitter duplicates if any\n",
    "    ds = np.diff(s_fit_sorted)\n",
    "    if np.any(ds == 0):\n",
    "        eps = 1e-8\n",
    "        for i in range(1, len(s_fit_sorted)):\n",
    "            if s_fit_sorted[i] <= s_fit_sorted[i-1]:\n",
    "                s_fit_sorted[i] = s_fit_sorted[i-1] + eps\n",
    "\n",
    "    interp_s_to_t = PchipInterpolator(s_fit_sorted, t_fit_sorted, extrapolate=True)\n",
    "\n",
    "    return interp_s_to_t, pixel2d_sorted, s_pixel_sorted, t_sorted, P3_sorted\n",
    "\n",
    "\n",
    "\n",
    "def predict_3d_for_s2_points(\n",
    "    s2_points,             \n",
    "    interp_s_to_t,           \n",
    "    pixel2d_polyline,       \n",
    "    model_type,\n",
    "    z_intercept,\n",
    "    linear_dir=None,\n",
    "    quadratic_firstorder_dir=None, quadratic_secondorder_dir=None\n",
    "):\n",
    "    '''\n",
    "    Predict 3D lane coordinates for new 2D pixel points using a previously learned\n",
    "    pixel-to-lane mapping and 3D lane model.\n",
    "\n",
    "    Args:\n",
    "        s2_points (N,2) np array: points (u, v) to predict 3D position.\n",
    "        interp_s_to_t (function): PchipInterpolator mapping pixel arc-length → lane parameter t\n",
    "            (see learn_pixel_to_t_mapping_for_lane()).\n",
    "        pixel2d_polyline (N,2) np array:  Sorted 2D pixel polyline (u,v) along increasing t\n",
    "        model_type (str): the used fitting model, either \"linear\" or \"quadratic\".\n",
    "        z_intercept (3,) np array: 3D point on plane for the y-intercept.\n",
    "\n",
    "        Either:\n",
    "            1) Linear:\n",
    "                linear_dir (3,) np array: Unit direction vector along the fitted line.\n",
    "                quadratic_firstorder_dir, quadratic_secondorder_dir = None\n",
    "            2) Quadratic:\n",
    "                linear_dir = None             \n",
    "                quadratic_firstorder_dir (3,) np array: Unit direction vector for first-order change along the fitted line.\n",
    "                quadratic_secondorder_dir (3,) np array: Unit direction vector for second-order change along the fitted line.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (\n",
    "            Predicted 3D coordinates of each pixel (N,3) pd array,\n",
    "            Corresponding lane parameter values along curve (N,) pd array,\n",
    "            Cumulative arc-length distances (px) along 2D polyline (N,) pd array\n",
    "        )\n",
    "    '''\n",
    "    M = s2_points.shape[0]\n",
    "    s_new = np.zeros(M, dtype=float)\n",
    "    for i, pt in enumerate(s2_points):\n",
    "        s_new[i], _, _, _, _ = project_point_to_2d_polyline(pt, pixel2d_polyline)\n",
    "\n",
    "    global minty_fresh\n",
    "    t_new = interp_s_to_t(s_new)\n",
    "    \n",
    "    if model_type == \"linear\":\n",
    "        X3 = lane_point_linear_model(z_intercept, linear_dir, t_new)\n",
    "    else:\n",
    "        X3 = lane_point_quadratic_model(z_intercept, quadratic_firstorder_dir, quadratic_secondorder_dir, t_new)\n",
    "    return X3, t_new, s_new\n",
    "\n",
    "\n",
    "\n",
    "def project_point_linear(P, z_intercept, linear_dir):\n",
    "    \"\"\"\n",
    "    Project a 3D point onto a linear lane model.\n",
    "\n",
    "    Args:\n",
    "        P (3,) np array: The 3D point to project.\n",
    "        z_intercept (3,) np array: 3D point on plane for the y-intercept.\n",
    "        linear_dir (3,) np array: Unit direction vector of the lane.\n",
    "\n",
    "    Returns: \n",
    "        tuple: (\n",
    "            t (float): Scalar lane coordinate along the line,\n",
    "            P_proj (3,) np array: The projected 3D point lying on the line\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    t = np.dot(P - z_intercept, linear_dir)\n",
    "    P_proj = z_intercept + t * linear_dir\n",
    "    return t, P_proj\n",
    "\n",
    "\n",
    "\n",
    "def project_point_quadratic(P, z_intercept, quadratic_firstorder_dir, quadratic_secondorder_dir):\n",
    "    \"\"\"\n",
    "    Project a 3D point onto a quadratic lane model.\n",
    "\n",
    "    Args:\n",
    "        P (3,) np array: The 3D point to project.\n",
    "        z_intercept (3,) np array: 3D point on plane for the y-intercept.\n",
    "        quadratic_firstorder_dir (3,) np array: Unit direction vector for first-order change along the fitted line.\n",
    "        quadratic_secondorder_dir (3,) np array: Unit direction vector for second-order change along the fitted line.\n",
    "\n",
    "    Returns: \n",
    "        tuple: (\n",
    "            t (float): Scalar lane coordinate along the quadratic curve,\n",
    "            P_proj (3,) np array: The projected 3D point lying on the quadratic curve\n",
    "        )\n",
    "    \"\"\"\n",
    "    r = z_intercept - P\n",
    "\n",
    "    # Coefficients of derivative cubic\n",
    "    A = 2 * np.dot(quadratic_secondorder_dir, quadratic_secondorder_dir)\n",
    "    B = 3 * np.dot(quadratic_firstorder_dir, quadratic_secondorder_dir)\n",
    "    C = 2 * np.dot(quadratic_firstorder_dir, quadratic_firstorder_dir) + np.dot(r, quadratic_secondorder_dir)\n",
    "    D = np.dot(r, quadratic_firstorder_dir)\n",
    "\n",
    "    # Solve cubic: A t³ + B t² + C t + D = 0\n",
    "    coeffs = [A, B, C, D]\n",
    "\n",
    "    roots = np.roots(coeffs)\n",
    "    real_roots = roots[np.isreal(roots)].real\n",
    "\n",
    "    # Evaluate error for all real roots\n",
    "    def error(t):\n",
    "        PT = z_intercept + t * quadratic_firstorder_dir + t * t * quadratic_secondorder_dir\n",
    "        return np.sum((P - PT)**2)\n",
    "\n",
    "    t_best = min(real_roots, key=error)\n",
    "    P_proj = z_intercept + t_best * quadratic_firstorder_dir + t_best * t_best * quadratic_secondorder_dir\n",
    "\n",
    "    return t_best, P_proj\n",
    "\n",
    "\n",
    "\n",
    "def project_points(\n",
    "    points, \n",
    "    model_type,\n",
    "    z_intercept,\n",
    "    linear_dir=None,\n",
    "    quadratic_firstorder_dir=None, \n",
    "    quadratic_secondorder_dir=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Project a set of 3D points onto a linear or quadratic lane model.\n",
    "\n",
    "    Args:\n",
    "        points (N,3) np array: Set of 3D points to project.\n",
    "        model_type (str): the used fitting model, either \"linear\" or \"quadratic\".\n",
    "        config (dict): Configuration file.\n",
    "        z_intercept (3,) np array: 3D point on plane for the y-intercept.\n",
    "\n",
    "        Either:\n",
    "            1) Linear:\n",
    "                linear_dir (3,) np array: Unit direction vector along the fitted line.\n",
    "                quadratic_firstorder_dir, quadratic_secondorder_dir = None\n",
    "            2) Quadratic:\n",
    "                linear_dir = None             \n",
    "                quadratic_firstorder_dir (3,) np array: Unit direction vector for first-order change along the fitted line.\n",
    "                quadratic_secondorder_dir (3,) np array: Unit direction vector for second-order change along the fitted line.\n",
    "\n",
    "    Returns:\n",
    "        t_list (N,) np array: Scalar lane coordinates for each point.\n",
    "        proj_list (N,3) np array: Projected points on the lane model.\n",
    "    \"\"\"\n",
    "    t_list = []\n",
    "    proj_list = []\n",
    "\n",
    "    if model_type == \"linear\":\n",
    "        for P in points:\n",
    "            t, Pp = project_point_linear(P, z_intercept, linear_dir)\n",
    "            t_list.append(t)\n",
    "            proj_list.append(Pp)\n",
    "    else:  # quadratic\n",
    "        for P in points:\n",
    "            t, Pp = project_point_quadratic(P, z_intercept, quadratic_firstorder_dir, quadratic_secondorder_dir)\n",
    "            t_list.append(t)\n",
    "            proj_list.append(Pp)\n",
    "\n",
    "    return np.array(t_list), np.array(proj_list)\n",
    "\n",
    "\n",
    "\n",
    "def correct_z_mismatched_points(\n",
    "    X3_pred,              \n",
    "    intrinsic_points,      \n",
    "    config,\n",
    "    model_type,\n",
    "    z_intercept,\n",
    "    linear_dir=None,\n",
    "    quadratic_firstorder_dir=None, \n",
    "    quadratic_secondorder_dir=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Correct inconsistent predicted 3D lane points using intrinsic depth references\n",
    "    and parametric projection where needed.\n",
    "\n",
    "    Args:\n",
    "        X3_pred (N,3) np array: Predicted 3D points.\n",
    "        intrinsic_points (N,3) np array: Reference 3D points derived from intrinsic projection.\n",
    "        config (dict): Configuration file.\n",
    "        model_type (str): the used fitting model, either \"linear\" or \"quadratic\".\n",
    "        config (dict): Configuration file.\n",
    "        z_intercept (3,) np array: 3D point on plane for the y-intercept.\n",
    "\n",
    "        Either:\n",
    "            1) Linear:\n",
    "                linear_dir (3,) np array: Unit direction vector along the fitted line.\n",
    "                quadratic_firstorder_dir, quadratic_secondorder_dir = None\n",
    "            2) Quadratic:\n",
    "                linear_dir = None             \n",
    "                quadratic_firstorder_dir (3,) np array: Unit direction vector for first-order change along the fitted line.\n",
    "                quadratic_secondorder_dir (3,) np array: Unit direction vector for second-order change along the fitted line.\n",
    "\n",
    "    Returns:\n",
    "        corrected_points (N,3) np array: Updated 3D points with potential replaced mismatched points.\n",
    "    \"\"\"\n",
    "    X3_pred = np.asarray(X3_pred)\n",
    "    intrinsic_points = np.asarray(intrinsic_points)\n",
    "    corrected_points = X3_pred.copy()\n",
    "\n",
    "    # Check z-range mismatch\n",
    "    max_deviation = config[\"depth_map\"][\"max_deviation_from_intr\"]\n",
    "    intrinsic_z = intrinsic_points[:, 2]\n",
    "    pred_z = X3_pred[:, 2]\n",
    "    lower = intrinsic_z * (1 - max_deviation)\n",
    "    upper = intrinsic_z * (1 + max_deviation)\n",
    "    mask_mismatch = (pred_z < lower) | (pred_z > upper)\n",
    "\n",
    "    if not np.any(mask_mismatch):\n",
    "        return corrected_points  # all points valid\n",
    "\n",
    "    # Process mismatched points\n",
    "    for _ in np.where(mask_mismatch)[0]:\n",
    "        idx = np.where(mask_mismatch)[0]\n",
    "        pts_to_project = intrinsic_points[idx]\n",
    "        _, projected_subset = project_points(\n",
    "            pts_to_project, \n",
    "            model_type, \n",
    "            z_intercept,\n",
    "            linear_dir,\n",
    "            quadratic_firstorder_dir, \n",
    "            quadratic_secondorder_dir\n",
    "        )\n",
    "        corrected_points[idx] = projected_subset\n",
    "\n",
    "    return corrected_points\n",
    "\n",
    "\n",
    "\n",
    "def save_pointcloud_sequence(arrays, base_folder, seq_id, sub_folder, file_id):\n",
    "    '''\n",
    "    Save a list of (N,3) np arrays of point clouds to .bin files in structured folders.\n",
    "\n",
    "    Directory structure:\n",
    "        base_folder/seq_id/sub_folder/<file_id>_<idx>.bin\n",
    "\n",
    "    Args:\n",
    "        arrays: list of (N,3) np arrays of point clouds (of individual lanes) to save.\n",
    "        base_folder, seq_id, sub_folder, file_id (str or int) build the directory structure.\n",
    "    '''\n",
    "    # Ensure directory exists\n",
    "    save_dir = os.path.join(base_folder, str(seq_id), sub_folder)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Loop and write each point cloud\n",
    "    for idx, points in enumerate(arrays):\n",
    "        if not isinstance(points, np.ndarray):\n",
    "            if log_specifics:\n",
    "                logger.error(f\"Item {idx} is not a numpy array.\")\n",
    "            else:\n",
    "                print(f\"Item {idx} is not a numpy array.\")\n",
    "            sys.exit(1)\n",
    "        if points.ndim != 2 or points.shape[1] != 3:\n",
    "            if log_specifics:\n",
    "                logger.error(f\"Item {idx} must be of shape (N,3), got {points.shape}\")\n",
    "            else:\n",
    "                print(f\"Item {idx} must be of shape (N,3), got {points.shape}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        file_path = os.path.join(save_dir, f\"{file_id}_{idx}.bin\")\n",
    "        points.astype(np.float32).tofile(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922f1e05",
   "metadata": {},
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b54d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cl_intrinsic(once_calibration_path, lane_detections_folder_path, seq_id, lidar_files):\n",
    "    '''\n",
    "    This function implements a pure-intrinsic approach: it projects 2D lane pixels\n",
    "    into 3D space using only the camera intrinsics, image size, distortion parameters,\n",
    "    and a fixed sensor height, without relying on LiDAR point correspondences or\n",
    "    ground plane estimation. Each lane in a LiDAR file produces one 3D output.\n",
    "\n",
    "    Run a full processing pipeline for a single solution on a set of LiDAR files.\n",
    "    This function iterates over each LiDAR file, performs any preprocessing steps, \n",
    "    applies the main processing routine to generate 3D outputs, and saves the results. \n",
    "\n",
    "    Args:\n",
    "        once_calibration_path (str): Path to the calibration file used for processing.\n",
    "        lane_detections_folder_path (str): Path to the folder containing the input 2D detection files.\n",
    "        seq_id (str or int): The run id / sequence id. \n",
    "        lidar_files (list of Path): List of LiDAR file paths to process.\n",
    "\n",
    "    Outputs:\n",
    "        The processed 3D results are saved to disk. Each lane is saved as a separate \n",
    "        .bin file, named as <file_id>_<lane_idx>.bin, under the output path specified \n",
    "        in the configuration file for this solution. The first lane in a file has index 0,\n",
    "        the next lane index 1, and so on.\n",
    "\n",
    "    Returns:\n",
    "        total_lane_count (int): the total count of lanes (attempted to) process.\n",
    "    '''\n",
    "    (\n",
    "        _,\n",
    "        _,\n",
    "        fx, fy, cx, cy,\n",
    "        img_width, img_height,\n",
    "        distortion\n",
    "    ) = load_calibration(once_calibration_path)\n",
    "    \n",
    "    total_files = len(lidar_files)\n",
    "    total_lane_count = 0\n",
    "\n",
    "    for idx, once_lidar_path in enumerate(tqdm(lidar_files, desc=f\"Processing cl intrinsic LiDAR files for {seq_id}\"), start=1):\n",
    "        ########## Run Check ##########\n",
    "        file_id = str(Path(once_lidar_path).stem)\n",
    "\n",
    "        if once_config[\"runtime\"][\"file_id\"] is not None:\n",
    "            if file_id != once_config[\"runtime\"][\"file_id\"]:\n",
    "                continue\n",
    "        elif not once_config[\"runtime\"][\"override_existing_output\"] and Path(os.path.join(once_config[\"output\"][\"base_path\"], seq_id, once_config[\"output\"][\"cl_intrinsic_path\"], file_id + \"_0.bin\")).exists():\n",
    "            logger.info(f\"File [{idx}/{total_files}]: File already processed: {file_id}\")\n",
    "            continue\n",
    "        else:\n",
    "            logger.info(f\"File [{idx}/{total_files}]: Processing:             {file_id}\")\n",
    "        ###############################\n",
    "\n",
    "\n",
    "\n",
    "        ########## Preprocessing ##########\n",
    "\n",
    "        ##### Load Input 2D Lanes #####\n",
    "        lanes = load_2d_lanes(os.path.join(lane_detections_folder_path, file_id + \".txt\"), once_config, img_width, img_height)\n",
    "        if lanes is None or len(lanes) == 0:\n",
    "            logger.error(f\"No lanes are found.\")\n",
    "            continue\n",
    "        ###################################\n",
    "\n",
    "\n",
    "\n",
    "        ########## Main Processing ##########\n",
    "        classic_pure_intrinsic = []\n",
    "        for lane_pixels in lanes:\n",
    "            lane_x = lane_pixels[:, 0]\n",
    "            lane_y = lane_pixels[:, 1]\n",
    "            classic_pure_intrinsic.append(pure_intrinsic_projection(lane_x, img_height-lane_y, fx, fy, cx, cy, once_config, distortion, once_config[\"ground_plane_ransac\"][\"camera_height\"]))\n",
    "            total_lane_count += 1\n",
    "        #####################################\n",
    "\n",
    "\n",
    "\n",
    "        ########## File Saving ##########\n",
    "        save_pointcloud_sequence( \n",
    "            classic_pure_intrinsic,\n",
    "            once_config[\"output\"][\"base_path\"],\n",
    "            seq_id,\n",
    "            once_config[\"output\"][\"cl_intrinsic_path\"],\n",
    "            file_id\n",
    "        )\n",
    "        #################################\n",
    "    \n",
    "    return total_lane_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d8f32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cl_intrinsic_groundplane(once_calibration_path, lane_detections_folder_path, seq_id, lidar_files):\n",
    "    '''\n",
    "    This function implements a ground-plane projection approach: it projects 2D lane pixels\n",
    "    into 3D space by first estimating the ground plane from the LiDAR points aligned in the\n",
    "    camera frame. Each pixel is then projected onto this estimated plane, rather than using\n",
    "    a fixed camera height. This approach accounts for the actual ground geometry in the scene,\n",
    "    producing one 3D output per lane in each LiDAR file.\n",
    "\n",
    "    Run a full processing pipeline for a single solution on a set of LiDAR files.\n",
    "    This function iterates over each LiDAR file, performs any preprocessing steps, \n",
    "    applies the main processing routine to generate 3D outputs, and saves the results. \n",
    "\n",
    "    Args:\n",
    "        once_calibration_path (str): Path to the calibration file used for processing.\n",
    "        lane_detections_folder_path (str): Path to the folder containing the input 2D detection files.\n",
    "        seq_id (str or int): The run id / sequence id. \n",
    "        lidar_files (list of Path): List of LiDAR file paths to process.\n",
    "\n",
    "    Outputs:\n",
    "        The processed 3D results are saved to disk. Each lane is saved as a separate \n",
    "        .bin file, named as <file_id>_<lane_idx>.bin, under the output path specified \n",
    "        in the configuration file for this solution. The first lane in a file has index 0,\n",
    "        the next lane index 1, and so on.\n",
    "\n",
    "    Returns:\n",
    "        total_lane_count (int): the total count of lanes (attempted to) process.\n",
    "    '''\n",
    "    (\n",
    "        T_camera_lidar,\n",
    "        _,\n",
    "        fx, fy, cx, cy,\n",
    "        img_width, img_height,\n",
    "        distortion\n",
    "    ) = load_calibration(once_calibration_path)\n",
    "    \n",
    "    total_files = len(lidar_files)\n",
    "    total_lane_count = 0\n",
    "\n",
    "    for idx, once_lidar_path in enumerate(tqdm(lidar_files, desc=f\"Processing cl intrinsic ground plane LiDAR files for {seq_id}\"), start=1):\n",
    "        ########## Run Check ##########\n",
    "        file_id = str(Path(once_lidar_path).stem)\n",
    "\n",
    "        if once_config[\"runtime\"][\"file_id\"] is not None:\n",
    "            if file_id != once_config[\"runtime\"][\"file_id\"]:\n",
    "                continue\n",
    "        elif not once_config[\"runtime\"][\"override_existing_output\"] and Path(os.path.join(once_config[\"output\"][\"base_path\"], seq_id, once_config[\"output\"][\"cl_intrinsic_ground_path\"], file_id + \"_0.bin\")).exists():\n",
    "            logger.info(f\"File [{idx}/{total_files}]: File already processed: {file_id}\")\n",
    "            continue\n",
    "        else:\n",
    "            logger.info(f\"File [{idx}/{total_files}]: Processing:             {file_id}\")\n",
    "        ###############################\n",
    "\n",
    "\n",
    "\n",
    "        ########## Preprocessing ##########\n",
    "\n",
    "        ##### Load Input 2D Lanes #####\n",
    "        lanes = load_2d_lanes(os.path.join(lane_detections_folder_path, file_id + \".txt\"), once_config, img_width, img_height)\n",
    "        if lanes is None or len(lanes) == 0:\n",
    "            logger.error(f\"No lanes are found.\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        ##### Calculate Ground Plane #####\n",
    "        lidar_points, _, _, _ = get_lidar_points(once_lidar_path)\n",
    "        \n",
    "        # Transform points from lidar to camera frame\n",
    "        points_lidar_hom = np.hstack((lidar_points, np.ones((lidar_points.shape[0], 1))))\n",
    "        points_lidar_camera = (T_camera_lidar @ points_lidar_hom.T).T[:,:3] # lidar -> camera\n",
    "        \n",
    "        # Get ground plane\n",
    "        prefiltered_points = prefilter_ground_plane(\n",
    "            points_lidar_camera, \n",
    "            -once_config[\"ground_plane_ransac\"][\"camera_height\"],\n",
    "            once_config[\"ground_plane_ransac\"][\"prefilter_band_half_width\"],\n",
    "            vertical_axis=1\n",
    "        )\n",
    "        plane_normal, plane_offset, _ = estimate_ground_plane(\n",
    "            prefiltered_points,\n",
    "            once_config,\n",
    "            vertical_axis=0\n",
    "        )\n",
    "        ###################################\n",
    "\n",
    "\n",
    "\n",
    "        ########## Main Processing ##########\n",
    "        classic_intrinsic_ground_plane = []\n",
    "        for lane_pixels in lanes:\n",
    "            lane_x = lane_pixels[:, 0]\n",
    "            lane_y = lane_pixels[:, 1]\n",
    "            intrinsic_points = pure_intrinsic_projection(lane_x, img_height - lane_y, fx, fy, cx, cy, once_config, distortion, None, plane_normal, plane_offset)\n",
    "            classic_intrinsic_ground_plane.append(intrinsic_points)\n",
    "            total_lane_count += 1\n",
    "        #####################################\n",
    "\n",
    "\n",
    "\n",
    "        ########## File Saving ##########\n",
    "        save_pointcloud_sequence( \n",
    "            classic_intrinsic_ground_plane,\n",
    "            once_config[\"output\"][\"base_path\"],\n",
    "            seq_id,\n",
    "            once_config[\"output\"][\"cl_intrinsic_ground_path\"],\n",
    "            file_id\n",
    "        )\n",
    "        #################################\n",
    "    \n",
    "    return total_lane_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c831b706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cl_depth(once_calibration_path, lane_detections_folder_path, seq_id, lidar_files):\n",
    "    '''\n",
    "    This function implements a LiDAR depth-based matching approach: it projects 2D lane pixels\n",
    "    into 3D space by first aligning LiDAR points to the camera frame and estimating the ground plane.\n",
    "    Only ground points within the camera's field of view are retained. These points are organized\n",
    "    into spatial bins corresponding to their 2D projections. For each lane pixel, the algorithm\n",
    "    searches the bins to find the nearest LiDAR point, expanding to neighboring bins if necessary.\n",
    "    The matched 3D point from LiDAR then becomes the 3D position of the pixel. This approach\n",
    "    directly leverages LiDAR depth to provide per-pixel 3D correspondences.\n",
    "\n",
    "    Run a full processing pipeline for a single solution on a set of LiDAR files.\n",
    "    This function iterates over each LiDAR file, performs any preprocessing steps, \n",
    "    applies the main processing routine to generate 3D outputs, and saves the results. \n",
    "\n",
    "    Args:\n",
    "        once_calibration_path (str): Path to the calibration file used for processing.\n",
    "        lane_detections_folder_path (str): Path to the folder containing the input 2D detection files.\n",
    "        seq_id (str or int): The run id / sequence id. \n",
    "        lidar_files (list of Path): List of LiDAR file paths to process.\n",
    "\n",
    "    Outputs:\n",
    "        The processed 3D results are saved to disk. Each lane is saved as a separate \n",
    "        .bin file, named as <file_id>_<lane_idx>.bin, under the output path specified \n",
    "        in the configuration file for this solution. The first lane in a file has index 0,\n",
    "        the next lane index 1, and so on.\n",
    "\n",
    "    Returns:\n",
    "        total_lane_count (int): the total count of lanes (attempted to) process.\n",
    "    '''\n",
    "    (\n",
    "        T_camera_lidar,\n",
    "        _,\n",
    "        fx, fy, cx, cy,\n",
    "        img_width, img_height,\n",
    "        distortion\n",
    "    ) = load_calibration(once_calibration_path)\n",
    "    \n",
    "    total_files = len(lidar_files)\n",
    "    total_lane_count = 0\n",
    "\n",
    "    for idx, once_lidar_path in enumerate(tqdm(lidar_files, desc=f\"Processing cl depth LiDAR files for {seq_id}\"), start=1):\n",
    "        ########## Run Check ##########\n",
    "        file_id = str(Path(once_lidar_path).stem)\n",
    "\n",
    "        if once_config[\"runtime\"][\"file_id\"] is not None:\n",
    "            if file_id != once_config[\"runtime\"][\"file_id\"]:\n",
    "                continue\n",
    "        elif not once_config[\"runtime\"][\"override_existing_output\"] and Path(os.path.join(once_config[\"output\"][\"base_path\"], seq_id, once_config[\"output\"][\"cl_depth_path\"], file_id + \"_0.bin\")).exists():\n",
    "            logger.info(f\"File [{idx}/{total_files}]: File already processed: {file_id}\")\n",
    "            continue\n",
    "        else:\n",
    "            logger.info(f\"File [{idx}/{total_files}]: Processing:             {file_id}\")\n",
    "        ###############################\n",
    "\n",
    "\n",
    "\n",
    "        ########## Preprocessing ##########\n",
    "\n",
    "        ##### Load Input 2D Lanes #####\n",
    "        lanes = load_2d_lanes(os.path.join(lane_detections_folder_path, file_id + \".txt\"), once_config, img_width, img_height)\n",
    "        if lanes is None or len(lanes) == 0:\n",
    "            logger.error(f\"No lanes are found.\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        ##### Calculate Ground Plane #####\n",
    "        lidar_points, _, _, _ = get_lidar_points(once_lidar_path)\n",
    "        \n",
    "        # Transform points from lidar to camera frame\n",
    "        points_lidar_hom = np.hstack((lidar_points, np.ones((lidar_points.shape[0], 1))))\n",
    "        points_lidar_camera = (T_camera_lidar @ points_lidar_hom.T).T[:,:3] # lidar -> camera\n",
    "\n",
    "        # Get ground plane\n",
    "        prefiltered_points = prefilter_ground_plane(\n",
    "            points_lidar_camera, \n",
    "            -once_config[\"ground_plane_ransac\"][\"camera_height\"],\n",
    "            once_config[\"ground_plane_ransac\"][\"prefilter_band_half_width\"],\n",
    "            vertical_axis=1\n",
    "        )\n",
    "        _, _, ground_plane_mask = estimate_ground_plane(\n",
    "            prefiltered_points,\n",
    "            once_config,\n",
    "            vertical_axis=0\n",
    "        )\n",
    "        ground_points = prefiltered_points[ground_plane_mask]\n",
    "\n",
    "        # Filter points into FOV\n",
    "        u_ground, v_ground, d_ground, sizes_sorted, ground_points_fov = filter_and_clip_points(\n",
    "            ground_points,\n",
    "            fx, fy, cx, cy, img_width, img_height,\n",
    "            once_config,\n",
    "            distortion=distortion\n",
    "        )\n",
    "\n",
    "        # Create depth based search\n",
    "        dpi = once_config[\"depth_map\"][\"dpi\"]\n",
    "        RADIUS_SCALE = dpi / (72 * np.sqrt(np.pi))      # Convert dpi from point to px, set to radius\n",
    "        cell_size = once_config[\"depth_map\"][\"lidar_point_size_max\"] * RADIUS_SCALE\n",
    "        r = (sizes_sorted * RADIUS_SCALE)\n",
    "        spatial_bins = create_spatial_bins(u_ground, v_ground, r, d_ground, ground_points_fov, cell_size)\n",
    "        ###################################\n",
    "\n",
    "\n",
    "\n",
    "        ########## Main Processing ##########\n",
    "        classic_pure_depth = []\n",
    "        for lane_pixels in lanes:\n",
    "            lane_x = lane_pixels[:, 0]\n",
    "            lane_y = lane_pixels[:, 1]\n",
    "\n",
    "            matched_points = []\n",
    "            for i in range(len(lane_x)):\n",
    "                _, _, _, pt = query_nearest_depth_from_bins(spatial_bins, lane_x[i], lane_y[i], bin_search_range=None) #search infinitely\n",
    "                matched_points.append(pt)\n",
    "            classic_pure_depth.append(np.array(matched_points))\n",
    "            \n",
    "            total_lane_count += 1\n",
    "        #####################################\n",
    "\n",
    "\n",
    "\n",
    "        ########## File Saving ##########\n",
    "        save_pointcloud_sequence( \n",
    "            classic_pure_depth,\n",
    "            once_config[\"output\"][\"base_path\"],\n",
    "            seq_id,\n",
    "            once_config[\"output\"][\"cl_depth_path\"],\n",
    "            file_id\n",
    "        )\n",
    "        #################################\n",
    "\n",
    "\n",
    "    return total_lane_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799213f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cl_intrinsic_depth(once_calibration_path, lane_detections_folder_path, seq_id, lidar_files):\n",
    "    '''\n",
    "    This function implements a fused intrinsic + LiDAR matching approach: it projects 2D lane pixels\n",
    "    into 3D space by first aligning LiDAR points to the camera frame and estimating the ground plane.\n",
    "    Only ground points within the camera's field of view are retained and organized into spatial bins.\n",
    "    For each lane pixel, the nearest LiDAR point is found in the bins, and its depth along the\n",
    "    camera viewing ray is extracted. The 3D point is then computed using the original pixel coordinates\n",
    "    with this matched depth, combining the accuracy of LiDAR depth with the stability of intrinsic-based\n",
    "    projection. Each lane in a LiDAR file produces one 3D output.\n",
    "\n",
    "    Run a full processing pipeline for a single solution on a set of LiDAR files.\n",
    "    This function iterates over each LiDAR file, performs any preprocessing steps, \n",
    "    applies the main processing routine to generate 3D outputs, and saves the results. \n",
    "\n",
    "    Args:\n",
    "        once_calibration_path (str): Path to the calibration file used for processing.\n",
    "        lane_detections_folder_path (str): Path to the folder containing the input 2D detection files.\n",
    "        seq_id (str or int): The run id / sequence id. \n",
    "        lidar_files (list of Path): List of LiDAR file paths to process.\n",
    "\n",
    "    Outputs:\n",
    "        The processed 3D results are saved to disk. Each lane is saved as a separate \n",
    "        .bin file, named as <file_id>_<lane_idx>.bin, under the output path specified \n",
    "        in the configuration file for this solution. The first lane in a file has index 0,\n",
    "        the next lane index 1, and so on.\n",
    "\n",
    "    Returns:\n",
    "        total_lane_count (int): the total count of lanes (attempted to) process.\n",
    "    '''\n",
    "    (\n",
    "        T_camera_lidar,\n",
    "        _,\n",
    "        fx, fy, cx, cy,\n",
    "        img_width, img_height,\n",
    "        distortion\n",
    "    ) = load_calibration(once_calibration_path)\n",
    "    \n",
    "    total_files = len(lidar_files)\n",
    "    total_lane_count = 0\n",
    "\n",
    "    for idx, once_lidar_path in enumerate(tqdm(lidar_files, desc=f\"Processing cl intrinsic + depth LiDAR files for {seq_id}\"), start=1):\n",
    "        ########## Run Check ##########\n",
    "        file_id = str(Path(once_lidar_path).stem)\n",
    "\n",
    "        if once_config[\"runtime\"][\"file_id\"] is not None:\n",
    "            if file_id != once_config[\"runtime\"][\"file_id\"]:\n",
    "                continue\n",
    "        elif not once_config[\"runtime\"][\"override_existing_output\"] and Path(os.path.join(once_config[\"output\"][\"base_path\"], seq_id, once_config[\"output\"][\"cl_intrinsic_depth_path\"], file_id + \"_0.bin\")).exists():\n",
    "            logger.info(f\"File [{idx}/{total_files}]: File already processed: {file_id}\")\n",
    "            continue\n",
    "        else:\n",
    "            logger.info(f\"File [{idx}/{total_files}]: Processing:             {file_id}\")\n",
    "        ###############################\n",
    "\n",
    "\n",
    "\n",
    "        ########## Preprocessing ##########\n",
    "\n",
    "        ##### Load Input 2D Lanes #####\n",
    "        lanes = load_2d_lanes(os.path.join(lane_detections_folder_path, file_id + \".txt\"), once_config, img_width, img_height)\n",
    "        if lanes is None or len(lanes) == 0:\n",
    "            logger.error(f\"No lanes are found.\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        ##### Calculate Ground Plane #####\n",
    "        lidar_points, _, _, _ = get_lidar_points(once_lidar_path)\n",
    "        \n",
    "        # Transform points from lidar to camera frame\n",
    "        points_lidar_hom = np.hstack((lidar_points, np.ones((lidar_points.shape[0], 1))))\n",
    "        points_lidar_camera = (T_camera_lidar @ points_lidar_hom.T).T[:,:3] # lidar -> camera\n",
    "\n",
    "        # Get ground plane\n",
    "        prefiltered_points = prefilter_ground_plane(\n",
    "            points_lidar_camera, \n",
    "            -once_config[\"ground_plane_ransac\"][\"camera_height\"],\n",
    "            once_config[\"ground_plane_ransac\"][\"prefilter_band_half_width\"],\n",
    "            vertical_axis=1\n",
    "        )\n",
    "        _, _, ground_plane_mask = estimate_ground_plane(\n",
    "            prefiltered_points,\n",
    "            once_config,\n",
    "            vertical_axis=0\n",
    "        )\n",
    "        ground_points = prefiltered_points[ground_plane_mask]\n",
    "\n",
    "        # Filter points into FOV\n",
    "        u_ground, v_ground, d_ground, sizes_sorted, ground_points_fov = filter_and_clip_points(\n",
    "            ground_points,\n",
    "            fx, fy, cx, cy, img_width, img_height,\n",
    "            once_config,\n",
    "            distortion=distortion\n",
    "        )\n",
    "\n",
    "        # Create depth based search\n",
    "        dpi = once_config[\"depth_map\"][\"dpi\"]\n",
    "        RADIUS_SCALE = dpi / (72 * np.sqrt(np.pi))      # Convert dpi from point to px, set to radius\n",
    "        cell_size = once_config[\"depth_map\"][\"lidar_point_size_max\"] * RADIUS_SCALE\n",
    "        r = (sizes_sorted * RADIUS_SCALE)\n",
    "        spatial_bins = create_spatial_bins(u_ground, v_ground, r, d_ground, ground_points_fov, cell_size)\n",
    "        ###################################\n",
    "\n",
    "\n",
    "\n",
    "        ########## Main Processing ##########\n",
    "        classic_combined_intrinsic_depth = []\n",
    "        for lane_pixels in lanes:\n",
    "            lane_x = lane_pixels[:, 0]\n",
    "            lane_y = lane_pixels[:, 1]\n",
    "\n",
    "            udv_point = []\n",
    "            for i in range(len(lane_x)):\n",
    "                _, _, depth, _ = query_nearest_depth_from_bins(spatial_bins, lane_x[i], lane_y[i], bin_search_range=None) #search infinitely\n",
    "                udv_point.append(np.array([lane_x[i], lane_y[i], depth]))\n",
    "            udv_point = np.array(udv_point)\n",
    "            classic_combined_intrinsic_depth.append(project_pixel_to_depth(udv_point[:,0], img_height - udv_point[:,1], udv_point[:,2], fx, fy, cx, cy, distortion))\n",
    "            \n",
    "            total_lane_count += 1\n",
    "        #####################################\n",
    "\n",
    "\n",
    "\n",
    "        ########## File Saving ##########\n",
    "        save_pointcloud_sequence( \n",
    "            classic_combined_intrinsic_depth,\n",
    "            once_config[\"output\"][\"base_path\"],\n",
    "            seq_id,\n",
    "            once_config[\"output\"][\"cl_intrinsic_depth_path\"],\n",
    "            file_id\n",
    "        )\n",
    "        #################################\n",
    "    \n",
    "    return total_lane_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5b2748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_thesis_solution(once_calibration_path, lane_detections_folder_path, seq_id, lidar_files):\n",
    "    '''\n",
    "    This function implements a custom lane reconstruction approach that fuses intrinsic projection,\n",
    "    LiDAR depth, and geometric line fitting to produce accurate 3D lane points. LiDAR points are first\n",
    "    aligned to the camera and filtered to retain only ground points within the camera's field of view.\n",
    "    A ground plane is estimated, and the 2D lane anchors are projected onto it using a pure-intrinsic\n",
    "    method. A linear or quadratic 3D line is fit through these projected points to represent the lane.\n",
    "    \n",
    "    For each set of consecutive lane anchors, all pixels in between are evaluated: the nearest LiDAR\n",
    "    point is searched using spatial bins, and the corresponding 2D match is projected onto the fitted\n",
    "    lane line. This produces accurate depth and 3D correspondences for each pixel. End segments of the\n",
    "    lane are processed with a larger search radius to avoid over-extrapolation.\n",
    "    \n",
    "    A mapping between pixel-space arc length and lane distance is then learned (using a PCHIP\n",
    "    interpolator), allowing the original 3D lane anchors to be projected along the fitted line according\n",
    "    to this mapping. Each lane in a LiDAR file produces one set of 3D output points.\n",
    "\n",
    "    Run a full processing pipeline for a single solution on a set of LiDAR files.\n",
    "    This function iterates over each LiDAR file, performs any preprocessing steps, \n",
    "    applies the main processing routine to generate 3D outputs, and saves the results. \n",
    "\n",
    "    Args:\n",
    "        once_calibration_path (str): Path to the calibration file used for processing.\n",
    "        lane_detections_folder_path (str): Path to the folder containing the input 2D detection files.\n",
    "        seq_id (str or int): The run id / sequence id. \n",
    "        lidar_files (list of Path): List of LiDAR file paths to process.\n",
    "\n",
    "    Outputs:\n",
    "        The processed 3D results are saved to disk. Each lane is saved as a separate \n",
    "        .bin file, named as <file_id>_<lane_idx>.bin, under the output path specified \n",
    "        in the configuration file for this solution. The first lane in a file has index 0,\n",
    "        the next lane index 1, and so on.\n",
    "\n",
    "    Returns:\n",
    "        total_lane_count (int): the total count of lanes (attempted to) process.\n",
    "    '''\n",
    "    (\n",
    "        T_camera_lidar,\n",
    "        _,\n",
    "        fx, fy, cx, cy,\n",
    "        img_width, img_height,\n",
    "        distortion\n",
    "    ) = load_calibration(once_calibration_path)\n",
    "    \n",
    "    total_files = len(lidar_files)\n",
    "    total_lane_count = 0\n",
    "\n",
    "    dpi = once_config[\"depth_map\"][\"dpi\"]\n",
    "    RADIUS_SCALE = dpi / (72 * np.sqrt(np.pi))      # Convert dpi from point to px, set to radius\n",
    "    cell_size = once_config[\"depth_map\"][\"lidar_point_size_max\"] * RADIUS_SCALE\n",
    "    max_search_range = once_config[\"depth_map\"][\"unmatched_max_search_range\"]\n",
    "    logger.info(f\"Max search range: {cell_size * 2 * max_search_range}\")\n",
    "\n",
    "\n",
    "    for idx, once_lidar_path in enumerate(tqdm(lidar_files, desc=f\"Processing thesis solution LiDAR files for {seq_id}\"), start=1):\n",
    "        ########## Run Check ##########\n",
    "        file_id = str(Path(once_lidar_path).stem)\n",
    "\n",
    "        if once_config[\"runtime\"][\"file_id\"] is not None:\n",
    "            if file_id != once_config[\"runtime\"][\"file_id\"]:\n",
    "                continue\n",
    "        elif not once_config[\"runtime\"][\"override_existing_output\"] and Path(os.path.join(once_config[\"output\"][\"base_path\"], seq_id, once_config[\"output\"][\"thesis_solution_path\"], file_id + \"_0.bin\")).exists():\n",
    "            logger.info(f\"File [{idx}/{total_files}]: File already processed: {file_id}\")\n",
    "            continue\n",
    "        else:\n",
    "            logger.info(f\"File [{idx}/{total_files}]: Processing:             {file_id}\")\n",
    "        ###############################\n",
    "\n",
    "\n",
    "\n",
    "        ########## Preprocessing ##########\n",
    "\n",
    "        ##### Load Input 2D Lanes #####\n",
    "        lanes = load_2d_lanes(os.path.join(lane_detections_folder_path, file_id + \".txt\"), once_config, img_width, img_height)\n",
    "        if lanes is None or len(lanes) == 0:\n",
    "            logger.error(f\"No lanes are found.\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        ##### Calculate Ground Plane #####\n",
    "        lidar_points, _, _, _ = get_lidar_points(once_lidar_path)\n",
    "        \n",
    "        # Transform points from lidar to camera frame\n",
    "        points_lidar_hom = np.hstack((lidar_points, np.ones((lidar_points.shape[0], 1))))\n",
    "        points_lidar_camera = (T_camera_lidar @ points_lidar_hom.T).T[:,:3] # lidar -> camera\n",
    "\n",
    "        # Get ground plane\n",
    "        prefiltered_points = prefilter_ground_plane(\n",
    "            points_lidar_camera, \n",
    "            -once_config[\"ground_plane_ransac\"][\"camera_height\"],\n",
    "            once_config[\"ground_plane_ransac\"][\"prefilter_band_half_width\"],\n",
    "            vertical_axis=1\n",
    "        )\n",
    "        plane_normal, plane_offset, ground_plane_mask = estimate_ground_plane(\n",
    "            prefiltered_points,\n",
    "            once_config,\n",
    "            vertical_axis=0\n",
    "        )\n",
    "        ground_points = prefiltered_points[ground_plane_mask]\n",
    "\n",
    "        # Filter points into FOV\n",
    "        u_ground, v_ground, d_ground, sizes_sorted, ground_points_fov = filter_and_clip_points(\n",
    "            ground_points,\n",
    "            fx, fy, cx, cy, img_width, img_height,\n",
    "            once_config,\n",
    "            distortion=distortion\n",
    "        )\n",
    "\n",
    "        # Create depth based search\n",
    "        r = (sizes_sorted * RADIUS_SCALE)\n",
    "        spatial_bins = create_spatial_bins(u_ground, v_ground, r, d_ground, ground_points_fov, cell_size)\n",
    "\n",
    "\n",
    "        ##### Depth Matching #####\n",
    "        fitted_line_precalc_values = fit_line_on_plane_precalc(plane_normal, plane_offset) # optimization, calc outside of for loop\n",
    "        \n",
    "        step = min(r) * once_config[\"depth_map\"][\"lane_density_step_fraction\"]\n",
    "        min_spacing = max(r) * once_config[\"depth_map\"][\"min_spacing_fraction\"]\n",
    "        ###################################\n",
    "\n",
    "\n",
    "\n",
    "        ########## Main Processing ##########\n",
    "        output_positions = []\n",
    "        for lane_pixels in lanes:\n",
    "            lane_x = lane_pixels[:, 0]\n",
    "            lane_y = lane_pixels[:, 1]\n",
    "\n",
    "\n",
    "            ############# Intrinsics & Unit Vec #############\n",
    "            intrinsic_points = pure_intrinsic_projection(lane_x, img_height - lane_y, fx, fy, cx, cy, once_config, distortion, None, plane_normal, plane_offset)\n",
    "\n",
    "            model_type, model_params = fit_line_on_plane(\n",
    "                intrinsic_points, \n",
    "                fitted_line_precalc_values, \n",
    "                curvature_threshold=once_config[\"projection_mapping\"][\"snap_curvature_threshold\"]\n",
    "            )\n",
    "            #################################################\n",
    "           \n",
    "\n",
    "\n",
    "            ############# Depth Matching #############\n",
    "            valid_depths = []\n",
    "            valid_points = []\n",
    "            matched_points = []\n",
    "            seen = set()\n",
    "            x_prev, y_prev = None, None\n",
    "            for i in range(len(lane_x) - 1):\n",
    "                x0, y0 = lane_x[i], lane_y[i]\n",
    "                x1, y1 = lane_x[i + 1], lane_y[i + 1]\n",
    "                dx, dy = x1 - x0, y1 - y0\n",
    "                dist = np.hypot(dx, dy)\n",
    "                num_steps = max(1, int(dist / step))\n",
    "                t_vals = np.linspace(0, 1, num_steps)\n",
    "                xs = x0 + t_vals * dx\n",
    "                ys = y0 + t_vals * dy\n",
    "\n",
    "                for x, y in zip(xs, ys):\n",
    "                    if x_prev is not None and np.hypot(x - x_prev, y - y_prev) < min_spacing:\n",
    "                        continue\n",
    "                    x_prev, y_prev = x, y\n",
    "\n",
    "                    if not (0 <= x < img_width and 0 <= y < img_height):\n",
    "                        continue\n",
    "\n",
    "                    x2, y2, depth, pt = query_depth_from_bins(spatial_bins, x, y, get_all_depths=False, prioritize_closest=True)\n",
    "                    if depth is None:\n",
    "                        continue\n",
    "\n",
    "                    diff_eps = once_config[\"depth_map\"][\"diff_eps\"]\n",
    "                    x2r, y2r = round(x2 / diff_eps), round(y2 / diff_eps)\n",
    "                    if (x2r, y2r) in seen:\n",
    "                        continue\n",
    "                    seen.add((x2r, y2r))\n",
    "\n",
    "                    denom = dx * dx + dy * dy\n",
    "                    if denom == 0:\n",
    "                        xi, yi = x0, y0\n",
    "                    else:\n",
    "                        t = ((x2 - x0) * dx + (y2 - y0) * dy) / denom\n",
    "                        t = np.clip(t, 0.0, 1.0)\n",
    "                        xi, yi = x0 + t * dx, y0 + t * dy\n",
    "\n",
    "                    valid_points.append((xi, yi))\n",
    "                    valid_depths.append(depth)\n",
    "                    matched_points.append(pt)\n",
    "\n",
    "            if len(valid_points) > 0:\n",
    "                min_valid_y = valid_points[-1][1]\n",
    "                max_valid_y = valid_points[0][1]\n",
    "\n",
    "                # --- FRONT END: anchors before first valid match ---\n",
    "                front_indices = np.where(lane_y < min_valid_y)[0]\n",
    "                if len(front_indices) > 0:\n",
    "                    for i in front_indices:\n",
    "                        xq, yq = lane_x[i], lane_y[i]\n",
    "                        xq2, yq2, depth, pt = query_nearest_depth_from_bins(\n",
    "                            spatial_bins, \n",
    "                            xq, yq, \n",
    "                            bin_search_range=once_config[\"depth_map\"][\"unmatched_max_search_range\"]\n",
    "                        )\n",
    "                        if depth is None:\n",
    "                            continue\n",
    "\n",
    "                        # Determine projection reference\n",
    "                        if i == 0:\n",
    "                            # Project onto first segment (0→1)\n",
    "                            x0, y0 = lane_x[0], lane_y[0]\n",
    "                            x1, y1 = lane_x[1], lane_y[1]\n",
    "                        else:\n",
    "                            # Project onto segment (i-1→i)\n",
    "                            x0, y0 = lane_x[i - 1], lane_y[i - 1]\n",
    "                            x1, y1 = lane_x[i], lane_y[i]\n",
    "\n",
    "                        vx, vy = x1 - x0, y1 - y0\n",
    "                        denom = vx * vx + vy * vy\n",
    "                        if denom == 0:\n",
    "                            xi, yi = x0, y0\n",
    "                        else:\n",
    "                            t = ((xq2 - x0) * vx + (yq2 - y0) * vy) / denom\n",
    "                            t = np.clip(t, 0.0, 1.0)\n",
    "                            xi, yi = x0 + t * vx, y0 + t * vy\n",
    "\n",
    "                        valid_points = np.vstack([valid_points, [xi, yi]])\n",
    "                        depth = verify_with_intrinsic_projection(xi, yi, fx, fy, cx, cy, once_config, plane_normal, plane_offset, depth, distortion)\n",
    "                        valid_depths = np.append(valid_depths, depth)\n",
    "                        matched_points.append(pt)\n",
    "\n",
    "                # --- BACK END: anchors after last valid match ---\n",
    "                back_indices = np.where(lane_y > max_valid_y)[0]\n",
    "                if len(back_indices) > 0:\n",
    "                    for i in back_indices:\n",
    "                        xq, yq = lane_x[i], lane_y[i]\n",
    "                        xq2, yq2, depth, pt = query_nearest_depth_from_bins(\n",
    "                            spatial_bins, \n",
    "                            xq, yq, \n",
    "                            bin_search_range=once_config[\"depth_map\"][\"unmatched_max_search_range\"]\n",
    "                        )\n",
    "                        if depth is None:\n",
    "                            continue\n",
    "\n",
    "                        # Determine projection reference\n",
    "                        if i == len(lane_x) - 1:\n",
    "                            # Project onto last segment (-2→-1)\n",
    "                            x0, y0 = lane_x[-2], lane_y[-2]\n",
    "                            x1, y1 = lane_x[-1], lane_y[-1]\n",
    "                        else:\n",
    "                            # Project onto segment (i→i+1)\n",
    "                            x0, y0 = lane_x[i], lane_y[i]\n",
    "                            x1, y1 = lane_x[i + 1], lane_y[i + 1]\n",
    "\n",
    "                        vx, vy = x1 - x0, y1 - y0\n",
    "                        denom = vx * vx + vy * vy\n",
    "                        if denom == 0:\n",
    "                            xi, yi = x0, y0\n",
    "                        else:\n",
    "                            t = ((xq2 - x0) * vx + (yq2 - y0) * vy) / denom\n",
    "                            t = np.clip(t, 0.0, 1.0)\n",
    "                            xi, yi = x0 + t * vx, y0 + t * vy\n",
    "\n",
    "                        valid_points = np.vstack([valid_points, [xi, yi]])\n",
    "                        depth = verify_with_intrinsic_projection(xi, yi, fx, fy, cx, cy, once_config, plane_normal, plane_offset, depth, distortion)\n",
    "                        valid_depths = np.append(valid_depths, depth)\n",
    "                        matched_points.append(pt)\n",
    "\n",
    "                valid_points = np.array(valid_points)\n",
    "                valid_depths = np.array(valid_depths)\n",
    "                depth_match_points = np.hstack([valid_points, valid_depths.reshape(-1,1)])\n",
    "            else:\n",
    "                depth_match_points = []\n",
    "            ##########################################\n",
    "        \n",
    "\n",
    "\n",
    "            ############# 2D to 3D Matching #############\n",
    "            if len(depth_match_points) > 2:\n",
    "                # Learn mapping\n",
    "                interp_s_to_t, pixel2d_sorted, _, _, _ = learn_pixel_to_t_mapping_for_lane(\n",
    "                    depth_match_points,\n",
    "                    model_type,\n",
    "                    once_config,\n",
    "                    model_params[\"z_intercept\"], \n",
    "                    img_height, fx, fy, cx, cy, distortion,\n",
    "                    linear_dir=model_params.get(\"line_dir\"),                            # None if quadratic\n",
    "                    quadratic_firstorder_dir=model_params.get(\"quad_firstorder_dir\"),   # None if linear\n",
    "                    quadratic_secondorder_dir=model_params.get(\"quad_secondorder_dir\")  # None if linear\n",
    "                )\n",
    "\n",
    "                # Predict 3D for new pixels\n",
    "                X3_pred, _, _ = predict_3d_for_s2_points(\n",
    "                    lane_pixels, interp_s_to_t, pixel2d_sorted, model_type, \n",
    "                    model_params[\"z_intercept\"],\n",
    "                    linear_dir=model_params.get(\"line_dir\"),                            # None if quadratic\n",
    "                    quadratic_firstorder_dir=model_params.get(\"quad_firstorder_dir\"),   # None if linear\n",
    "                    quadratic_secondorder_dir=model_params.get(\"quad_secondorder_dir\")  # None if linear\n",
    "                )\n",
    "                X3_pred = correct_z_mismatched_points(\n",
    "                    X3_pred, \n",
    "                    intrinsic_points,\n",
    "                    once_config, \n",
    "                    model_type, \n",
    "                    model_params[\"z_intercept\"],\n",
    "                    linear_dir=model_params.get(\"line_dir\"),                            # None if quadratic\n",
    "                    quadratic_firstorder_dir=model_params.get(\"quad_firstorder_dir\"),   # None if linear\n",
    "                    quadratic_secondorder_dir=model_params.get(\"quad_secondorder_dir\")  # None if linear\n",
    "                )\n",
    "            else:\n",
    "                X3_pred = intrinsic_points\n",
    "                logger.warning(f\"Not enough point-lidar matches to perform mapping [{len(depth_match_points)}/3]. Defaulting to intrinsic projection.\")\n",
    "\n",
    "            output_positions.append(X3_pred)\n",
    "            #############################################\n",
    "            \n",
    "\n",
    "            total_lane_count += 1\n",
    "        #####################################\n",
    "\n",
    "\n",
    "\n",
    "        ########## File Saving ##########\n",
    "        save_pointcloud_sequence( \n",
    "            output_positions,\n",
    "            once_config[\"output\"][\"base_path\"],\n",
    "            seq_id,\n",
    "            once_config[\"output\"][\"thesis_solution_path\"],\n",
    "            file_id\n",
    "        )\n",
    "        #################################\n",
    "    \n",
    "    return total_lane_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452465d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_solutions(once_calibration_path, lane_detections_folder_path, seq_id, lidar_files):\n",
    "    '''\n",
    "    This function implements all solutions simultaneously (if that solution's config run is on):\n",
    "        - Pure intrinsic\n",
    "        - Intrinsic + ground plane\n",
    "        - Lidar matching\n",
    "        - Intrinsic + Lidar matching\n",
    "        - Thesis code\n",
    "    This function is rewritten to be optimal in sharing parameters between solutions when \n",
    "    available. This solution is always more optimal to run, but it does not give accurate \n",
    "    logging timing metrics (because it cannot differentiate runtime calls from each solution).\n",
    "    For information on each individual solution, refer to that solution's function.\n",
    "\n",
    "    This function checks if the output of thesis_code exists to determine whether to re-make\n",
    "    a given set of input files. IE this checks if a file with <file_id> exists in thesis \n",
    "    output, to determine if the files need to be generated.\n",
    "\n",
    "    Run a full processing pipeline for a single solution on a set of LiDAR files.\n",
    "    This function iterates over each LiDAR file, performs any preprocessing steps, \n",
    "    applies the main processing routine to generate 3D outputs, and saves the results. \n",
    "\n",
    "    Args:\n",
    "        once_calibration_path (str): Path to the calibration file used for processing.\n",
    "        lane_detections_folder_path (str): Path to the folder containing the input 2D detection files.\n",
    "        seq_id (str or int): The run id / sequence id. \n",
    "        lidar_files (list of Path): List of LiDAR file paths to process.\n",
    "\n",
    "    Outputs:\n",
    "        The processed 3D results are saved to disk. Each lane is saved as a separate \n",
    "        .bin file, named as <file_id>_<lane_idx>.bin, under the output path specified \n",
    "        in the configuration file for this solution. The first lane in a file has index 0,\n",
    "        the next lane index 1, and so on.\n",
    "\n",
    "    Returns:\n",
    "        total_lane_count (int): the total count of lanes (attempted to) process.\n",
    "    '''\n",
    "    (\n",
    "        T_camera_lidar,\n",
    "        _,\n",
    "        fx, fy, cx, cy,\n",
    "        img_width, img_height,\n",
    "        distortion\n",
    "    ) = load_calibration(once_calibration_path)\n",
    "    \n",
    "    total_files = len(lidar_files)\n",
    "    total_lane_count = 0\n",
    "\n",
    "    dpi = once_config[\"depth_map\"][\"dpi\"]\n",
    "    RADIUS_SCALE = dpi / (72 * np.sqrt(np.pi))      # Convert dpi from point to px, set to radius\n",
    "    cell_size = once_config[\"depth_map\"][\"lidar_point_size_max\"] * RADIUS_SCALE\n",
    "    max_search_range = once_config[\"depth_map\"][\"unmatched_max_search_range\"]\n",
    "    logger.info(f\"Max search range: {cell_size * 2 *max_search_range}\")\n",
    "\n",
    "\n",
    "    for idx, once_lidar_path in enumerate(tqdm(lidar_files, desc=f\"Processing all solutions LiDAR files for {seq_id}\"), start=1):\n",
    "        ########## Run Check ##########\n",
    "        file_id = str(Path(once_lidar_path).stem)\n",
    "\n",
    "        if once_config[\"runtime\"][\"file_id\"] is not None:\n",
    "            if file_id != once_config[\"runtime\"][\"file_id\"]:\n",
    "                continue\n",
    "        elif not once_config[\"runtime\"][\"override_existing_output\"] and Path(os.path.join(once_config[\"output\"][\"base_path\"], seq_id, once_config[\"output\"][\"thesis_solution_path\"], file_id + \"_0.bin\")).exists():\n",
    "            logger.info(f\"File [{idx}/{total_files}]: File already processed: {file_id}\")\n",
    "            continue\n",
    "        else:\n",
    "            logger.info(f\"File [{idx}/{total_files}]: Processing:             {file_id}\")\n",
    "        ###############################\n",
    "\n",
    "\n",
    "\n",
    "        ########## Preprocessing ##########\n",
    "\n",
    "        ##### Load input 2D lanes #####\n",
    "        lanes = load_2d_lanes(os.path.join(lane_detections_folder_path, file_id + \".txt\"), once_config, img_width, img_height)\n",
    "        if lanes is None or len(lanes) == 0:\n",
    "            logger.error(f\"No lanes are found.\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        ##### Calculate Ground Plane #####\n",
    "        lidar_points, _, _, _ = get_lidar_points(once_lidar_path)\n",
    "\n",
    "        # Transform points from lidar to camera frame\n",
    "        points_lidar_hom = np.hstack((lidar_points, np.ones((lidar_points.shape[0], 1))))\n",
    "        points_lidar_camera = (T_camera_lidar @ points_lidar_hom.T).T[:,:3] # lidar -> camera\n",
    "\n",
    "        # Get ground plane\n",
    "        prefiltered_points = prefilter_ground_plane(\n",
    "            points_lidar_camera, \n",
    "            -once_config[\"ground_plane_ransac\"][\"camera_height\"],\n",
    "            once_config[\"ground_plane_ransac\"][\"prefilter_band_half_width\"],\n",
    "            vertical_axis=1\n",
    "        )\n",
    "        plane_normal, plane_offset, ground_plane_mask = estimate_ground_plane(\n",
    "            prefiltered_points,\n",
    "            once_config,\n",
    "            vertical_axis=0\n",
    "        )\n",
    "        ground_points = prefiltered_points[ground_plane_mask]\n",
    "\n",
    "        # Filter points into FOV\n",
    "        u_ground, v_ground, d_ground, sizes_sorted, ground_points_fov = filter_and_clip_points(\n",
    "            ground_points,\n",
    "            fx, fy, cx, cy, img_width, img_height,\n",
    "            once_config,\n",
    "            distortion=distortion\n",
    "        )\n",
    "\n",
    "        # Create depth based search\n",
    "        r = (sizes_sorted * RADIUS_SCALE)\n",
    "        spatial_bins = create_spatial_bins(u_ground, v_ground, r, d_ground, ground_points_fov, cell_size)\n",
    "\n",
    "\n",
    "        ##### Intrinsics  & Unit Vec #####\n",
    "        fitted_line_precalc_values = fit_line_on_plane_precalc(plane_normal, plane_offset)\n",
    "        classic_pure_intrinsic = []\n",
    "        classic_intrinsic_ground_plane = []\n",
    "\n",
    "        ##### Pure Depth #####\n",
    "        classic_pure_depth = []\n",
    "        classic_combined_intrinsic_depth = []\n",
    "\n",
    "        ##### Depth Matching #####\n",
    "        step = min(r) * once_config[\"depth_map\"][\"lane_density_step_fraction\"]\n",
    "        min_spacing = max(r) * once_config[\"depth_map\"][\"min_spacing_fraction\"]\n",
    "\n",
    "        ##### My Solution #####\n",
    "        output_positions = []\n",
    "        ###################################\n",
    "\n",
    "\n",
    "        \n",
    "        ########## Main Processing ##########\n",
    "        for lane_pixels in lanes:\n",
    "            lane_x = lane_pixels[:, 0]\n",
    "            lane_y = lane_pixels[:, 1]\n",
    "\n",
    "\n",
    "            ############# Intrinsics & Unit Vec #############\n",
    "            if once_config[\"output\"][\"calc_cl_intrinsic\"]:\n",
    "                classic_pure_intrinsic.append(pure_intrinsic_projection(lane_x, img_height-lane_y, fx, fy, cx, cy, once_config, distortion, once_config[\"ground_plane_ransac\"][\"camera_height\"]))\n",
    "            \n",
    "\n",
    "            if once_config[\"output\"][\"calc_cl_intrinsic_ground\"] or once_config[\"output\"][\"calc_thesis_solution\"]:\n",
    "                intrinsic_points = pure_intrinsic_projection(lane_x, img_height - lane_y, fx, fy, cx, cy, once_config, distortion, None, plane_normal, plane_offset)\n",
    "                classic_intrinsic_ground_plane.append(intrinsic_points)\n",
    "\n",
    "                model_type, model_params = fit_line_on_plane(\n",
    "                    intrinsic_points, \n",
    "                    fitted_line_precalc_values, \n",
    "                    curvature_threshold=once_config[\"projection_mapping\"][\"snap_curvature_threshold\"]\n",
    "                )\n",
    "            #################################################\n",
    "\n",
    "\n",
    "\n",
    "            ############# Pure Depth #############\n",
    "            if once_config[\"output\"][\"calc_cl_depth\"] or once_config[\"output\"][\"calc_cl_intrinsic_depth\"]:\n",
    "                matched_points = []\n",
    "                udv_point = []\n",
    "                for i in range(len(lane_x)):\n",
    "                    _, _, depth, pt = query_nearest_depth_from_bins(spatial_bins, lane_x[i], lane_y[i], bin_search_range=None) #search infinitely\n",
    "                    matched_points.append(pt)\n",
    "                    udv_point.append(np.array([lane_x[i], lane_y[i], depth]))\n",
    "                classic_pure_depth.append(np.array(matched_points))\n",
    "                udv_point = np.array(udv_point)\n",
    "                classic_combined_intrinsic_depth.append(project_pixel_to_depth(udv_point[:,0], img_height - udv_point[:,1], udv_point[:,2], fx, fy, cx, cy, distortion))\n",
    "            ######################################\n",
    "\n",
    "\n",
    "\n",
    "            ############# Depth Matching #############\n",
    "            if once_config[\"output\"][\"calc_thesis_solution\"]:\n",
    "                valid_depths = []\n",
    "                valid_points = []\n",
    "                matched_points = []\n",
    "                seen = set()\n",
    "                x_prev, y_prev = None, None\n",
    "                for i in range(len(lane_x) - 1):\n",
    "                    x0, y0 = lane_x[i], lane_y[i]\n",
    "                    x1, y1 = lane_x[i + 1], lane_y[i + 1]\n",
    "                    dx, dy = x1 - x0, y1 - y0\n",
    "                    dist = np.hypot(dx, dy)\n",
    "                    num_steps = max(1, int(dist / step))\n",
    "                    t_vals = np.linspace(0, 1, num_steps)\n",
    "                    xs = x0 + t_vals * dx\n",
    "                    ys = y0 + t_vals * dy\n",
    "\n",
    "                    for x, y in zip(xs, ys):\n",
    "                        if x_prev is not None and np.hypot(x - x_prev, y - y_prev) < min_spacing:\n",
    "                            continue\n",
    "                        x_prev, y_prev = x, y\n",
    "\n",
    "                        if not (0 <= x < img_width and 0 <= y < img_height):\n",
    "                            continue\n",
    "\n",
    "                        x2, y2, depth, pt = query_depth_from_bins(spatial_bins, x, y, get_all_depths=False, prioritize_closest=True)\n",
    "                        if depth is None:\n",
    "                            continue\n",
    "\n",
    "                        diff_eps = once_config[\"depth_map\"][\"diff_eps\"]\n",
    "                        x2r, y2r = round(x2 / diff_eps), round(y2 / diff_eps)\n",
    "                        if (x2r, y2r) in seen:\n",
    "                            continue\n",
    "                        seen.add((x2r, y2r))\n",
    "\n",
    "                        denom = dx * dx + dy * dy\n",
    "                        if denom == 0:\n",
    "                            xi, yi = x0, y0\n",
    "                        else:\n",
    "                            t = ((x2 - x0) * dx + (y2 - y0) * dy) / denom\n",
    "                            t = np.clip(t, 0.0, 1.0)\n",
    "                            xi, yi = x0 + t * dx, y0 + t * dy\n",
    "\n",
    "                        valid_points.append((xi, yi))\n",
    "                        valid_depths.append(depth)\n",
    "                        matched_points.append(pt)\n",
    "\n",
    "                if len(valid_points) > 0:\n",
    "                    min_valid_y = valid_points[-1][1]\n",
    "                    max_valid_y = valid_points[0][1]\n",
    "\n",
    "                    # --- FRONT END: anchors before first valid match ---\n",
    "                    front_indices = np.where(lane_y < min_valid_y)[0]\n",
    "                    if len(front_indices) > 0:\n",
    "                        for i in front_indices:\n",
    "                            xq, yq = lane_x[i], lane_y[i]\n",
    "                            xq2, yq2, depth, pt = query_nearest_depth_from_bins(\n",
    "                                spatial_bins, \n",
    "                                xq, yq, \n",
    "                                bin_search_range=once_config[\"depth_map\"][\"unmatched_max_search_range\"]\n",
    "                            )\n",
    "                            if depth is None:\n",
    "                                continue\n",
    "\n",
    "                            # Determine projection reference\n",
    "                            if i == 0:\n",
    "                                # Project onto first segment (0→1)\n",
    "                                x0, y0 = lane_x[0], lane_y[0]\n",
    "                                x1, y1 = lane_x[1], lane_y[1]\n",
    "                            else:\n",
    "                                # Project onto segment (i-1→i)\n",
    "                                x0, y0 = lane_x[i - 1], lane_y[i - 1]\n",
    "                                x1, y1 = lane_x[i], lane_y[i]\n",
    "\n",
    "                            vx, vy = x1 - x0, y1 - y0\n",
    "                            denom = vx * vx + vy * vy\n",
    "                            if denom == 0:\n",
    "                                xi, yi = x0, y0\n",
    "                            else:\n",
    "                                t = ((xq2 - x0) * vx + (yq2 - y0) * vy) / denom\n",
    "                                t = np.clip(t, 0.0, 1.0)\n",
    "                                xi, yi = x0 + t * vx, y0 + t * vy\n",
    "                            \n",
    "                            valid_points = np.vstack([valid_points, [xi, yi]])\n",
    "                            depth = verify_with_intrinsic_projection(xi, yi, fx, fy, cx, cy, once_config, plane_normal, plane_offset, depth, distortion)\n",
    "                            valid_depths = np.append(valid_depths, depth)\n",
    "                            matched_points.append(pt)\n",
    "\n",
    "\n",
    "                    # --- BACK END: anchors after last valid match ---\n",
    "                    back_indices = np.where(lane_y > max_valid_y)[0]\n",
    "                    if len(back_indices) > 0:\n",
    "                        for i in back_indices:\n",
    "                            xq, yq = lane_x[i], lane_y[i]\n",
    "                            xq2, yq2, depth, pt = query_nearest_depth_from_bins(\n",
    "                                spatial_bins, \n",
    "                                xq, yq, \n",
    "                                bin_search_range=once_config[\"depth_map\"][\"unmatched_max_search_range\"]\n",
    "                            )\n",
    "                            if depth is None:\n",
    "                                continue\n",
    "\n",
    "                            # Determine projection reference\n",
    "                            if i == len(lane_x) - 1:\n",
    "                                # Project onto last segment (-2→-1)\n",
    "                                x0, y0 = lane_x[-2], lane_y[-2]\n",
    "                                x1, y1 = lane_x[-1], lane_y[-1]\n",
    "                            else:\n",
    "                                # Project onto segment (i→i+1)\n",
    "                                x0, y0 = lane_x[i], lane_y[i]\n",
    "                                x1, y1 = lane_x[i + 1], lane_y[i + 1]\n",
    "\n",
    "                            vx, vy = x1 - x0, y1 - y0\n",
    "                            denom = vx * vx + vy * vy\n",
    "                            if denom == 0:\n",
    "                                xi, yi = x0, y0\n",
    "                            else:\n",
    "                                t = ((xq2 - x0) * vx + (yq2 - y0) * vy) / denom\n",
    "                                t = np.clip(t, 0.0, 1.0)\n",
    "                                xi, yi = x0 + t * vx, y0 + t * vy\n",
    "\n",
    "                            valid_points = np.vstack([valid_points, [xi, yi]])\n",
    "                            depth = verify_with_intrinsic_projection(xi, yi, fx, fy, cx, cy, once_config, plane_normal, plane_offset, depth, distortion)\n",
    "                            valid_depths = np.append(valid_depths, depth)\n",
    "                            matched_points.append(pt)\n",
    "\n",
    "                    valid_points = np.array(valid_points)\n",
    "                    valid_depths = np.array(valid_depths)\n",
    "                    depth_match_points = np.hstack([valid_points, valid_depths.reshape(-1,1)])\n",
    "                else:\n",
    "                    depth_match_points = []\n",
    "            ##########################################\n",
    "        \n",
    "\n",
    "\n",
    "            ############# 2D to 3D Matching #############\n",
    "            if once_config[\"output\"][\"calc_thesis_solution\"]:\n",
    "                if len(depth_match_points) > 2:\n",
    "                    # Learn mapping\n",
    "                    interp_s_to_t, pixel2d_sorted, _, _, _ = learn_pixel_to_t_mapping_for_lane(\n",
    "                        depth_match_points,\n",
    "                        model_type,\n",
    "                        once_config,\n",
    "                        model_params[\"z_intercept\"], \n",
    "                        img_height, fx, fy, cx, cy, distortion,\n",
    "                        linear_dir=model_params.get(\"line_dir\"),                            # None if quadratic\n",
    "                        quadratic_firstorder_dir=model_params.get(\"quad_firstorder_dir\"),   # None if linear\n",
    "                        quadratic_secondorder_dir=model_params.get(\"quad_secondorder_dir\")  # None if linear\n",
    "                    )\n",
    "\n",
    "                    # Predict 3D for new pixels\n",
    "                    X3_pred, _, _ = predict_3d_for_s2_points(\n",
    "                        lane_pixels, interp_s_to_t, pixel2d_sorted, model_type, \n",
    "                        model_params[\"z_intercept\"],\n",
    "                        linear_dir=model_params.get(\"line_dir\"),                            # None if quadratic\n",
    "                        quadratic_firstorder_dir=model_params.get(\"quad_firstorder_dir\"),   # None if linear\n",
    "                        quadratic_secondorder_dir=model_params.get(\"quad_secondorder_dir\")  # None if linear\n",
    "                    )\n",
    "                    X3_pred = correct_z_mismatched_points(\n",
    "                        X3_pred, \n",
    "                        intrinsic_points,\n",
    "                        once_config, \n",
    "                        model_type, \n",
    "                        model_params[\"z_intercept\"],\n",
    "                        linear_dir=model_params.get(\"line_dir\"),                            # None if quadratic\n",
    "                        quadratic_firstorder_dir=model_params.get(\"quad_firstorder_dir\"),   # None if linear\n",
    "                        quadratic_secondorder_dir=model_params.get(\"quad_secondorder_dir\")  # None if linear\n",
    "                    )\n",
    "                else:\n",
    "                    X3_pred = intrinsic_points\n",
    "                    logger.warning(f\"Not enough point-lidar matches to perform mapping [{len(depth_match_points)}/3]. Defaulting to intrinsic projection.\")\n",
    "\n",
    "                output_positions.append(X3_pred)\n",
    "            #############################################\n",
    "\n",
    "\n",
    "            total_lane_count += 1\n",
    "        #####################################\n",
    "\n",
    "\n",
    "\n",
    "        ############# File Saving #############\n",
    "        if True:\n",
    "            if once_config[\"output\"][\"calc_cl_intrinsic\"]:\n",
    "                save_pointcloud_sequence( \n",
    "                    classic_pure_intrinsic,\n",
    "                    once_config[\"output\"][\"base_path\"],\n",
    "                    seq_id,\n",
    "                    once_config[\"output\"][\"cl_intrinsic_path\"],\n",
    "                    file_id\n",
    "                )\n",
    "            if once_config[\"output\"][\"calc_cl_intrinsic_ground\"]:\n",
    "                save_pointcloud_sequence( \n",
    "                    classic_intrinsic_ground_plane,\n",
    "                    once_config[\"output\"][\"base_path\"],\n",
    "                    seq_id,\n",
    "                    once_config[\"output\"][\"cl_intrinsic_ground_path\"],\n",
    "                    file_id\n",
    "                )\n",
    "            if once_config[\"output\"][\"calc_cl_depth\"]:\n",
    "                save_pointcloud_sequence( \n",
    "                    classic_pure_depth,\n",
    "                    once_config[\"output\"][\"base_path\"],\n",
    "                    seq_id,\n",
    "                    once_config[\"output\"][\"cl_depth_path\"],\n",
    "                    file_id\n",
    "                )\n",
    "            if once_config[\"output\"][\"calc_cl_intrinsic_depth\"]:\n",
    "                save_pointcloud_sequence( \n",
    "                    classic_combined_intrinsic_depth,\n",
    "                    once_config[\"output\"][\"base_path\"],\n",
    "                    seq_id,\n",
    "                    once_config[\"output\"][\"cl_intrinsic_depth_path\"],\n",
    "                    file_id\n",
    "                )\n",
    "            if once_config[\"output\"][\"calc_thesis_solution\"]:\n",
    "                save_pointcloud_sequence( \n",
    "                    output_positions,\n",
    "                    once_config[\"output\"][\"base_path\"],\n",
    "                    seq_id,\n",
    "                    once_config[\"output\"][\"thesis_solution_path\"],\n",
    "                    file_id\n",
    "                )\n",
    "        #######################################\n",
    "    \n",
    "    return total_lane_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d62e085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_per_seq(config, seq_id):\n",
    "    '''\n",
    "    This function implements all solutions for one run id / sequence id (if that solution's config run is on):\n",
    "        - Pure intrinsic\n",
    "        - Intrinsic + ground plane\n",
    "        - Lidar matching\n",
    "        - Intrinsic + Lidar matching\n",
    "        - Thesis code\n",
    "\n",
    "    If \"run all no timing\" is enabled, all solutions are run simultaneously (which is significantly faster). \n",
    "    Otherwise, runs one at a time (but accurately records runtime metrics for each). Thus, this function calls\n",
    "    the sub-running functions per-solution (overriding data by settings).\n",
    "\n",
    "    This function also establishes per-sequence logging. The final return value is per-solution runtimes.\n",
    "\n",
    "    Args:\n",
    "        config (dict): Configuration file.\n",
    "        seq_id (str or int): The run id / sequence id. \n",
    "\n",
    "    Outputs:\n",
    "        The processed 3D results are saved to disk per solution. See each solution's call function for specifics.\n",
    "        Additionally outputs a log file (for the run/sequence) in the appropriate output file. \n",
    "\n",
    "    Returns:\n",
    "        runtimes (dict): a dictionary of runtimes per solution.\n",
    "    '''\n",
    "    base_path = config[\"data\"][\"base_path\"]\n",
    "\n",
    "    lidar_folder_path = os.path.join(base_path, seq_id, config[\"data\"][\"lidar_path\"])\n",
    "    once_calibration_path = os.path.join(base_path, seq_id, config[\"data\"][\"calibration_path\"])\n",
    "    lane_detections_folder_path = os.path.join(base_path, seq_id, config[\"data\"][\"lane_detections_folder_path\"])\n",
    "    \n",
    "    lidar_files = list(Path(lidar_folder_path).glob(\"*.bin\"))\n",
    "\n",
    "    switch_log_file(logger, os.path.join(config[\"output\"][\"base_path\"], seq_id), seq_id)\n",
    "\n",
    "    runtimes = {}\n",
    "    if config[\"runtime\"][\"run_all_no_timing\"]:\n",
    "        logger.info(\"\\n\"*3 + (\"=\"*100 + \"\\n\")*3)\n",
    "        logger.info(\"Starting all calculations.\")\n",
    "        start_timer(logger)\n",
    "        lane_count = run_all_solutions(once_calibration_path, lane_detections_folder_path, seq_id, lidar_files)\n",
    "        logger.info(\"\\n\"*3)\n",
    "        runtimes[\"run_all_no_timing\"] = stop_timer(logger, \"All simultaneously\", lane_count)\n",
    "    else:\n",
    "        if config[\"output\"][\"calc_cl_intrinsic\"]:\n",
    "            logger.info(\"\\n\"*3 + (\"=\"*100 + \"\\n\")*3)\n",
    "            logger.info(\"Starting intrinsic calculations.\")\n",
    "            start_timer(logger)\n",
    "            lane_count = run_cl_intrinsic(once_calibration_path, lane_detections_folder_path, seq_id, lidar_files)\n",
    "            logger.info(\"\\n\"*3)\n",
    "            runtimes[config[\"output\"][\"cl_intrinsic_path\"]] = stop_timer(logger, \"Pure Intrinsic\", lane_count)\n",
    "\n",
    "        if config[\"output\"][\"calc_cl_intrinsic_ground\"]:\n",
    "            logger.info(\"\\n\" + (\"=\"*100 + \"\\n\")*3)\n",
    "            logger.info(\"Starting intrinsic ground plane calculations.\")\n",
    "            start_timer(logger)\n",
    "            lane_count = run_cl_intrinsic_groundplane(once_calibration_path, lane_detections_folder_path, seq_id, lidar_files)\n",
    "            logger.info(\"\\n\"*3)\n",
    "            runtimes[config[\"output\"][\"cl_intrinsic_ground_path\"]] = stop_timer(logger, \"Intrinsic + Ground Plane\", lane_count)\n",
    "\n",
    "        if config[\"output\"][\"calc_cl_depth\"]:\n",
    "            logger.info(\"\\n\" + (\"=\"*100 + \"\\n\")*3)\n",
    "            logger.info(\"Starting depth calculations.\")\n",
    "            start_timer(logger)\n",
    "            lane_count = run_cl_depth(once_calibration_path, lane_detections_folder_path, seq_id, lidar_files)\n",
    "            logger.info(\"\\n\"*3)\n",
    "            runtimes[config[\"output\"][\"cl_depth_path\"]] = stop_timer(logger, \"Pure Depth\", lane_count)\n",
    "\n",
    "        if config[\"output\"][\"calc_cl_intrinsic_depth\"]:\n",
    "            logger.info(\"\\n\" + (\"=\"*100 + \"\\n\")*3)\n",
    "            logger.info(\"Starting intrinsic + depth calculations.\")\n",
    "            start_timer(logger)\n",
    "            lane_count = run_cl_intrinsic_depth(once_calibration_path, lane_detections_folder_path, seq_id, lidar_files)\n",
    "            logger.info(\"\\n\"*3)\n",
    "            runtimes[config[\"output\"][\"cl_intrinsic_depth_path\"]] = stop_timer(logger, \"Intrinsic + Depth\", lane_count)\n",
    "            \n",
    "        if config[\"output\"][\"calc_thesis_solution\"]:\n",
    "            logger.info(\"\\n\" + (\"=\"*100 + \"\\n\")*3)\n",
    "            logger.info(\"Starting thesis code calculations.\")\n",
    "            start_timer(logger)\n",
    "            lane_count = run_thesis_solution(once_calibration_path, lane_detections_folder_path, seq_id, lidar_files)\n",
    "            logger.info(\"\\n\"*3)\n",
    "            runtimes[config[\"output\"][\"thesis_solution_path\"]] = stop_timer(logger, \"Custom Thesis\", lane_count)\n",
    "\n",
    "    return runtimes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec42067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_runtime_results(config, all_runtimes, seq_ids):\n",
    "    '''\n",
    "    Saves a dictionary of runtime results per sequence per solution. Overrides existing data if enabled,\n",
    "    otherwise fills in missing runs / solutions.\n",
    "\n",
    "    Args:\n",
    "        config (dict): Configuration file.\n",
    "        all_runtimes (dict): A dictionary of sequences with subdictionaries for solutions and their runtimes. \n",
    "        seq_id (strs or ints): All run ids / sequence ids.\n",
    "\n",
    "    Outputs:\n",
    "        The runtime results of all sequences and all solutions is saved to the disk. It appends to the JSON file,\n",
    "        allowing async solution runs.\n",
    "    '''\n",
    "    runtime_output = os.path.join(config[\"output\"][\"base_path\"], config[\"output\"][\"runtime_data_path\"])\n",
    "    if os.path.exists(runtime_output):\n",
    "        with open(runtime_output, \"r\") as f:\n",
    "            existing = json.load(f)\n",
    "    else:\n",
    "        existing = []\n",
    "\n",
    "    existing_dict = {item[\"seq_id\"]: item[\"runtimes\"] for item in existing}\n",
    "    for i, seq_id in enumerate(seq_ids):\n",
    "        current_runtimes = {\n",
    "            k: (v[i] if v[i] != -1 else None)\n",
    "            for k, v in all_runtimes.items()\n",
    "        }\n",
    "        if seq_id not in existing_dict:\n",
    "            # New seq, add\n",
    "            existing_dict[seq_id] = current_runtimes\n",
    "            continue\n",
    "        # Existing seq, fill in values\n",
    "        old_runtimes = existing_dict[seq_id]\n",
    "        for key, old_val in old_runtimes.items():\n",
    "            new_val = current_runtimes[key]\n",
    "            if old_val is None and new_val is not None:\n",
    "                # Fill previously-null value\n",
    "                old_runtimes[key] = new_val\n",
    "            elif config[\"runtime\"][\"override_existing_output\"] and new_val is not None:\n",
    "                # Override any existing value if allowed\n",
    "                old_runtimes[key] = new_val\n",
    "    output_list = [{\"seq_id\": seq_id, \"runtimes\": existing_dict[seq_id]} for seq_id in sorted(existing_dict.keys())]\n",
    "    with open(runtime_output, \"w\") as f:\n",
    "        json.dump(output_list, f, indent=2)\n",
    "\n",
    "    main_logger.info(f\"Runtime output file updated: {runtime_output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5111c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing cl intrinsic LiDAR files for 000027: 100%|██████████| 1147/1147 [00:08<00:00, 142.77it/s]\n",
      "Processing cl intrinsic ground plane LiDAR files for 000027: 100%|██████████| 1147/1147 [00:13<00:00, 82.20it/s] \n",
      "Processing cl depth LiDAR files for 000027: 100%|██████████| 1147/1147 [14:31<00:00,  1.32it/s] \n",
      "Processing cl intrinsic + depth LiDAR files for 000027: 100%|██████████| 1147/1147 [15:28<00:00,  1.23it/s] \n",
      "Processing thesis solution LiDAR files for 000027: 100%|██████████| 1147/1147 [00:40<00:00, 28.23it/s]\n",
      "Processing cl intrinsic LiDAR files for 000028: 100%|██████████| 485/485 [00:03<00:00, 148.98it/s]\n",
      "Processing cl intrinsic ground plane LiDAR files for 000028: 100%|██████████| 485/485 [00:05<00:00, 87.43it/s] \n",
      "Processing cl depth LiDAR files for 000028: 100%|██████████| 485/485 [00:51<00:00,  9.36it/s]\n",
      "Processing cl intrinsic + depth LiDAR files for 000028: 100%|██████████| 485/485 [00:56<00:00,  8.66it/s]\n",
      "Processing thesis solution LiDAR files for 000028: 100%|██████████| 485/485 [00:15<00:00, 32.10it/s] \n",
      "Processing cl intrinsic LiDAR files for 000034: 100%|██████████| 810/810 [00:06<00:00, 133.30it/s]\n",
      "Processing cl intrinsic ground plane LiDAR files for 000034: 100%|██████████| 810/810 [00:11<00:00, 72.71it/s]\n",
      "Processing cl depth LiDAR files for 000034: 100%|██████████| 810/810 [13:17<00:00,  1.02it/s]\n",
      "Processing cl intrinsic + depth LiDAR files for 000034: 100%|██████████| 810/810 [13:35<00:00,  1.01s/it]\n",
      "Processing thesis solution LiDAR files for 000034: 100%|██████████| 810/810 [00:33<00:00, 24.21it/s]\n",
      "Processing cl intrinsic LiDAR files for 000076: 100%|██████████| 1028/1028 [00:07<00:00, 130.75it/s]\n",
      "Processing cl intrinsic ground plane LiDAR files for 000076: 100%|██████████| 1028/1028 [00:13<00:00, 74.06it/s]\n",
      "Processing cl depth LiDAR files for 000076: 100%|██████████| 1028/1028 [06:01<00:00,  2.84it/s] \n",
      "Processing cl intrinsic + depth LiDAR files for 000076: 100%|██████████| 1028/1028 [06:51<00:00,  2.50it/s] \n",
      "Processing thesis solution LiDAR files for 000076: 100%|██████████| 1028/1028 [00:45<00:00, 22.46it/s]\n",
      "Processing cl intrinsic LiDAR files for 000077: 100%|██████████| 610/610 [00:04<00:00, 135.56it/s]\n",
      "Processing cl intrinsic ground plane LiDAR files for 000077: 100%|██████████| 610/610 [00:07<00:00, 76.61it/s]\n",
      "Processing cl depth LiDAR files for 000077: 100%|██████████| 610/610 [09:27<00:00,  1.07it/s]  \n",
      "Processing cl intrinsic + depth LiDAR files for 000077: 100%|██████████| 610/610 [09:19<00:00,  1.09it/s]  \n",
      "Processing thesis solution LiDAR files for 000077: 100%|██████████| 610/610 [00:31<00:00, 19.20it/s]\n",
      "Processing cl intrinsic LiDAR files for 000080: 100%|██████████| 961/961 [00:07<00:00, 134.28it/s]\n",
      "Processing cl intrinsic ground plane LiDAR files for 000080: 100%|██████████| 961/961 [00:12<00:00, 77.51it/s] \n",
      "Processing cl depth LiDAR files for 000080: 100%|██████████| 961/961 [28:42<00:00,  1.79s/it]  \n",
      "Processing cl intrinsic + depth LiDAR files for 000080: 100%|██████████| 961/961 [30:09<00:00,  1.88s/it]  \n",
      "Processing thesis solution LiDAR files for 000080: 100%|██████████| 961/961 [00:44<00:00, 21.55it/s]\n",
      "Processing cl intrinsic LiDAR files for 000092: 100%|██████████| 583/583 [00:04<00:00, 143.34it/s]\n",
      "Processing cl intrinsic ground plane LiDAR files for 000092: 100%|██████████| 583/583 [00:07<00:00, 83.29it/s] \n",
      "Processing cl depth LiDAR files for 000092: 100%|██████████| 583/583 [09:37<00:00,  1.01it/s]\n",
      "Processing cl intrinsic + depth LiDAR files for 000092: 100%|██████████| 583/583 [09:58<00:00,  1.03s/it]\n",
      "Processing thesis solution LiDAR files for 000092: 100%|██████████| 583/583 [00:27<00:00, 21.33it/s] \n",
      "Processing cl intrinsic LiDAR files for 000104: 100%|██████████| 615/615 [00:04<00:00, 132.90it/s]\n",
      "Processing cl intrinsic ground plane LiDAR files for 000104: 100%|██████████| 615/615 [00:08<00:00, 70.70it/s]\n",
      "Processing cl depth LiDAR files for 000104: 100%|██████████| 615/615 [06:23<00:00,  1.60it/s]  \n",
      "Processing cl intrinsic + depth LiDAR files for 000104: 100%|██████████| 615/615 [07:13<00:00,  1.42it/s]  \n",
      "Processing thesis solution LiDAR files for 000104: 100%|██████████| 615/615 [00:35<00:00, 17.43it/s]\n",
      "Processing cl intrinsic LiDAR files for 000112: 100%|██████████| 1225/1225 [00:08<00:00, 138.92it/s]\n",
      "Processing cl intrinsic ground plane LiDAR files for 000112: 100%|██████████| 1225/1225 [00:15<00:00, 78.18it/s]\n",
      "Processing cl depth LiDAR files for 000112: 100%|██████████| 1225/1225 [1:02:02<00:00,  3.04s/it]\n",
      "Processing cl intrinsic + depth LiDAR files for 000112: 100%|██████████| 1225/1225 [1:04:16<00:00,  3.15s/it]\n",
      "Processing thesis solution LiDAR files for 000112: 100%|██████████| 1225/1225 [00:59<00:00, 20.62it/s]\n",
      "Processing cl intrinsic LiDAR files for 000113: 100%|██████████| 946/946 [00:07<00:00, 124.89it/s]\n",
      "Processing cl intrinsic ground plane LiDAR files for 000113: 100%|██████████| 946/946 [00:12<00:00, 74.49it/s]\n",
      "Processing cl depth LiDAR files for 000113: 100%|██████████| 946/946 [02:57<00:00,  5.32it/s]\n",
      "Processing cl intrinsic + depth LiDAR files for 000113: 100%|██████████| 946/946 [02:59<00:00,  5.26it/s]\n",
      "Processing thesis solution LiDAR files for 000113: 100%|██████████| 946/946 [00:51<00:00, 18.34it/s]\n",
      "Processing cl intrinsic LiDAR files for 000121: 100%|██████████| 857/857 [00:06<00:00, 134.30it/s]\n",
      "Processing cl intrinsic ground plane LiDAR files for 000121: 100%|██████████| 857/857 [00:11<00:00, 72.79it/s]\n",
      "Processing cl depth LiDAR files for 000121: 100%|██████████| 857/857 [14:22<00:00,  1.01s/it]  \n",
      "Processing cl intrinsic + depth LiDAR files for 000121: 100%|██████████| 857/857 [12:38<00:00,  1.13it/s]  \n",
      "Processing thesis solution LiDAR files for 000121: 100%|██████████| 857/857 [00:41<00:00, 20.50it/s]\n",
      "Processing cl intrinsic LiDAR files for 000168: 100%|██████████| 771/771 [00:04<00:00, 173.23it/s]\n",
      "Processing cl intrinsic ground plane LiDAR files for 000168: 100%|██████████| 771/771 [00:08<00:00, 95.94it/s] \n",
      "Processing cl depth LiDAR files for 000168: 100%|██████████| 771/771 [08:55<00:00,  1.44it/s]  \n",
      "Processing cl intrinsic + depth LiDAR files for 000168: 100%|██████████| 771/771 [08:12<00:00,  1.56it/s]  \n",
      "Processing thesis solution LiDAR files for 000168: 100%|██████████| 771/771 [00:29<00:00, 26.35it/s] \n",
      "Processing cl intrinsic LiDAR files for 000200: 100%|██████████| 1049/1049 [00:07<00:00, 137.60it/s]\n",
      "Processing cl intrinsic ground plane LiDAR files for 000200: 100%|██████████| 1049/1049 [00:14<00:00, 74.88it/s]\n",
      "Processing cl depth LiDAR files for 000200: 100%|██████████| 1049/1049 [04:25<00:00,  3.96it/s]\n",
      "Processing cl intrinsic + depth LiDAR files for 000200: 100%|██████████| 1049/1049 [04:14<00:00,  4.12it/s]\n",
      "Processing thesis solution LiDAR files for 000200: 100%|██████████| 1049/1049 [00:43<00:00, 24.08it/s]\n",
      "Processing cl intrinsic LiDAR files for 000201: 100%|██████████| 468/468 [00:03<00:00, 124.36it/s]\n",
      "Processing cl intrinsic ground plane LiDAR files for 000201: 100%|██████████| 468/468 [00:06<00:00, 76.51it/s] \n",
      "Processing cl depth LiDAR files for 000201: 100%|██████████| 468/468 [01:19<00:00,  5.88it/s]\n",
      "Processing cl intrinsic + depth LiDAR files for 000201: 100%|██████████| 468/468 [01:29<00:00,  5.24it/s]\n",
      "Processing thesis solution LiDAR files for 000201: 100%|██████████| 468/468 [00:33<00:00, 13.80it/s]\n",
      "Processing cl intrinsic LiDAR files for 000273: 100%|██████████| 960/960 [00:07<00:00, 133.79it/s]\n",
      "Processing cl intrinsic ground plane LiDAR files for 000273: 100%|██████████| 960/960 [00:12<00:00, 79.02it/s] \n",
      "Processing cl depth LiDAR files for 000273: 100%|██████████| 960/960 [06:17<00:00,  2.54it/s]  \n",
      "Processing cl intrinsic + depth LiDAR files for 000273: 100%|██████████| 960/960 [06:24<00:00,  2.50it/s]  \n",
      "Processing thesis solution LiDAR files for 000273: 100%|██████████| 960/960 [00:28<00:00, 34.13it/s] \n",
      "Processing cl intrinsic LiDAR files for 000275: 100%|██████████| 747/747 [00:05<00:00, 133.44it/s]\n",
      "Processing cl intrinsic ground plane LiDAR files for 000275: 100%|██████████| 747/747 [00:09<00:00, 77.69it/s]\n",
      "Processing cl depth LiDAR files for 000275: 100%|██████████| 747/747 [02:37<00:00,  4.73it/s]\n",
      "Processing cl intrinsic + depth LiDAR files for 000275: 100%|██████████| 747/747 [02:43<00:00,  4.57it/s]\n",
      "Processing thesis solution LiDAR files for 000275: 100%|██████████| 747/747 [00:27<00:00, 27.15it/s]\n",
      "Processing cl intrinsic LiDAR files for 000303: 100%|██████████| 923/923 [00:06<00:00, 132.32it/s]\n",
      "Processing cl intrinsic ground plane LiDAR files for 000303: 100%|██████████| 923/923 [00:11<00:00, 78.54it/s] \n",
      "Processing cl depth LiDAR files for 000303: 100%|██████████| 923/923 [04:00<00:00,  3.84it/s]\n",
      "Processing cl intrinsic + depth LiDAR files for 000303: 100%|██████████| 923/923 [05:33<00:00,  2.77it/s]  \n",
      "Processing thesis solution LiDAR files for 000303: 100%|██████████| 923/923 [00:51<00:00, 18.07it/s]\n",
      "Processing cl intrinsic LiDAR files for 000318: 100%|██████████| 770/770 [00:06<00:00, 118.00it/s]\n",
      "Processing cl intrinsic ground plane LiDAR files for 000318: 100%|██████████| 770/770 [00:11<00:00, 67.50it/s]\n",
      "Processing cl depth LiDAR files for 000318: 100%|██████████| 770/770 [02:27<00:00,  5.21it/s]\n",
      "Processing cl intrinsic + depth LiDAR files for 000318: 100%|██████████| 770/770 [02:26<00:00,  5.25it/s]\n",
      "Processing thesis solution LiDAR files for 000318: 100%|██████████| 770/770 [00:57<00:00, 13.48it/s]\n",
      "Processing cl intrinsic LiDAR files for 000322: 100%|██████████| 766/766 [00:06<00:00, 114.74it/s]\n",
      "Processing cl intrinsic ground plane LiDAR files for 000322: 100%|██████████| 766/766 [00:11<00:00, 67.61it/s]\n",
      "Processing cl depth LiDAR files for 000322: 100%|██████████| 766/766 [14:24<00:00,  1.13s/it]\n",
      "Processing cl intrinsic + depth LiDAR files for 000322: 100%|██████████| 766/766 [15:39<00:00,  1.23s/it]\n",
      "Processing thesis solution LiDAR files for 000322: 100%|██████████| 766/766 [00:41<00:00, 18.47it/s]\n",
      "Processing cl intrinsic LiDAR files for 000334: 100%|██████████| 524/524 [00:04<00:00, 126.85it/s]\n",
      "Processing cl intrinsic ground plane LiDAR files for 000334: 100%|██████████| 524/524 [00:07<00:00, 73.75it/s] \n",
      "Processing cl depth LiDAR files for 000334: 100%|██████████| 524/524 [01:41<00:00,  5.16it/s]\n",
      "Processing cl intrinsic + depth LiDAR files for 000334: 100%|██████████| 524/524 [01:41<00:00,  5.14it/s]\n",
      "Processing thesis solution LiDAR files for 000334: 100%|██████████| 524/524 [00:37<00:00, 13.89it/s]\n"
     ]
    }
   ],
   "source": [
    "######### Main Running Block #########\n",
    "\n",
    "# Determine which seq ids to run on\n",
    "base_path = once_config[\"data\"][\"base_path\"]\n",
    "seq_id = once_config[\"runtime\"][\"seq_id\"]\n",
    "seq_ids = []\n",
    "if seq_id is None:\n",
    "    # Get all sequences\n",
    "    for name in os.listdir(base_path):\n",
    "        full_path = os.path.join(base_path, name)\n",
    "        if os.path.isdir(full_path):\n",
    "            seq_ids.append(name)\n",
    "    \n",
    "    main_logger.info(f\"Running all run ids: {len(seq_ids)} found.\\n\\n\\n\\n\")\n",
    "else:\n",
    "    full_path = os.path.join(base_path, seq_id)\n",
    "    if os.path.exists(full_path) and os.path.isdir(full_path):\n",
    "        seq_ids.append(seq_id)\n",
    "        main_logger.info(f\"Running prespecified run id: {seq_id}\")\n",
    "    else:\n",
    "        main_logger.error(f\"Prespecified run id {seq_id} is not found, or not a run folder.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "# Run all sequences\n",
    "runtime_keys = [\n",
    "    \"run_all_no_timing\", \n",
    "    once_config[\"output\"][\"cl_intrinsic_path\"],\n",
    "    once_config[\"output\"][\"cl_intrinsic_ground_path\"],\n",
    "    once_config[\"output\"][\"cl_depth_path\"],\n",
    "    once_config[\"output\"][\"cl_intrinsic_depth_path\"],\n",
    "    once_config[\"output\"][\"thesis_solution_path\"]\n",
    "]\n",
    "all_runtimes = {k: [] for k in runtime_keys}\n",
    "for seq_id in seq_ids:\n",
    "    main_logger.info(f\"Running seq_id: {seq_id}\")\n",
    "    start_timer(main_logger)\n",
    "    runtimes = main_per_seq(once_config, seq_id)\n",
    "    stop_timer(main_logger, f\"Seq {seq_id}\", calc_lane_time=False)\n",
    "    for k in runtime_keys:\n",
    "        if k == \"run_all_no_timing\":\n",
    "            value = runtimes.get(k, -1)\n",
    "        else:\n",
    "            value = runtimes.get(k, -1)\n",
    "        all_runtimes[k].append(value)\n",
    "\n",
    "# Save runtime results\n",
    "save_runtime_results(once_config, all_runtimes, seq_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e7c1af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
