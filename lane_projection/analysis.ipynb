{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9afe7c2",
   "metadata": {},
   "source": [
    "## Thesis Analysis\n",
    "Created by Jett Penner<br>\n",
    "December 2025 <br>\n",
    "\n",
    "\n",
    "Performs quantitative (and some qualitative) analysis of the data, generating some graphs and tables automatically where efficient for use in my thesis paper. This code lacks coherency or organization and may require non-sequential code block running, as this code is purely intended for personal output generation, and not for future replication (but may act as a guide on the analyses performed). Thus, comments are inconsistent, and certain graphing modules may be AI-generated.\n",
    "\n",
    "Again, only needed for thesis analysis, not for real implementation. Run the files in order:\n",
    "1. Run the `ONCE-3DLanes Data Loader` for data loading and preprocessing.\n",
    "2. Run the `2D-to-3D Lanes Pipeline` for projection output (for proposed and alternate solutions).\n",
    "3. Run the `2D-to-3D Lanes Outlier Postfilter` for preprocessing outlier detection.\n",
    "4. Run the `Results Compiler` to generate aggregate and summary statistics for easier (and faster) analyses generation.\n",
    "5. Run this code (sometimes non-sequentially) to generate summary values of output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317bccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from scipy import stats\n",
    "import shutil\n",
    "import re\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da7cca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_solution_label_mapper(all_solutions, solution_labels):\n",
    "    \"\"\"\n",
    "    Returns a function f(solution) -> corresponding label.\n",
    "    Solutions are matched by identity/equality against the all_solutions list.\n",
    "    \"\"\"\n",
    "    if len(all_solutions) != len(solution_labels):\n",
    "        raise ValueError(\"all_solutions and solution_labels must be the same length\")\n",
    "    \n",
    "    # Build lookup table\n",
    "    lookup = {sol: label for sol, label in zip(all_solutions, solution_labels)}\n",
    "\n",
    "    def mapper(solution):\n",
    "        try:\n",
    "            return lookup[solution]\n",
    "        except KeyError:\n",
    "            raise KeyError(f\"Solution {solution!r} not found in all_solutions\")\n",
    "\n",
    "    return mapper\n",
    "\n",
    "\n",
    "def make_is_important_mapper(all_solutions, alternative_solutions):\n",
    "    \"\"\"\n",
    "    Returns a function is_important(solution) -> True/False.\n",
    "    True if the solution is not in alternative_solutions (i.e., important),\n",
    "    False if it exists in alternative_solutions.\n",
    "    \"\"\"\n",
    "    # Build lookup table\n",
    "    lookup = {sol: (sol not in alternative_solutions) for sol in all_solutions}\n",
    "\n",
    "    def is_important(solution):\n",
    "        try:\n",
    "            return lookup[solution]\n",
    "        except KeyError:\n",
    "            raise KeyError(f\"Solution {solution!r} not found in all_solutions\")\n",
    "\n",
    "    return is_important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60031928",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"once\" + \"_config.yaml\", \"r\") as f:\n",
    "    once_config = yaml.safe_load(f)\n",
    "\n",
    "base_path = once_config[\"output\"][\"base_path\"]\n",
    "seq_ids = []\n",
    "# Get all sequences\n",
    "for name in os.listdir(base_path):\n",
    "    full_path = os.path.join(base_path, name)\n",
    "    if os.path.isdir(full_path):\n",
    "        seq_ids.append(name)\n",
    "results_eval_folder = once_config[\"result_analytics\"][\"results_eval_folder\"]\n",
    "\n",
    "thesis_solution = once_config[\"output\"][\"thesis_solution_path\"]\n",
    "alternative_solutions = []\n",
    "if once_config[\"output\"][\"calc_cl_intrinsic\"]:\n",
    "    alternative_solutions.append(once_config[\"output\"][\"cl_intrinsic_path\"])\n",
    "if once_config[\"output\"][\"calc_cl_intrinsic_ground\"]:\n",
    "    alternative_solutions.append(once_config[\"output\"][\"cl_intrinsic_ground_path\"])\n",
    "if once_config[\"output\"][\"calc_cl_depth\"]:\n",
    "    alternative_solutions.append(once_config[\"output\"][\"cl_depth_path\"])\n",
    "if once_config[\"output\"][\"calc_cl_intrinsic_depth\"]:\n",
    "    alternative_solutions.append(once_config[\"output\"][\"cl_intrinsic_depth_path\"])\n",
    "\n",
    "solution_labels = []\n",
    "\n",
    "all_solutions = []\n",
    "if once_config[\"output\"][\"calc_thesis_solution\"]:\n",
    "    all_solutions.append(thesis_solution)\n",
    "    solution_labels.append(\"Proposed\")\n",
    "for idx, f in enumerate(alternative_solutions):\n",
    "    all_solutions.append(f)\n",
    "    solution_labels.append(chr(ord('A') + idx))\n",
    "\n",
    "solution_labels = [\"Proposed\", \"Pinhole Projection\", \"Ground Pinhole Projection\", \"LiDAR Interpolation\", \"Intrinsic + LiDAR\"]\n",
    "    \n",
    "\n",
    "map_solution = make_solution_label_mapper(all_solutions, solution_labels)\n",
    "is_important = make_is_important_mapper(all_solutions, alternative_solutions)\n",
    "\n",
    "def file_map_solution(s):\n",
    "    s = s.strip()\n",
    "    s = re.sub(r'[^A-Za-z]', '_', s)\n",
    "    s = re.sub(r'_+', '_', s)\n",
    "    return map_solution(s)\n",
    "\n",
    "evaluation_extension = once_config[\"result_analytics\"][\"evaluation_extension\"]\n",
    "\n",
    "runtime_data_path = os.path.join(once_config[\"output\"][\"base_path\"], once_config[\"output\"][\"runtime_data_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59b4ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_dict = {}\n",
    "\n",
    "for seq_id in seq_ids:\n",
    "    runtime_dict[seq_id] = {solution: {} for solution in all_solutions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b64cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left empty for ease of non-sequential running"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd823215",
   "metadata": {},
   "source": [
    "## Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b0570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_runtime(runtime_dict, runtime_data_path, seq_id, performance_path):\n",
    "    # Load runtime JSON data\n",
    "    with open(runtime_data_path, \"r\") as f:\n",
    "        runtime_data = json.load(f)\n",
    "\n",
    "    # Load performance JSON data to extract counts\n",
    "    with open(performance_path, \"r\") as f:\n",
    "        performance_data = json.load(f)\n",
    "    run_info = performance_data.get(\"run_info\", {})\n",
    "    n_frames = run_info.get(\"n_frames\", 1)\n",
    "    n_lanes = run_info.get(\"n_lanes\", 1)\n",
    "    n_points = run_info.get(\"n_points\", 1)\n",
    "\n",
    "    runtime_dict[seq_id][\"count_data\"] = {\n",
    "        \"n_frames\": n_frames,\n",
    "        \"n_lanes\": n_lanes,\n",
    "        \"n_points\": n_points\n",
    "    }\n",
    "\n",
    "    # Iterate through each runtime entry\n",
    "    for entry in runtime_data:\n",
    "        s_id = entry.get(\"seq_id\")\n",
    "        if s_id == seq_id:\n",
    "            runtimes = entry.get(\"runtimes\", {})\n",
    "\n",
    "            for solution_name, runtime_value in runtimes.items():\n",
    "                if solution_name in runtime_dict[seq_id]:\n",
    "                    if runtime_value == None:\n",
    "                        runtime_value = 0\n",
    "                    runtime_dict[seq_id][solution_name][\"runtime_data\"] = {\n",
    "                        \"runtime\": runtime_value,\n",
    "                        \"runtime_frame\": runtime_value / n_frames,\n",
    "                        \"runtime_lanes\": runtime_value / n_lanes,\n",
    "                        \"runtime_points\": runtime_value / n_points\n",
    "                    }\n",
    "\n",
    "                    \n",
    "for seq_id in tqdm(seq_ids, desc=\"Processing runtimes\"):\n",
    "    performance_path = os.path.join(base_path, seq_id, results_eval_folder, (all_solutions[0] + evaluation_extension))\n",
    "    populate_runtime(runtime_dict, runtime_data_path, seq_id, performance_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc06a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_runtime_figures(runtime_dict, output_filename, point_divisor=1000):\n",
    "    details_rows = []\n",
    "    summary_rows = []\n",
    "\n",
    "    # Collect data\n",
    "    for seq_id, seq_data in runtime_dict.items():\n",
    "        summary_row = {\"Run id\": seq_id}\n",
    "        for solution_name, sol_data in seq_data.items():\n",
    "            rt_data = sol_data.get(\"runtime_data\", {})\n",
    "            if not rt_data:\n",
    "                continue\n",
    "\n",
    "            details_rows.append({\n",
    "                \"Run id\": seq_id,\n",
    "                \"Solution\": solution_name,\n",
    "                \"Runtime (s)\": rt_data[\"runtime\"],\n",
    "                \"Runtime / Frame (s)\": round(rt_data[\"runtime_frame\"], 4),\n",
    "                \"Runtime / Lane (s)\": round(rt_data[\"runtime_lanes\"], 4),\n",
    "                f\"Runtime / {point_divisor} Points (s)\": round(rt_data[\"runtime_points\"] * point_divisor, 4)\n",
    "            })\n",
    "\n",
    "            summary_row[solution_name] = round(rt_data[\"runtime_frame\"], 4)\n",
    "\n",
    "        summary_rows.append(summary_row)\n",
    "\n",
    "    # Convert to DataFrames\n",
    "    details_df = pd.DataFrame(details_rows)\n",
    "    summary_df = pd.DataFrame(summary_rows).fillna(\"\")\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(os.path.dirname(output_filename), exist_ok=True)\n",
    "\n",
    "    # Output Excel file\n",
    "    excel_path = f\"{output_filename}.xlsx\"\n",
    "    with pd.ExcelWriter(excel_path, engine=\"openpyxl\") as writer:\n",
    "        details_df.to_excel(writer, index=False, sheet_name=\"details\")\n",
    "        summary_df.to_excel(writer, index=False, sheet_name=\"summary\")\n",
    "\n",
    "    print(f\"Runtime table written to {os.path.abspath(excel_path)}\")\n",
    "\n",
    "    # Prepare data\n",
    "    summary_df_sorted = summary_df.sort_values(\"Run id\")\n",
    "    run_ids = summary_df_sorted[\"Run id\"].astype(str).str[-3:]  # last 3 chars\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Get list of solutions excluding Run id\n",
    "    solution_names = [col for col in summary_df.columns if col != \"Run id\"]\n",
    "\n",
    "    # Identify the important solution\n",
    "    important_solution = next((s for s in solution_names if is_important(s)), None)\n",
    "\n",
    "    # Generate distinct colors for non-important solutions\n",
    "    non_important_solutions = [s for s in solution_names if s != important_solution]\n",
    "    n_colors = len(non_important_solutions)\n",
    "    cmap = matplotlib.colormaps.get_cmap(\"BuGn\")\n",
    "    colors_array = [cmap(i) for i in np.linspace(0.3, 1.0, n_colors)]\n",
    "    colors = {s: colors_array[i] for i, s in enumerate(non_important_solutions)}\n",
    "\n",
    "    # Assign red to the important solution\n",
    "    if important_solution is not None:\n",
    "        colors[important_solution] = (1.0, 0.0, 0.0, 1.0)  # red RGBA\n",
    "\n",
    "    for solution_name in solution_names:\n",
    "        y_vals = summary_df_sorted[solution_name].replace(\"\", np.nan).astype(float)\n",
    "\n",
    "        # Skip solution if entire column is NaN\n",
    "        if np.all(np.isnan(y_vals)):\n",
    "            continue\n",
    "\n",
    "        # Determine alpha and linewidth based on importance\n",
    "        if solution_name == important_solution:\n",
    "            alpha = 1.0\n",
    "            linewidth = 2.5\n",
    "        else:\n",
    "            alpha = 0.6  # slightly subdued\n",
    "            linewidth = 1.5\n",
    "\n",
    "        plt.plot(\n",
    "            run_ids,\n",
    "            y_vals,\n",
    "            marker=\"o\",\n",
    "            label=map_solution(solution_name),\n",
    "            color=colors[solution_name],\n",
    "            alpha=alpha,\n",
    "            linewidth=linewidth\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Run ID\")\n",
    "    plt.ylabel(\"Runtime per Frame (s)\")\n",
    "    plt.title(\"Runtime per Frame Across Sequences\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "    plt.legend()\n",
    "\n",
    "    # Save plot\n",
    "    fig_path = f\"{output_filename}.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_path, dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Runtime plot written to {os.path.abspath(fig_path)}\")\n",
    "\n",
    "\n",
    "generate_runtime_figures(\n",
    "    runtime_dict, \n",
    "    os.path.join(once_config[\"result_analytics\"][\"figure_output_base_path\"], \"runtime\"),\n",
    "    point_divisor=once_config[\"result_analytics\"][\"point_divisor\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6fb882",
   "metadata": {},
   "source": [
    "## Counts of items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e44995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_frame_counts():\n",
    "    once_loader_base = once_config[\"data\"][\"once_config_path\"]\n",
    "    with open(os.path.join(once_loader_base,\"config.yaml\"), \"r\") as f:\n",
    "        once_loader_config = yaml.safe_load(f)\n",
    "    splits = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "    total_seq_frames = []\n",
    "    for seq_id in seq_ids:\n",
    "        for split in splits:\n",
    "            potential_folder = os.path.join(\n",
    "                once_loader_base, \n",
    "                once_loader_config[\"once_data\"][\"cam_data\"],\n",
    "                split,\n",
    "                \"data\",\n",
    "                seq_id\n",
    "            )\n",
    "\n",
    "            if os.path.exists(potential_folder) and os.path.isdir(potential_folder):\n",
    "                total_frames_folder = os.path.join(potential_folder, \"cam01\")\n",
    "                count = 0\n",
    "                for fname in os.listdir(total_frames_folder):\n",
    "                    if fname.lower().endswith(\".jpg\"):\n",
    "                        name_only = os.path.splitext(fname)[0]\n",
    "                        if name_only.isdigit():   # all characters must be digits\n",
    "                            count += 1 \n",
    "                total_seq_frames.append(count)\n",
    "    return total_seq_frames\n",
    "\n",
    "\n",
    "def generate_n_items_table(runtime_dict, output_filename, total_seq_frames):\n",
    "    details_rows = []\n",
    "\n",
    "    for idx, (seq_id, seq_data) in enumerate(runtime_dict.items()):        \n",
    "        cd = seq_data[\"count_data\"]\n",
    "    \n",
    "        n_frames = cd[\"n_frames\"]\n",
    "        n_lanes = cd[\"n_lanes\"]\n",
    "        n_points = cd[\"n_points\"]\n",
    "\n",
    "        avg_lanes_per_valid_frame = n_lanes / n_frames if n_frames > 0 else None\n",
    "        avg_points_per_lane = n_points / n_lanes if n_lanes > 0 else None\n",
    "\n",
    "        # details rows (per-seq full record)\n",
    "        details_rows.append({\n",
    "            \"Run ID\": seq_id,\n",
    "            \"Total Frames\": total_seq_frames[idx],\n",
    "            \"Valid Frames\": n_frames,\n",
    "            \"Total Lanes\": n_lanes,\n",
    "            \"Avg Lanes per Valid Frame\": avg_lanes_per_valid_frame,\n",
    "            \"Avg Points per Lane\": avg_points_per_lane,\n",
    "            \"Total Points\": n_points\n",
    "        })\n",
    "\n",
    "    # Convert to DataFrames\n",
    "    details_df = pd.DataFrame(details_rows)\n",
    "\n",
    "    # Make output directory\n",
    "    os.makedirs(os.path.dirname(output_filename), exist_ok=True)\n",
    "\n",
    "    # Write Excel file\n",
    "    excel_path = f\"{output_filename}.xlsx\"\n",
    "    with pd.ExcelWriter(excel_path, engine=\"openpyxl\") as writer:\n",
    "        details_df.to_excel(writer, index=False, sheet_name=\"counts\")\n",
    "\n",
    "    print(f\"Counts table written to {os.path.abspath(excel_path)}\")\n",
    "\n",
    "\n",
    "total_seq_frames = get_raw_frame_counts()\n",
    "generate_n_items_table(runtime_dict, os.path.join(once_config[\"result_analytics\"][\"figure_output_base_path\"], \"num_items\"), total_seq_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f081927",
   "metadata": {},
   "source": [
    "## Generating Per-Solution Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1707e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution_detail_analytics(solution, percentiles=[95], max_thresh=None, calc_lane_details=True, seq_grouping_subdict=None):\n",
    "    if max_thresh is None:\n",
    "        max_thresh = np.inf\n",
    "\n",
    "    if seq_grouping_subdict is not None:\n",
    "        group_set = seq_grouping_subdict[\"group_set\"]\n",
    "    else:\n",
    "        group_set = [\"x\"]\n",
    "\n",
    "    def summarize_array(arr, percentiles=[90, 95], calculate_pointwise_metrics=True):\n",
    "        arr = np.asarray(arr, dtype=float)\n",
    "        arr = arr[np.isfinite(arr)]\n",
    "\n",
    "        if arr.size == 0:\n",
    "            return {'n': 0}\n",
    "        summary = {\n",
    "            'n': int(arr.size),\n",
    "            'mean': float(np.mean(arr)),\n",
    "            'median': float(np.median(arr)),\n",
    "            'std': float(np.std(arr, ddof=0)),\n",
    "            'min': float(np.min(arr)),\n",
    "            'max': float(np.max(arr)),\n",
    "            'skew': float(stats.skew(arr)),\n",
    "            'kurtosis': float(stats.kurtosis(arr, fisher=True)),\n",
    "        }\n",
    "\n",
    "        for p in percentiles:\n",
    "            summary[f'p{p}'] = float(np.percentile(arr, p))\n",
    "\n",
    "        if calculate_pointwise_metrics:\n",
    "            mse = float(np.mean(arr**2))\n",
    "            summary['MAE'] = float(np.mean(np.abs(arr)))\n",
    "            summary['MSE'] = mse\n",
    "            summary['RMSE'] = float(np.sqrt(mse))\n",
    "\n",
    "        return summary\n",
    "\n",
    "    all_results = {m: {} for m in group_set}\n",
    "    for set_item in group_set:\n",
    "        all_point_distances = []\n",
    "        all_curve_distances = []\n",
    "        all_lane_point_metrics = {\n",
    "            \"MAE\": [],\n",
    "            \"MSE\": [],\n",
    "            \"RMSE\": [],\n",
    "            \"Chamfer\": [],\n",
    "            \"Hausdorff\": []\n",
    "        }\n",
    "        all_lane_curve_metrics = {\n",
    "            \"MAE\": [],\n",
    "            \"MSE\": [],\n",
    "            \"RMSE\": []\n",
    "        }\n",
    "        set_item_count = 0\n",
    "        \n",
    "        for seq_id in tqdm(seq_ids, desc=(f\"Per-seq processing for {solution}\") + (f\" for {set_item}\" if seq_grouping_subdict is not None else \"\")):\n",
    "            if seq_grouping_subdict is not None:\n",
    "                if not seq_grouping_subdict[\"group_dict\"][seq_id] == set_item:\n",
    "                    continue\n",
    "            set_item_count += 1\n",
    "            solution_path = os.path.join(base_path, seq_id, results_eval_folder, solution + evaluation_extension)\n",
    "            with open(solution_path) as f:\n",
    "                solution_data = json.load(f)\n",
    "            \n",
    "            frames = solution_data.get(\"frames\", {})\n",
    "\n",
    "            for frame_data in frames.values():\n",
    "                lanes = frame_data.get(\"lanes\", {})\n",
    "\n",
    "                for lane_data in lanes.values():\n",
    "                    pp = lane_data.get(\"per_point\", {})\n",
    "\n",
    "                    # point distances\n",
    "                    if \"point_distances\" in pp:\n",
    "                        vals = [float(v) for v in pp[\"point_distances\"] if (np.isfinite(v) and v <= max_thresh)]\n",
    "                        all_point_distances.extend(vals)\n",
    "\n",
    "                    # curve distances\n",
    "                    if \"curve_distances\" in pp:\n",
    "                        vals = [float(v) for v in pp[\"curve_distances\"] if (np.isfinite(v) and v <= max_thresh)]\n",
    "                        all_curve_distances.extend(vals)\n",
    "\n",
    "                    mp = lane_data.get(\"metrics_point\", {})\n",
    "                    for key in all_lane_point_metrics:\n",
    "                        if key in mp:\n",
    "                            all_lane_point_metrics[key].append(mp[key])\n",
    "                        elif (key + \"_point\") in mp:\n",
    "                            all_lane_point_metrics[key].append(mp[key + \"_point\"])\n",
    "\n",
    "                    mc = lane_data.get(\"metrics_curve\", {})\n",
    "                    for key in all_lane_curve_metrics:\n",
    "                        if key in mc:\n",
    "                            all_lane_curve_metrics[key].append(mc[key])\n",
    "                        elif (key + \"_curve\") in mc:\n",
    "                            all_lane_curve_metrics[key].append(mc[key + \"_curve\"])\n",
    "\n",
    "        \n",
    "        # Compute full statistics\n",
    "        point_stats = summarize_array(all_point_distances, percentiles)\n",
    "        curve_stats = summarize_array(all_curve_distances, percentiles)\n",
    "\n",
    "        result = {\n",
    "            \"all_point_distances\": all_point_distances,\n",
    "            \"all_curve_distances\": all_curve_distances,\n",
    "            \"point_stats\": point_stats,\n",
    "            \"curve_stats\": curve_stats\n",
    "        }\n",
    "\n",
    "        if calc_lane_details:\n",
    "            result[\"all_lane_point_values\"] = all_lane_point_metrics\n",
    "            result[\"all_curve_point_values\"] = all_lane_curve_metrics\n",
    "            result[\"all_lane_point_stats\"] = {}\n",
    "            result[\"all_lane_curve_stats\"] = {}\n",
    "            for key, values in all_lane_point_metrics.items():\n",
    "                result[\"all_lane_point_stats\"][key] = summarize_array(np.array(values), percentiles=percentiles, calculate_pointwise_metrics=False)\n",
    "            for key, values in all_lane_curve_metrics.items():\n",
    "                result[\"all_lane_curve_stats\"][key] = summarize_array(np.array(values), percentiles=percentiles, calculate_pointwise_metrics=False)\n",
    "\n",
    "        all_results[set_item] = result\n",
    "\n",
    "    if seq_grouping_subdict is None:\n",
    "        return all_results[group_set[0]]\n",
    "    else:\n",
    "        return all_results\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def generate_solution_metrics_table(solution_dict, output_filename, nested_dict=False):\n",
    "    def process_single_dict(single_dict):\n",
    "        \"\"\"Process one solution_dict and return a DataFrame\"\"\"\n",
    "        all_innermost_keys = set()\n",
    "        for outer_key, outer_val in single_dict.items():\n",
    "            if isinstance(outer_val, dict):\n",
    "                for mid_key, mid_val in outer_val.items():\n",
    "                    if isinstance(mid_val, (int, float)):\n",
    "                        all_innermost_keys.add(mid_key)\n",
    "                    elif isinstance(mid_val, dict):\n",
    "                        for end_key, end_val in mid_val.items():\n",
    "                            if isinstance(end_val, (int, float)):\n",
    "                                all_innermost_keys.add(end_key)\n",
    "        all_innermost_keys = sorted(all_innermost_keys)\n",
    "\n",
    "        row_pairs = []\n",
    "        for outer_key, outer_val in single_dict.items():\n",
    "            if isinstance(outer_val, dict):\n",
    "                for mid_key, mid_val in outer_val.items():\n",
    "                    if isinstance(mid_val, (int, float)):\n",
    "                        row_pairs.append({\n",
    "                            \"label\": outer_key,\n",
    "                            \"data\": outer_val\n",
    "                        })\n",
    "                        break\n",
    "                    elif isinstance(mid_val, dict):\n",
    "                        for end_key, end_val in mid_val.items():\n",
    "                            if isinstance(end_val, (int, float)):\n",
    "                                row_pairs.append({\n",
    "                                    \"label\": f\"{outer_key} {mid_key}\",\n",
    "                                    \"data\": mid_val\n",
    "                                })\n",
    "                                break\n",
    "\n",
    "        rows = []\n",
    "        for pair in row_pairs:\n",
    "            row_dict = {\"Origin\": pair[\"label\"]}\n",
    "            for key in all_innermost_keys:\n",
    "                row_dict[key] = pair[\"data\"].get(key, None)\n",
    "            rows.append(row_dict)\n",
    "\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_filename), exist_ok=True)\n",
    "    excel_path = f\"{output_filename}.xlsx\"\n",
    "\n",
    "    with pd.ExcelWriter(excel_path, engine=\"openpyxl\") as writer:\n",
    "        if nested_dict:\n",
    "            # Each key in solution_dict is a sub-dictionary -> one sheet per key\n",
    "            for sheet_name, subdict in solution_dict.items():\n",
    "                df = process_single_dict(subdict)\n",
    "                df.to_excel(writer, index=False, sheet_name=str(sheet_name))\n",
    "        else:\n",
    "            # Single table\n",
    "            df = process_single_dict(solution_dict)\n",
    "            df.to_excel(writer, index=False, sheet_name=\"solution_metrics\")\n",
    "\n",
    "    print(f\"Solution metrics table written to {os.path.abspath(excel_path)}\")\n",
    "\n",
    "\n",
    "\n",
    "def prepare_output_folder(folder_name: str):\n",
    "    folder_path = os.path.join(once_config[\"result_analytics\"][\"figure_output_base_path\"], folder_name)\n",
    "\n",
    "    if os.path.exists(folder_path):\n",
    "        # Delete all contents inside the folder\n",
    "        num = len(os.listdir(folder_path))\n",
    "        for name in os.listdir(folder_path):\n",
    "            item = os.path.join(folder_path, name)\n",
    "            if os.path.isfile(item):\n",
    "                os.remove(item)\n",
    "            elif os.path.isdir(item):\n",
    "                shutil.rmtree(item)\n",
    "        print(f\"[INFO] Cleared {num} items in existing folder: {folder_path}\")\n",
    "    else:\n",
    "        # Create the folder\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        print(f\"[INFO] Created new folder: {folder_path}\")\n",
    "\n",
    "    return folder_path\n",
    "\n",
    "\n",
    "\n",
    "def plot_distance_distributions(data1, data2, plot_points=True, bins=50, verbose=True, labels=None, outfolder=None):\n",
    "    # Extract arrays\n",
    "    all_point = np.asarray(data1, dtype=float)\n",
    "    all_curve = np.asarray(data2, dtype=float)\n",
    "\n",
    "    # Select active dataset\n",
    "    if plot_points:\n",
    "        data = all_point\n",
    "        label = \"Point Euclidean Distance\"\n",
    "    else:\n",
    "        data = all_curve\n",
    "        label = \"Curve Euclidean Distance\"\n",
    "\n",
    "    # Remove non-finite values\n",
    "    data = data[np.isfinite(data)]\n",
    "    all_point_clean = all_point[np.isfinite(all_point)]\n",
    "    all_curve_clean = all_curve[np.isfinite(all_curve)]\n",
    "\n",
    "    if labels is not None:\n",
    "        num_graph_labels = len(labels[next(iter(labels))])\n",
    "        if (verbose and not num_graph_labels == 7) or (not verbose and not num_graph_labels == 2):\n",
    "            print(f\"[Error]: Not enough graph labels, needed {7 if verbose else 2}, got {num_graph_labels}.\")\n",
    "            labels = None\n",
    "    if labels is None:\n",
    "        labels = {\n",
    "            \"titles\": [\n",
    "                \"Overlaid Histogram: Point vs Curve Distances\",\n",
    "                \"Overlaid Log-Scaled Histogram: Point vs Curve Distances\",\n",
    "                f\"Histogram of {label}\",\n",
    "                f\"Log-Scaled Histogram of {label}\",\n",
    "                f\"CDF of {label}\",\n",
    "                f\"Box Plot of {label}\",\n",
    "                f\"Violin Plot of {label}\"\n",
    "            ],\n",
    "            \"xlabel\": [\n",
    "                \"Euclidean Distance (m)\",\n",
    "                \"Euclidean Distance (m)\",\n",
    "                label + \" (m)\",\n",
    "                label + \" (m)\",\n",
    "                label,\n",
    "                label,\n",
    "                label\n",
    "            ],\n",
    "            \"ylabel\": [\n",
    "                \"Count\",\n",
    "                \"Log Count\"\n",
    "                \"Count\",\n",
    "                \"Log Count\",\n",
    "                \"CDF\",\n",
    "                \"\",\n",
    "                \"\"\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    def save_plot_if_needed(title, outfolder):\n",
    "        if outfolder is None:\n",
    "            plt.show()\n",
    "            return\n",
    "        safe_title = re.sub(r'[<>:\"/\\\\|?*]', '_', title)\n",
    "        safe_title = re.sub(r'\\s+', '_', safe_title)\n",
    "        safe_title = re.sub(r'_+', '_', safe_title)\n",
    "        fname = os.path.join(outfolder, safe_title + \".png\")\n",
    "        if os.path.exists(fname):\n",
    "            i = 1\n",
    "            while True:\n",
    "                alt = os.path.join(outfolder, f\"{safe_title}{i}.png\")\n",
    "                if not os.path.exists(alt):\n",
    "                    print(f\"[Error] {fname} exists, saving as {safe_title}{i}.png\")\n",
    "                    fname = alt\n",
    "                    break\n",
    "                i += 1\n",
    "        plt.savefig(fname, dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    idx = 0\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(all_point_clean, bins=bins, alpha=0.5, label=\"Point Distance\")\n",
    "    plt.hist(all_curve_clean, bins=bins, alpha=0.5, label=\"Curve Distance\")\n",
    "    plt.title(labels[\"titles\"][idx])\n",
    "    plt.xlabel(labels[\"xlabel\"][idx])\n",
    "    plt.ylabel(labels[\"ylabel\"][idx])\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    save_plot_if_needed(labels[\"titles\"][idx], outfolder)\n",
    "    idx += 1\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(all_point_clean, bins=bins, alpha=0.5, label=\"Point Distance\", log=True)\n",
    "    plt.hist(all_curve_clean, bins=bins, alpha=0.5, label=\"Curve Distance\", log=True)\n",
    "    plt.title(labels[\"titles\"][idx])\n",
    "    plt.xlabel(labels[\"xlabel\"][idx])\n",
    "    plt.ylabel(labels[\"ylabel\"][idx])\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    save_plot_if_needed(labels[\"titles\"][idx], outfolder)\n",
    "    idx += 1\n",
    "\n",
    "    if verbose:\n",
    "        plt.figure()\n",
    "        plt.hist(data, bins=bins)\n",
    "        plt.title(labels[\"titles\"][idx])\n",
    "        plt.xlabel(labels[\"xlabel\"][idx])\n",
    "        plt.ylabel(labels[\"ylabel\"][idx])\n",
    "        plt.tight_layout()\n",
    "        save_plot_if_needed(labels[\"titles\"][idx], outfolder)\n",
    "        idx += 1\n",
    "\n",
    "    if verbose:\n",
    "        plt.figure()\n",
    "        plt.hist(data, bins=bins, log=True)\n",
    "        plt.title(labels[\"titles\"][idx])\n",
    "        plt.xlabel(labels[\"xlabel\"][idx])\n",
    "        plt.ylabel(labels[\"ylabel\"][idx])\n",
    "        plt.tight_layout()\n",
    "        save_plot_if_needed(labels[\"titles\"][idx], outfolder)\n",
    "        idx += 1\n",
    "\n",
    "    if verbose:\n",
    "        sorted_data = np.sort(data)\n",
    "        yvals = np.arange(1, len(sorted_data) + 1) / len(sorted_data)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(sorted_data, yvals)\n",
    "        plt.title(labels[\"titles\"][idx])\n",
    "        plt.xlabel(labels[\"xlabel\"][idx])\n",
    "        plt.ylabel(labels[\"ylabel\"][idx])\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        save_plot_if_needed(labels[\"titles\"][idx], outfolder)\n",
    "        idx += 1\n",
    "\n",
    "    if verbose:\n",
    "        plt.figure()\n",
    "        plt.boxplot(data, vert=False)\n",
    "        plt.title(labels[\"titles\"][idx])\n",
    "        plt.xlabel(labels[\"xlabel\"][idx])\n",
    "        plt.tight_layout()\n",
    "        save_plot_if_needed(labels[\"titles\"][idx], outfolder)\n",
    "        idx += 1\n",
    "\n",
    "    if verbose:\n",
    "        plt.figure()\n",
    "        plt.violinplot(data, vert=False, showmeans=True)\n",
    "        plt.title(labels[\"titles\"][idx])\n",
    "        plt.xlabel(labels[\"xlabel\"][idx])\n",
    "        plt.tight_layout()\n",
    "        save_plot_if_needed(labels[\"titles\"][idx], outfolder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f419d599",
   "metadata": {},
   "source": [
    "### Thesis Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14be16db",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles = once_config[\"result_analytics\"][\"percentiles\"]\n",
    "thesis_details_dict = solution_detail_analytics(thesis_solution, percentiles, max_thresh=None)\n",
    "generate_solution_metrics_table(thesis_details_dict, os.path.join(once_config[\"result_analytics\"][\"figure_output_base_path\"], \"thesis_metrics\"))\n",
    "\n",
    "if True:\n",
    "    access_index = 2\n",
    "    n_percent_val = str(percentiles[access_index])\n",
    "    n_percent_label = 'p' + n_percent_val\n",
    "\n",
    "    larger_metric = \"point_stats\" if thesis_details_dict[\"point_stats\"][n_percent_label] > thesis_details_dict[\"curve_stats\"][n_percent_label] else \"curve_stats\"\n",
    "    print(f\"{n_percent_val}% thresh for point: {thesis_details_dict['point_stats'][n_percent_label]}\\n{n_percent_val}% thresh for curve: {thesis_details_dict['curve_stats'][n_percent_label]}\")\n",
    "    print(f\"Threshold falls to: {thesis_details_dict[larger_metric][n_percent_label]}\")\n",
    "    n_percent_thesis_details_dict = solution_detail_analytics(\n",
    "        thesis_solution, \n",
    "        once_config[\"result_analytics\"][\"percentiles\"], \n",
    "        max_thresh=thesis_details_dict[larger_metric][n_percent_label],\n",
    "        calc_lane_details=False\n",
    "    )\n",
    "    generate_solution_metrics_table(n_percent_thesis_details_dict, os.path.join(once_config[\"result_analytics\"][\"figure_output_base_path\"], f\"thesis_{n_percent_val}_metrics\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1f5c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Weather/tod comparison\n",
    "def build_weather_dict():\n",
    "    weather_dict = {m:{} for m in seq_ids}\n",
    "    period_dict = {m:{} for m in seq_ids}\n",
    "    all_weathers = set()\n",
    "    all_periods = set()\n",
    "    for seq_id in seq_ids:\n",
    "        calib_file = os.path.join(\n",
    "            once_config[\"data\"][\"base_path\"],\n",
    "            seq_id,\n",
    "            once_config[\"data\"][\"calibration_path\"]\n",
    "        )\n",
    "        if not os.path.exists(calib_file):\n",
    "            print(f\"[ERROR]: Calibration file not found: {calib_file}\")\n",
    "            sys.exit(1)\n",
    "        with open(calib_file, 'r') as f:\n",
    "            calibration_data = json.load(f)\n",
    "        weather = calibration_data[\"weather\"]\n",
    "        period = calibration_data[\"period\"]\n",
    "\n",
    "        all_weathers.add(weather)\n",
    "        all_periods.add(period)\n",
    "        weather_dict[seq_id] = weather\n",
    "        period_dict[seq_id] = period\n",
    "\n",
    "    seq_grouping_dict = {\n",
    "        \"weather\": {\n",
    "            \"group_dict\": weather_dict,\n",
    "            \"group_set\": all_weathers\n",
    "        },\n",
    "        \"period\": {\n",
    "            \"group_dict\": period_dict,\n",
    "            \"group_set\": all_periods\n",
    "        }\n",
    "    }\n",
    "    return seq_grouping_dict\n",
    "seq_grouping_dict = build_weather_dict()\n",
    "\n",
    "\n",
    "def print_group_counts(data, print_details=False):\n",
    "    group_dict = data.get(\"group_dict\", {})\n",
    "    group_set = data.get(\"group_set\", [])\n",
    "\n",
    "    # Build reverse lookup: item â†’ list of ids\n",
    "    item_to_ids = {item: [] for item in group_set}\n",
    "    for gid, item in group_dict.items():\n",
    "        if item in item_to_ids:\n",
    "            item_to_ids[item].append(gid)\n",
    "        else:\n",
    "            # in case group_dict contains an item not listed in group_set\n",
    "            item_to_ids.setdefault(item, []).append(gid)\n",
    "\n",
    "    # --- First section: print item + count ---\n",
    "    for item in sorted(item_to_ids.keys()):\n",
    "        print(f\"{item}: {len(item_to_ids[item])}\")\n",
    "\n",
    "    # --- Second section (optional): detailed listing ---\n",
    "    if print_details:\n",
    "        print(\"\\n--- Details ---\")\n",
    "        for item in sorted(item_to_ids.keys()):\n",
    "            ids = item_to_ids[item]\n",
    "            print(f\"{item}:\")\n",
    "            for gid in sorted(ids):\n",
    "                print(f\"    {gid}\")\n",
    "\n",
    "seq_grouping_dict = build_weather_dict()\n",
    "\n",
    "print_group_counts(seq_grouping_dict[\"weather\"], print_details=False)\n",
    "thesis_weather_dict = solution_detail_analytics(thesis_solution, percentiles, max_thresh=None, seq_grouping_subdict=seq_grouping_dict[\"weather\"])\n",
    "generate_solution_metrics_table(thesis_weather_dict, os.path.join(once_config[\"result_analytics\"][\"figure_output_base_path\"], \"thesis_weather\"), nested_dict=True)\n",
    "\n",
    "print_group_counts(seq_grouping_dict[\"period\"], print_details=False)\n",
    "thesis_period_dict = solution_detail_analytics(thesis_solution, percentiles, max_thresh=None, seq_grouping_subdict=seq_grouping_dict[\"period\"])\n",
    "generate_solution_metrics_table(thesis_period_dict, os.path.join(once_config[\"result_analytics\"][\"figure_output_base_path\"], \"thesis_period\"), nested_dict=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70ce90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfolder = prepare_output_folder(\"thesis_graphs\")\n",
    "\n",
    "# labels = {\n",
    "#     \"titles\": [\"Aggregate Point Errors Histogram\", \"Log-Scaled Aggregate Point Errors Histogram\"],\n",
    "#     \"xlabel\": [\"Distance (m)\", \"Distance (m)\"],\n",
    "#     \"ylabel\": [\"Count\", \"Log Count\"]\n",
    "# }\n",
    "plot_distance_distributions(\n",
    "   thesis_details_dict[\"all_point_distances\"], \n",
    "   thesis_details_dict[\"all_curve_distances\"], \n",
    "   verbose=False,\n",
    "   outfolder=outfolder,\n",
    "#    labels=labels\n",
    ")\n",
    "\n",
    "if \"n_percent_thesis_details_dict\" in globals():\n",
    "    n_pecent_labels = {\n",
    "        \"titles\": [ f\"Overlaid Histogram ({n_percent_val}%): Point vs Curve Distances\", f\"Overlaid Log-Scaled Histogram ({n_percent_val}%): Point vs Curve Distances\"],\n",
    "        \"xlabel\": [\"Euclidean Distance (m)\", \"Euclidean Distance (m)\"],\n",
    "        \"ylabel\": [\"Count\", \"Log Count\"]\n",
    "    } \n",
    "    plot_distance_distributions(\n",
    "      n_percent_thesis_details_dict[\"all_point_distances\"], \n",
    "      n_percent_thesis_details_dict[\"all_curve_distances\"], \n",
    "      verbose=False, \n",
    "      labels=n_pecent_labels,\n",
    "      outfolder=outfolder\n",
    "    )\n",
    "\n",
    "\n",
    "rmse_labels = {\n",
    "    \"titles\": [\"Overlaid Histogram: Point RMSE vs Curve RMSE\", \"Overlaid Log-Scaled Histogram: Point RMSE vs Curve RMSE\"],\n",
    "    # \"titles\": [\"Aggregate Lane Errors Histogram\", \"Log-Scaled Aggregate Lane Errors Histogram\"],\n",
    "    \"xlabel\": [\"Distance (m)\", \"Distance (m)\"],\n",
    "    \"ylabel\": [\"Count\", \"Log Count\"]\n",
    "}\n",
    "plot_distance_distributions(\n",
    "    thesis_details_dict[\"all_lane_point_values\"][\"RMSE\"], \n",
    "    thesis_details_dict[\"all_curve_point_values\"][\"RMSE\"], \n",
    "    verbose=False, \n",
    "    labels=rmse_labels,\n",
    "    outfolder=outfolder\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02650241",
   "metadata": {},
   "source": [
    "### Other solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78db3629",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Solution A: pure intrinsic\n",
    "percentiles = once_config[\"result_analytics\"][\"percentiles\"]\n",
    "for solution in all_solutions:\n",
    "    if solution == thesis_solution:\n",
    "        continue\n",
    "    solution_details_dict = solution_detail_analytics(solution, percentiles, max_thresh=None)\n",
    "    solution_name = file_map_solution(solution)\n",
    "    generate_solution_metrics_table(solution_details_dict, os.path.join(once_config[\"result_analytics\"][\"figure_output_base_path\"], f\"{solution_name}_metrics\"))\n",
    "    \n",
    "    outfolder = prepare_output_folder(f\"{solution_name}_graphs\")\n",
    "    plot_distance_distributions(\n",
    "        solution_details_dict[\"all_point_distances\"], \n",
    "        solution_details_dict[\"all_curve_distances\"], \n",
    "        verbose=False,\n",
    "        outfolder=outfolder,\n",
    "        #    labels=labels\n",
    "    )\n",
    "    rmse_labels = {\n",
    "        \"titles\": [\"Overlaid Histogram: Point RMSE vs Curve RMSE\", \"Overlaid Log-Scaled Histogram: Point RMSE vs Curve RMSE\"],\n",
    "        # \"titles\": [\"Aggregate Lane Errors Histogram\", \"Log-Scaled Aggregate Lane Errors Histogram\"],\n",
    "        \"xlabel\": [\"Distance (m)\", \"Distance (m)\"],\n",
    "        \"ylabel\": [\"Count\", \"Log Count\"]\n",
    "    }\n",
    "    plot_distance_distributions(\n",
    "        solution_details_dict[\"all_lane_point_values\"][\"RMSE\"], \n",
    "        solution_details_dict[\"all_curve_point_values\"][\"RMSE\"], \n",
    "        verbose=False, \n",
    "        labels=rmse_labels,\n",
    "        outfolder=outfolder\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a5e380",
   "metadata": {},
   "source": [
    "## Comparison Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2671fe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_first_eval_json(root_folder):\n",
    "    for folder in sorted(os.listdir(root_folder)):\n",
    "        # Must be a directory with numeric name\n",
    "        if not folder.isdigit():\n",
    "            continue\n",
    "\n",
    "        eval_dir = os.path.join(root_folder, folder, once_config[\"result_analytics\"][\"results_eval_folder\"])\n",
    "        if not os.path.isdir(eval_dir):\n",
    "            continue\n",
    "\n",
    "        # Search inside the evaluation folder\n",
    "        for fname in sorted(os.listdir(eval_dir)):\n",
    "            if fname.endswith(once_config[\"result_analytics\"][\"evaluation_extension\"]):\n",
    "                base = fname[:-len(once_config[\"result_analytics\"][\"evaluation_extension\"])]\n",
    "                if base in all_solutions:\n",
    "                    return os.path.join(eval_dir, fname)\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def print_eval_json_structure(json_path):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    print(f\"\\nLoaded JSON: {json_path}\\n\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # 1. Get lane_aggregates keys\n",
    "    # -------------------------------\n",
    "    frame_aggregates = data.get(\"frame_aggregates\", {})\n",
    "    lane_aggregates = data.get(\"lane_aggregates\", {})\n",
    "    point_aggregates = data.get(\"point_aggregates\", {})\n",
    "\n",
    "    # -------------------------------\n",
    "    # 2. Get first frame and first lane\n",
    "    # -------------------------------\n",
    "    frames = data.get(\"frames\", {})\n",
    "    if not frames:\n",
    "        print(\"No frames\")\n",
    "        return\n",
    "\n",
    "    first_frame_key = next(iter(frames.keys()))\n",
    "    first_frame = frames[first_frame_key]\n",
    "\n",
    "    lanes = first_frame.get(\"lanes\", {})\n",
    "    if not lanes:\n",
    "        print(\"No lanes in first frame\")\n",
    "        return\n",
    "\n",
    "    first_lane_key = next(iter(lanes.keys()))\n",
    "    first_lane = lanes[first_lane_key]\n",
    "\n",
    "    metrics_point = first_lane.get(\"metrics_point\", {})\n",
    "    metrics_curve = first_lane.get(\"metrics_curve\", {})\n",
    "    frame_metrics = first_frame.get(\"frame_metrics\", {})\n",
    "\n",
    "    # -------------------------------\n",
    "    # PRINT OUTPUT\n",
    "    # -------------------------------\n",
    "\n",
    "    print(\"1) Subkeys in metrics_point:\")\n",
    "    for k in metrics_point.keys():\n",
    "        print(f\"   - {k}\")\n",
    "\n",
    "    print(\"\\n2) Subkeys in metrics_curve:\")\n",
    "    for k in metrics_curve.keys():\n",
    "        print(f\"   - {k}\")\n",
    "\n",
    "    print(\"\\n3) Subkeys in frame_metrics:\")\n",
    "    for k in frame_metrics.keys():\n",
    "        print(f\"   - {k}\")\n",
    "\n",
    "    print(\"\\n4) Subkeys in frame_aggregates:\")\n",
    "    for k in frame_aggregates.keys():\n",
    "        print(f\"   - {k}\")\n",
    "\n",
    "    print(\"\\n4) Subkeys in lane_aggregates:\")\n",
    "    for k in lane_aggregates.keys():\n",
    "        print(f\"   - {k}\")\n",
    "\n",
    "    print(\"\\n5) Subkeys in point_aggregates\")\n",
    "    for k in point_aggregates.keys():\n",
    "        print(f\"   - {k}\")\n",
    "\n",
    "    print(\"\\n5) Subkeys of each lane and point agg sub-metric:\")\n",
    "    metric_dicts = iter(lane_aggregates.values())\n",
    "    first_metric_dict = next(metric_dicts, {})\n",
    "    for k in first_metric_dict.keys():\n",
    "        print(f\"   - {k}\")\n",
    "\n",
    "\n",
    "# Turn true to see the available keys for eval_metrics\n",
    "if False:\n",
    "    json_file = find_first_eval_json(once_config[\"output\"][\"base_path\"])\n",
    "    if json_file:\n",
    "        print_eval_json_structure(json_file)\n",
    "    else:\n",
    "        print(\"No matching eval JSON file found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3863c426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics to check\n",
    "eval_metrics = {\n",
    "    \"frame_aggregates\": [],\n",
    "    \"lane_aggregates\": [],\n",
    "    \"point_aggregates\": [],\n",
    "    \"frame_wins\": [\n",
    "        \"MAE_point_mean\", \"MAE_point_median\", \n",
    "        \"RMSE_point_mean\", \"RMSE_point_median\",\n",
    "        \"MAE_curve_mean\", \"MAE_curve_median\",\n",
    "        \"RMSE_curve_mean\", \"RMSE_curve_median\"\n",
    "    ],\n",
    "    \"lane_wins_point\":  [\"MAE_point\", \"RMSE_point\"],\n",
    "    \"lane_wins_curve\": [\"MAE_curve\", \"RMSE_curve\"]\n",
    "}\n",
    "aggregates_submetrics = []\n",
    "\n",
    "def create_wins_dict():\n",
    "    frame_agg_metrics = eval_metrics[\"frame_aggregates\"]\n",
    "    lane_agg_metrics = eval_metrics[\"lane_aggregates\"]\n",
    "    point_agg_metrics = eval_metrics[\"point_aggregates\"]\n",
    "    sub_metrics = aggregates_submetrics\n",
    "    frame_metrics = eval_metrics[\"frame_wins\"]\n",
    "    lane_metrics_point = eval_metrics[\"lane_wins_point\"]\n",
    "    lane_wins_curve = eval_metrics[\"lane_wins_curve\"]\n",
    "    \n",
    "\n",
    "    def create_seq_dic():\n",
    "        return {\n",
    "            \"frame_aggregates\": {m: {n: 0 for n in sub_metrics} for m in frame_agg_metrics},\n",
    "            \"lane_aggregates\": {m: {n: 0 for n in sub_metrics} for m in lane_agg_metrics},\n",
    "            \"point_aggregates\": {m: {n: 0 for n in sub_metrics} for m in point_agg_metrics},\n",
    "            \"frame_wins\": {m: 0 for m in frame_metrics},\n",
    "            \"lane_wins_point\": {m: 0 for m in lane_metrics_point},\n",
    "            \"lane_wins_curve\": {m: 0 for m in lane_wins_curve}\n",
    "        }\n",
    "\n",
    "    solution_equal_evaluation_percent = 1 + once_config[\"result_analytics\"][\"solution_equal_evaluation_percent\"]\n",
    "    compare_solutions_dict = {}\n",
    "    for solution in alternative_solutions:\n",
    "\n",
    "        per_seq_dict = {m: create_seq_dic() for m in seq_ids}\n",
    "\n",
    "        for seq_id in tqdm(seq_ids, desc=f\"Per-seq processing for {solution}\"):\n",
    "            try:\n",
    "                # Load thesis solution\n",
    "                thesis_path = os.path.join(base_path, seq_id, results_eval_folder, thesis_solution + evaluation_extension)\n",
    "                with open(thesis_path) as f:\n",
    "                    thesis_data = json.load(f)\n",
    "\n",
    "                # Load other solutions\n",
    "                path = os.path.join(base_path, seq_id, results_eval_folder, solution + evaluation_extension)\n",
    "                with open(path) as f:\n",
    "                    other_solution = json.load(f)\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "\n",
    "            for metric in frame_agg_metrics:\n",
    "                for sub_metric in sub_metrics:\n",
    "                    thesis_value = thesis_data[\"frame_aggregates\"][metric][sub_metric]\n",
    "                    other = other_solution[\"frame_aggregates\"][metric][sub_metric]\n",
    "                per_seq_dict[seq_id][\"frame_aggregates\"][metric][sub_metric] = int(thesis_value < other * solution_equal_evaluation_percent)\n",
    "\n",
    "            # ---------- Lane aggregates ----------\n",
    "            for metric in lane_agg_metrics:\n",
    "                for sub_metric in sub_metrics:\n",
    "                    thesis_value = thesis_data[\"lane_aggregates\"][metric][sub_metric]\n",
    "                    other = other_solution[\"lane_aggregates\"][metric][sub_metric]\n",
    "                per_seq_dict[seq_id][\"lane_aggregates\"][metric][sub_metric] = int(thesis_value < other * solution_equal_evaluation_percent)\n",
    "            \n",
    "            # ---------- Point aggregates ----------\n",
    "            for metric in point_agg_metrics:\n",
    "                for sub_metric in sub_metrics:\n",
    "                    thesis_value = thesis_data[\"point_aggregates\"][metric][sub_metric]\n",
    "                    other = other_solution[\"point_aggregates\"][metric][sub_metric]\n",
    "                per_seq_dict[seq_id][\"point_aggregates\"][metric][sub_metric] = int(thesis_value < other * solution_equal_evaluation_percent)\n",
    "                \n",
    "            # ---------- Per-frame ----------\n",
    "            for frame_id, frame_data in thesis_data[\"frames\"].items():\n",
    "                for metric in frame_metrics:\n",
    "                    thesis_value = frame_data[\"frame_metrics\"][metric]\n",
    "                    other = other_solution[\"frames\"][frame_id][\"frame_metrics\"][metric]\n",
    "                    if thesis_value < other * solution_equal_evaluation_percent:\n",
    "                        per_seq_dict[seq_id][\"frame_wins\"][metric] += 1\n",
    "\n",
    "                # ---------- Per-lane ----------\n",
    "                for lane_id, lane_data in frame_data[\"lanes\"].items():\n",
    "                    for metric in lane_metrics_point:\n",
    "                        thesis_value = lane_data[\"metrics_point\"][metric]\n",
    "                        other = other_solution[\"frames\"][frame_id][\"lanes\"][lane_id][\"metrics_point\"][metric]\n",
    "                        if thesis_value < other * solution_equal_evaluation_percent:\n",
    "                            per_seq_dict[seq_id][\"lane_wins_point\"][metric] += 1\n",
    "                    for metric in lane_wins_curve:\n",
    "                        thesis_value = lane_data[\"metrics_curve\"][metric]\n",
    "                        other = other_solution[\"frames\"][frame_id][\"lanes\"][lane_id][\"metrics_curve\"][metric]\n",
    "                        if thesis_value < other * solution_equal_evaluation_percent:\n",
    "                            per_seq_dict[seq_id][\"lane_wins_curve\"][metric] += 1\n",
    "\n",
    "            for metric in frame_metrics:\n",
    "                per_seq_dict[seq_id][\"frame_wins\"][metric] /= runtime_dict[seq_id][\"count_data\"][\"n_frames\"]\n",
    "            for metric in lane_metrics_point:\n",
    "                per_seq_dict[seq_id][\"lane_wins_point\"][metric] /= runtime_dict[seq_id][\"count_data\"][\"n_lanes\"]\n",
    "            for metric in lane_wins_curve:\n",
    "                per_seq_dict[seq_id][\"lane_wins_curve\"][metric] /= runtime_dict[seq_id][\"count_data\"][\"n_lanes\"]\n",
    "\n",
    "        overall_seq_dict = create_seq_dic()\n",
    "        for seq_id in seq_ids:\n",
    "            for m in lane_agg_metrics:\n",
    "                for n in sub_metrics:\n",
    "                    overall_seq_dict[\"frame_aggregates\"][m][n] += 1 if per_seq_dict[seq_id][\"frame_aggregates\"][m][n] else 0\n",
    "            for m in lane_agg_metrics:\n",
    "                for n in sub_metrics:\n",
    "                    overall_seq_dict[\"lane_aggregates\"][m][n] += 1 if per_seq_dict[seq_id][\"lane_aggregates\"][m][n] else 0\n",
    "            for m in point_agg_metrics:\n",
    "                for n in sub_metrics:\n",
    "                    overall_seq_dict[\"point_aggregates\"][m][n] += 1 if per_seq_dict[seq_id][\"point_aggregates\"][m][n] else 0\n",
    "            for m in frame_metrics:\n",
    "                overall_seq_dict[\"frame_wins\"][m] += per_seq_dict[seq_id][\"frame_wins\"][m] * runtime_dict[seq_id][\"count_data\"][\"n_frames\"]\n",
    "            for m in lane_metrics_point:\n",
    "                overall_seq_dict[\"lane_wins_point\"][m] += per_seq_dict[seq_id][\"lane_wins_point\"][m] * runtime_dict[seq_id][\"count_data\"][\"n_lanes\"]\n",
    "            for m in lane_wins_curve:\n",
    "                overall_seq_dict[\"lane_wins_curve\"][m] += per_seq_dict[seq_id][\"lane_wins_curve\"][m] * runtime_dict[seq_id][\"count_data\"][\"n_lanes\"]\n",
    "\n",
    "        for m in lane_agg_metrics:\n",
    "            for n in sub_metrics:\n",
    "                overall_seq_dict[\"frame_aggregates\"][m][n] /= len(seq_ids)\n",
    "        for m in lane_agg_metrics:\n",
    "            for n in sub_metrics:\n",
    "                overall_seq_dict[\"lane_aggregates\"][m][n] /= len(seq_ids)\n",
    "        for m in point_agg_metrics:\n",
    "            for n in sub_metrics:\n",
    "                overall_seq_dict[\"point_aggregates\"][m][n] /= len(seq_ids)\n",
    "        total_n_frames = sum([runtime_dict[seq_id][\"count_data\"][\"n_frames\"] for seq_id in seq_ids])\n",
    "        for m in frame_metrics:\n",
    "            overall_seq_dict[\"frame_wins\"][m] /= total_n_frames\n",
    "        total_n_lanes = sum([runtime_dict[seq_id][\"count_data\"][\"n_lanes\"] for seq_id in seq_ids])\n",
    "        for m in lane_metrics_point:\n",
    "            overall_seq_dict[\"lane_wins_point\"][m] /= total_n_lanes\n",
    "        for m in lane_wins_curve:\n",
    "            overall_seq_dict[\"lane_wins_curve\"][m] /= total_n_lanes\n",
    "\n",
    "        compare_solutions_dict[solution] = {\n",
    "            \"overall\": overall_seq_dict,\n",
    "            \"individual\": per_seq_dict\n",
    "        }\n",
    "\n",
    "    return compare_solutions_dict\n",
    "\n",
    "compare_solutions_dict = create_wins_dict()\n",
    "if True:\n",
    "    outpath = os.path.join(once_config[\"result_analytics\"][\"figure_output_base_path\"], \"metric_comparison.json\")\n",
    "    with open(outpath, 'w') as f:\n",
    "        json.dump(compare_solutions_dict, f, indent=4)\n",
    "    print(f\"Solution comparison data saved to {outpath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c255e470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gt_curve_distance(partial_out_path, output_filename):\n",
    "    base_path = once_config[\"output\"][\"base_path\"]\n",
    "    all_gt_dists = []\n",
    "\n",
    "    for seq_id in tqdm(seq_ids, desc=f\"Per-seq processing (GT distances) for {partial_out_path}\"):\n",
    "        try:\n",
    "            thesis_path = os.path.join(base_path, seq_id, results_eval_folder, partial_out_path + evaluation_extension)\n",
    "            with open(thesis_path) as f:\n",
    "                thesis_data = json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "\n",
    "        # Extract distances from all frames â†’ lanes â†’ per_point â†’ gt_to_curve_distances\n",
    "        frames = thesis_data.get(\"frames\", {})\n",
    "        for _, frame_data in frames.items():\n",
    "            lanes = frame_data.get(\"lanes\", {})\n",
    "            for _, lane_data in lanes.items():\n",
    "                per_point = lane_data.get(\"per_point\", {})\n",
    "                gt_dists = per_point.get(\"gt_to_curve_distances\", [])\n",
    "                if isinstance(gt_dists, list):\n",
    "                    all_gt_dists.extend(gt_dists)\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Compute metrics\n",
    "    # -------------------------------------------------\n",
    "    if len(all_gt_dists) == 0:\n",
    "        print(\"No gt_to_curve_distances found.\")\n",
    "        return\n",
    "\n",
    "    arr = np.array(all_gt_dists)\n",
    "\n",
    "    metrics = {\n",
    "        \"mean\": float(np.mean(arr)),\n",
    "        \"median\": float(np.median(arr)),\n",
    "        \"max\": float(np.max(arr)),\n",
    "        \"std\": float(np.std(arr)),\n",
    "        \"mae\": float(np.mean(np.abs(arr))),\n",
    "        \"rmse\": float(np.sqrt(np.mean(arr ** 2)))\n",
    "    }\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Convert to a dataframe that matches your structure:\n",
    "    #   Origin | mean | max | std | mae | rmse\n",
    "    # -------------------------------------------------\n",
    "    rows = [{\n",
    "        \"Origin\": \"gt_to_curve_distances\",\n",
    "        **metrics\n",
    "    }]\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Save to Excel (same pattern as your other function)\n",
    "    # -------------------------------------------------\n",
    "    os.makedirs(os.path.dirname(output_filename), exist_ok=True)\n",
    "    excel_path = f\"{output_filename}.xlsx\"\n",
    "\n",
    "    with pd.ExcelWriter(excel_path, engine=\"openpyxl\") as writer:\n",
    "        df.to_excel(writer, index=False, sheet_name=\"gt_curve_distances\")\n",
    "\n",
    "    print(f\"GTâ†’curve distance metrics written to {os.path.abspath(excel_path)}\")\n",
    "\n",
    "get_gt_curve_distance(thesis_solution, os.path.join(once_config[\"result_analytics\"][\"figure_output_base_path\"], \"gt_curve_metrics\"))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e32174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_compare_metric_figures(\n",
    "    main_dict,\n",
    "    output_filename,\n",
    "    y_labels=None\n",
    "):\n",
    "    rows = []\n",
    "\n",
    "    for metric_category, submetric_list in eval_metrics.items():\n",
    "\n",
    "        for submetric in submetric_list:\n",
    "\n",
    "            # Case 1: aggregate metrics â†’ has mean/median\n",
    "            if metric_category.endswith(\"aggregates\"):\n",
    "                for agg_sub in aggregates_submetrics:\n",
    "                    metric_name = f\"{submetric} {agg_sub}\"\n",
    "\n",
    "                    row = {\n",
    "                        \"Metric Category\": metric_category,\n",
    "                        \"Metric\": metric_name\n",
    "                    }\n",
    "\n",
    "                    for ok in alternative_solutions:\n",
    "                        val = (\n",
    "                            main_dict.get(ok, {})\n",
    "                                    .get(\"overall\", {})\n",
    "                                    .get(metric_category, {})\n",
    "                                    .get(submetric, {})\n",
    "                                    .get(agg_sub, None)\n",
    "                        )\n",
    "                        row[ok] = val\n",
    "\n",
    "                    rows.append(row)\n",
    "\n",
    "            # Case 2: simple one-level metrics\n",
    "            else:\n",
    "                metric_name = submetric\n",
    "\n",
    "                row = {\n",
    "                    \"Metric Category\": metric_category,\n",
    "                    \"Metric\": metric_name\n",
    "                }\n",
    "\n",
    "                for ok in alternative_solutions:\n",
    "                    val = (\n",
    "                        main_dict.get(ok, {})\n",
    "                                .get(\"overall\", {})\n",
    "                                .get(metric_category, {})\n",
    "                                .get(submetric, None)\n",
    "                    )\n",
    "                    row[ok] = val\n",
    "\n",
    "                rows.append(row)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_filename), exist_ok=True)\n",
    "\n",
    "    excel_path = f\"{output_filename}.xlsx\"\n",
    "    with pd.ExcelWriter(excel_path, engine=\"openpyxl\") as writer:\n",
    "        df.to_excel(writer, index=False, sheet_name=\"metrics\")\n",
    "\n",
    "    print(f\"Evaluation metrics table written to {os.path.abspath(excel_path)}\")\n",
    "\n",
    "\n",
    "    # Extract only numeric columns (outer solution keys)\n",
    "    heat_df = df[alternative_solutions].copy()\n",
    "\n",
    "    # Convert values â†’ percent form\n",
    "    percent_matrix = heat_df.to_numpy(dtype=float) * 100.0\n",
    "\n",
    "    # Apply rounding rules\n",
    "    def safe_round(x):\n",
    "        if x is None or np.isnan(x):\n",
    "            return np.nan\n",
    "        if 0 < x < 1:\n",
    "            return 0\n",
    "        if 99 < x < 100:\n",
    "            return 99\n",
    "        return int(round(x))\n",
    "\n",
    "    vectorized_round = np.vectorize(safe_round)\n",
    "    percent_matrix = vectorized_round(percent_matrix)\n",
    "\n",
    "\n",
    "    if y_labels is not None:\n",
    "        if len(y_labels) == len(df):\n",
    "            final_y_labels = y_labels\n",
    "        else:\n",
    "            print(f\"[Error]: Provided y_labels length {len(y_labels)} \"\n",
    "                  f\"does not match number of rows {len(df)}. Falling back to auto-generated labels.\")\n",
    "            y_labels = None  # Fall through to default behavior\n",
    "\n",
    "    if y_labels is None:\n",
    "        # Build concatenated labels: \"<Metric Category> <Metric>\"\n",
    "        combined = (df[\"Metric Category\"] + \" \" + df[\"Metric\"]).tolist()\n",
    "\n",
    "        # Prettify: replace underscores, capitalize each word\n",
    "        clean = []\n",
    "        for label in combined:\n",
    "            label = label.replace(\"_\", \" \")\n",
    "            label = \" \".join([w.capitalize() for w in label.split()])\n",
    "            clean.append(label)\n",
    "\n",
    "        final_y_labels = clean\n",
    "\n",
    "\n",
    "    x_labels = [map_solution(ok) for ok in alternative_solutions]\n",
    "\n",
    "\n",
    "    from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "    # ---- Custom redâ†’yellowâ†’green colormap ----\n",
    "    cmap = LinearSegmentedColormap.from_list(\n",
    "        \"red_to_green\",\n",
    "        [\n",
    "            (0.0, \"red\"),      # 0%\n",
    "            (0.5, \"white\"),   # 50%\n",
    "            (1.0, \"green\")     # 100%\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(12, max(6, len(df) * 0.35)))\n",
    "    plt.imshow(percent_matrix, aspect=\"auto\", cmap=cmap, vmin=0, vmax=100)\n",
    "\n",
    "    # Overlay text values\n",
    "    for i in range(percent_matrix.shape[0]):\n",
    "        for j in range(percent_matrix.shape[1]):\n",
    "            val = percent_matrix[i, j]\n",
    "            if not np.isnan(val):\n",
    "                plt.text(\n",
    "                    j, i, f\"{val}%\",\n",
    "                    ha=\"center\", va=\"center\", color=\"black\"\n",
    "                )\n",
    "\n",
    "    # -------- X / Y tick labels ----------\n",
    "    plt.xticks(\n",
    "        ticks=np.arange(len(x_labels)),\n",
    "        labels=x_labels,\n",
    "        rotation=0,       # â† upright\n",
    "        ha=\"center\"\n",
    "    )\n",
    "\n",
    "    plt.yticks(\n",
    "        ticks=np.arange(len(final_y_labels)),\n",
    "        labels=final_y_labels\n",
    "    )\n",
    "\n",
    "    plt.title(\"Proposed Solution vs. Alternatives: Percentage of Frames/Lanes Outperforming\")\n",
    "    plt.xlabel(\"Alternative Solution\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # ------------------------\n",
    "    # SAVE FIGURE\n",
    "    # ------------------------\n",
    "    fig_path = f\"{output_filename}.png\"\n",
    "    plt.savefig(fig_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Heatmap saved to {os.path.abspath(fig_path)}\")\n",
    "\n",
    "y_labels = [\n",
    "    \"Per-Frame Mean Point MAE\", \"Per-Frame Median Point MAE\", \"Per-Frame Mean Point RMSE\", \"Per-Frame Median Point RMSE\",\n",
    "    \"Per-Frame Mean Curve MAE\", \"Per-Frame Median Curve MAE\", \"Per-Frame Mean Curve RMSE\", \"Per-Frame Median Curve RMSE\",\n",
    "    \"Per-Lane Point MAE\", \"Per-Lane Point RMSE\",\n",
    "    \"Per-Lane Curve MAE\", \"Per-Lane Curve RMSE\"\n",
    "]\n",
    "generate_compare_metric_figures(compare_solutions_dict, os.path.join(once_config[\"result_analytics\"][\"figure_output_base_path\"], \"metric_comparison\"), y_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17216514",
   "metadata": {},
   "source": [
    "## Qualitative Analysis Visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afa50b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_2d_aligmnent(seq_id, frame_id, solution):\n",
    "    outfolder = os.path.join(once_config[\"result_analytics\"][\"figure_output_base_path\"], \"qualitative\")\n",
    "    os.makedirs(outfolder, exist_ok=True)\n",
    "    outfilename = os.path.join(outfolder, str(solution) + \"_\" + str(seq_id) + \"_\" + str(frame_id))\n",
    "\n",
    "    # Data loading\n",
    "    if True:\n",
    "        gt_2d_output_path = os.path.join(\n",
    "            once_config[\"data\"][\"base_path\"],\n",
    "            seq_id,\n",
    "            once_config[\"data\"][\"lane_detections_folder_path\"],\n",
    "            frame_id + \".txt\"\n",
    "        )\n",
    "        if not os.path.exists(gt_2d_output_path):\n",
    "            print(f\"[ERROR]: GT 2D path does not exist: {gt_2d_output_path}\")\n",
    "            sys.exit(1)\n",
    "        \n",
    "        solution_output_folder_path = os.path.join(\n",
    "            once_config[\"output\"][\"base_path\"],\n",
    "            seq_id,\n",
    "            solution\n",
    "        )\n",
    "        if not os.path.exists(solution_output_folder_path):\n",
    "            print(f\"[ERROR]: Solutoin folder path does not exist: {solution_output_folder_path}\")\n",
    "            sys.exit(1)\n",
    "        if not any(Path(solution_output_folder_path).glob(f\"{frame_id}_*.bin\")):\n",
    "            print(f\"[ERROR]: No such files exist in {solution_output_folder_path} called {frame_id}_*.bin\")\n",
    "            sys.exit(1)\n",
    "        solution_files = [str(f) for f in sorted(Path(solution_output_folder_path).glob(f\"{frame_id}_*.bin\"))]\n",
    "\n",
    "        solution_calib_file = os.path.join(\n",
    "            once_config[\"data\"][\"base_path\"],\n",
    "            seq_id,\n",
    "            once_config[\"data\"][\"calibration_path\"]\n",
    "        )\n",
    "        if not os.path.exists(solution_calib_file):\n",
    "            print(f\"[ERROR]: Calib file does not exist: {solution_calib_file}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        lidar_file = os.path.join(\n",
    "            once_config[\"data\"][\"base_path\"],\n",
    "            seq_id, \n",
    "            once_config[\"data\"][\"lidar_path\"],\n",
    "            frame_id + \".bin\"\n",
    "        )\n",
    "        if not os.path.exists(lidar_file):\n",
    "            print(f\"[ERROR]: Lidar file does not exist: {lidar_file}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        camera_file = os.path.join(\n",
    "            once_config[\"data\"][\"base_path\"],\n",
    "            seq_id,\n",
    "            once_config[\"data\"][\"camera_path\"],\n",
    "            frame_id + \".png\"\n",
    "        )\n",
    "        if not os.path.exists(camera_file):\n",
    "            print(f\"[ERROR]: Camera file does not exist: {camera_file}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        # Load calib\n",
    "        import nbimporter\n",
    "        from main_runner import load_calibration, load_2d_lanes, get_lidar_points\n",
    "        (\n",
    "            T_camera_lidar,\n",
    "            _,\n",
    "            fx, fy, cx, cy,\n",
    "            img_width, img_height,\n",
    "            distortion\n",
    "        ) = load_calibration(solution_calib_file, log=False)\n",
    "\n",
    "        lanes = load_2d_lanes(gt_2d_output_path, once_config, img_width, img_height, log=False)\n",
    "        if lanes is None or len(lanes) == 0:\n",
    "            print(f\"[ERROR]: No lanes were found in the desired file.\")\n",
    "            sys.exit(1)\n",
    "\n",
    "    # Load LiDAR\n",
    "    def RotateCamera(lidar_points, T_camera_lidar):\n",
    "        ones = np.ones((lidar_points.shape[0], 1))\n",
    "        points_lidar_hom = np.hstack((lidar_points, ones))\n",
    "        points_transformed_hom = (T_camera_lidar @ points_lidar_hom.T).T # lidar -> camera\n",
    "        return points_transformed_hom[:,:3]\n",
    "    lidar_points, _, _, _ = get_lidar_points(lidar_file)\n",
    "    points_lidar_camera = RotateCamera(lidar_points, T_camera_lidar)\n",
    "    \n",
    "    def project_points_onto_image(\n",
    "        points, \n",
    "        fx, fy, cx, cy, img_width, img_height, distortion\n",
    "    ):\n",
    "        points_rescaled, _ = cv2.projectPoints(\n",
    "            points,\n",
    "            np.zeros((3, 1), dtype=np.float32),\n",
    "            np.zeros((3, 1), dtype=np.float32),\n",
    "            np.array([\n",
    "                [fx,   0,  cx],\n",
    "                [0,   fy,  cy],\n",
    "                [0,    0,   1]\n",
    "            ], dtype=np.float64),\n",
    "            distortion\n",
    "        )\n",
    "\n",
    "        points_2d = points_rescaled.reshape(-1, 2)\n",
    "        points_3d = points.reshape(-1, 3)\n",
    "        mask = (\n",
    "            (points_2d[:, 0] >= 0) &\n",
    "            (points_2d[:, 0] < img_width) &\n",
    "            (points_2d[:, 1] >= 0) &\n",
    "            (points_2d[:, 1] < img_height) &\n",
    "            (points_3d[:, 2] > 0)\n",
    "        )\n",
    "        points_visible = points_3d[mask]\n",
    "        config = once_config\n",
    "        depth_cutoff_min = config[\"depth_map\"][\"depth_cutoff_min\"]\n",
    "        depth_cutoff_max = config[\"depth_map\"][\"depth_cutoff_max\"]\n",
    "        depth_max_point_scaling_distance = config[\"depth_map\"][\"depth_max_point_scaling_distance\"]\n",
    "        lidar_point_size_min = config[\"depth_map\"][\"lidar_point_size_min\"]\n",
    "        lidar_point_size_max = config[\"depth_map\"][\"lidar_point_size_max\"]\n",
    "\n",
    "        # Create depth map    \n",
    "        X = points_visible[:, 0]\n",
    "        Y = points_visible[:, 1]\n",
    "        Z = points_visible[:, 2]\n",
    "        eps = 1e-6\n",
    "        Z = np.maximum(Z, eps)\n",
    "        u = fx * (X / Z) + cx\n",
    "        v = fy * (Y / Z) + cy\n",
    "\n",
    "        mask = (\n",
    "            (u >= 0) & (u < img_width) &\n",
    "            (v >= 0) & (v < img_height)\n",
    "        )\n",
    "        u = u[mask]\n",
    "        v = v[mask]\n",
    "        c = Z[mask]\n",
    "        depth_clipped = np.clip(c, depth_cutoff_min, depth_max_point_scaling_distance)  # Clip to fixed range\n",
    "        depth_normalized = (depth_clipped - depth_cutoff_min) / (depth_max_point_scaling_distance - depth_cutoff_min)\n",
    "        sizes = lidar_point_size_max - (depth_normalized * (lidar_point_size_max - lidar_point_size_min))  # Linear interpolation\n",
    "\n",
    "        sorted_indices = np.argsort(c)[::-1]  # Sort descending (closer points last)\n",
    "        u_sorted = u[sorted_indices]\n",
    "        v_sorted = v[sorted_indices]\n",
    "        d_sorted = c[sorted_indices]\n",
    "        range_min = np.min(d_sorted)\n",
    "        range_max = np.max(d_sorted)\n",
    "        sizes_sorted = sizes[sorted_indices]\n",
    "        v_flipped = img_height - v_sorted\n",
    "\n",
    "        return (\n",
    "            u_sorted, \n",
    "            v_flipped,\n",
    "            d_sorted,\n",
    "            sizes_sorted,\n",
    "            range_min,\n",
    "            range_max\n",
    "        )\n",
    "\n",
    "\n",
    "    img = mpimg.imread(camera_file)\n",
    "    img_flipped = np.flipud(img)  # Flip image vertically\n",
    "    (\n",
    "        lidar_u, \n",
    "        lidar_v,\n",
    "        lidar_d,\n",
    "        lidar_s,\n",
    "        range_min,\n",
    "        range_max\n",
    "    ) = project_points_onto_image(\n",
    "        points_lidar_camera, \n",
    "        fx, fy, cx, cy, img_width, img_height, distortion\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.scatter(lidar_u, lidar_v, c=lidar_d, cmap='viridis', s=lidar_s**2, vmin=range_min, vmax=range_max)\n",
    "    plt.colorbar(label='Depth (euclidean distance in meters)')\n",
    "    plt.title(\"Camera View: Projection of LiDAR Points\")\n",
    "    plt.xlabel(\"u (pixels)\")\n",
    "    plt.ylabel(\"v (pixels)\")\n",
    "    plt.xlim([0, img_width])\n",
    "    plt.ylim([0, img_height])\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(img_flipped)\n",
    "    plt.scatter(lidar_u, lidar_v, c=lidar_d, cmap='viridis', s=lidar_s**2, vmin=range_min, vmax=range_max)\n",
    "    plt.colorbar(label='Depth (euclidean distance in meters)')\n",
    "    plt.title(\"LiDAR Points Projected on Camera Image\")\n",
    "    plt.xlabel(\"u (pixels)\")\n",
    "    plt.ylabel(\"v (pixels)\")\n",
    "    plt.xlim([0, img_width])\n",
    "    plt.ylim([0, img_height])\n",
    "    plt.grid(False)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def display_2d(seq_id, frame_id, solution):\n",
    "    outfolder = os.path.join(once_config[\"result_analytics\"][\"figure_output_base_path\"], \"qualitative\")\n",
    "    os.makedirs(outfolder, exist_ok=True)\n",
    "    outfilename = os.path.join(outfolder, str(solution) + \"_\" + str(seq_id) + \"_\" + str(frame_id))\n",
    "\n",
    "    # Data loading\n",
    "    if True:\n",
    "        gt_2d_output_path = os.path.join(\n",
    "            once_config[\"data\"][\"base_path\"],\n",
    "            seq_id,\n",
    "            once_config[\"data\"][\"lane_detections_folder_path\"],\n",
    "            frame_id + \".txt\"\n",
    "        )\n",
    "        if not os.path.exists(gt_2d_output_path):\n",
    "            print(f\"[ERROR]: GT 2D path does not exist: {gt_2d_output_path}\")\n",
    "            sys.exit(1)\n",
    "        \n",
    "        solution_output_folder_path = os.path.join(\n",
    "            once_config[\"output\"][\"base_path\"],\n",
    "            seq_id,\n",
    "            solution\n",
    "        )\n",
    "        if not os.path.exists(solution_output_folder_path):\n",
    "            print(f\"[ERROR]: Solutoin folder path does not exist: {solution_output_folder_path}\")\n",
    "            sys.exit(1)\n",
    "        if not any(Path(solution_output_folder_path).glob(f\"{frame_id}_*.bin\")):\n",
    "            print(f\"[ERROR]: No such files exist in {solution_output_folder_path} called {frame_id}_*.bin\")\n",
    "            sys.exit(1)\n",
    "        solution_files = [str(f) for f in sorted(Path(solution_output_folder_path).glob(f\"{frame_id}_*.bin\"))]\n",
    "\n",
    "        solution_calib_file = os.path.join(\n",
    "            once_config[\"data\"][\"base_path\"],\n",
    "            seq_id,\n",
    "            once_config[\"data\"][\"calibration_path\"]\n",
    "        )\n",
    "        if not os.path.exists(solution_calib_file):\n",
    "            print(f\"[ERROR]: Calib file does not exist: {solution_calib_file}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        lidar_file = os.path.join(\n",
    "            once_config[\"data\"][\"base_path\"],\n",
    "            seq_id, \n",
    "            once_config[\"data\"][\"lidar_path\"],\n",
    "            frame_id + \".bin\"\n",
    "        )\n",
    "        if not os.path.exists(lidar_file):\n",
    "            print(f\"[ERROR]: Lidar file does not exist: {lidar_file}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        camera_file = os.path.join(\n",
    "            once_config[\"data\"][\"base_path\"],\n",
    "            seq_id,\n",
    "            once_config[\"data\"][\"camera_path\"],\n",
    "            frame_id + \".png\"\n",
    "        )\n",
    "        if not os.path.exists(camera_file):\n",
    "            print(f\"[ERROR]: Camera file does not exist: {camera_file}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        # Load calib\n",
    "        import nbimporter\n",
    "        from main_runner import load_calibration, load_2d_lanes, get_lidar_points\n",
    "        (\n",
    "            T_camera_lidar,\n",
    "            _,\n",
    "            fx, fy, cx, cy,\n",
    "            img_width, img_height,\n",
    "            distortion\n",
    "        ) = load_calibration(solution_calib_file, log=False)\n",
    "\n",
    "        lanes = load_2d_lanes(gt_2d_output_path, once_config, img_width, img_height, log=False)\n",
    "        if lanes is None or len(lanes) == 0:\n",
    "            print(f\"[ERROR]: No lanes were found in the desired file.\")\n",
    "            sys.exit(1)\n",
    "\n",
    "    # Load LiDAR\n",
    "    def RotateCamera(lidar_points, T_camera_lidar):\n",
    "        ones = np.ones((lidar_points.shape[0], 1))\n",
    "        points_lidar_hom = np.hstack((lidar_points, ones))\n",
    "        points_transformed_hom = (T_camera_lidar @ points_lidar_hom.T).T # lidar -> camera\n",
    "        return points_transformed_hom[:,:3]\n",
    "    lidar_points, _, _, _ = get_lidar_points(lidar_file)\n",
    "    points_lidar_camera = RotateCamera(lidar_points, T_camera_lidar)\n",
    "    \n",
    "    def project_points_onto_image(\n",
    "        points, \n",
    "        fx, fy, cx, cy, img_width, img_height, distortion\n",
    "    ):\n",
    "        points_rescaled, _ = cv2.projectPoints(\n",
    "            points,\n",
    "            np.zeros((3, 1), dtype=np.float32),\n",
    "            np.zeros((3, 1), dtype=np.float32),\n",
    "            np.array([\n",
    "                [fx,   0,  cx],\n",
    "                [0,   fy,  cy],\n",
    "                [0,    0,   1]\n",
    "            ], dtype=np.float64),\n",
    "            distortion\n",
    "        )\n",
    "\n",
    "        points_2d = points_rescaled.reshape(-1, 2)\n",
    "        points_3d = points.reshape(-1, 3)\n",
    "        mask = (\n",
    "            (points_2d[:, 0] >= 0) &\n",
    "            (points_2d[:, 0] < img_width) &\n",
    "            (points_2d[:, 1] >= 0) &\n",
    "            (points_2d[:, 1] < img_height) &\n",
    "            (points_3d[:, 2] > 0)\n",
    "        )\n",
    "        points_visible = points_3d[mask]\n",
    "        config = once_config\n",
    "        depth_cutoff_min = config[\"depth_map\"][\"depth_cutoff_min\"]\n",
    "        depth_cutoff_max = config[\"depth_map\"][\"depth_cutoff_max\"]\n",
    "        depth_max_point_scaling_distance = config[\"depth_map\"][\"depth_max_point_scaling_distance\"]\n",
    "        lidar_point_size_min = config[\"depth_map\"][\"lidar_point_size_min\"]\n",
    "        lidar_point_size_max = config[\"depth_map\"][\"lidar_point_size_max\"]\n",
    "\n",
    "        # Create depth map    \n",
    "        X = points_visible[:, 0]\n",
    "        Y = points_visible[:, 1]\n",
    "        Z = points_visible[:, 2]\n",
    "        eps = 1e-6\n",
    "        Z = np.maximum(Z, eps)\n",
    "        u = fx * (X / Z) + cx\n",
    "        v = fy * (Y / Z) + cy\n",
    "\n",
    "        mask = (\n",
    "            (u >= 0) & (u < img_width) &\n",
    "            (v >= 0) & (v < img_height)\n",
    "        )\n",
    "        u = u[mask]\n",
    "        v = v[mask]\n",
    "        c = Z[mask]\n",
    "        depth_clipped = np.clip(c, depth_cutoff_min, depth_max_point_scaling_distance)  # Clip to fixed range\n",
    "        depth_normalized = (depth_clipped - depth_cutoff_min) / (depth_max_point_scaling_distance - depth_cutoff_min)\n",
    "        sizes = lidar_point_size_max - (depth_normalized * (lidar_point_size_max - lidar_point_size_min))  # Linear interpolation\n",
    "\n",
    "        sorted_indices = np.argsort(c)[::-1]  # Sort descending (closer points last)\n",
    "        u_sorted = u[sorted_indices]\n",
    "        v_sorted = v[sorted_indices]\n",
    "        d_sorted = c[sorted_indices]\n",
    "        range_min = np.min(d_sorted)\n",
    "        range_max = np.max(d_sorted)\n",
    "        sizes_sorted = sizes[sorted_indices]\n",
    "        v_flipped = img_height - v_sorted\n",
    "\n",
    "        return (\n",
    "            u_sorted, \n",
    "            v_flipped,\n",
    "            d_sorted,\n",
    "            sizes_sorted,\n",
    "            range_min,\n",
    "            range_max\n",
    "        )\n",
    "\n",
    "\n",
    "    img = mpimg.imread(camera_file)\n",
    "    img_flipped = np.flipud(img)  # Flip image vertically\n",
    "\n",
    "    output_lanes = []\n",
    "    for file in solution_files:\n",
    "        points = np.fromfile(file, dtype=np.float32).reshape(-1, 3)\n",
    "        output_lanes.append(points )\n",
    "\n",
    "    def plot_lane_over_image(points=None, lanes_2d=None, title=\"\", outfile=None):\n",
    "        solution_color = \"red\"\n",
    "        gt_color = \"#F0E442\"\n",
    "        line_color = \"#2596be\"            \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(img_flipped)\n",
    "        if points is not None:\n",
    "            for idx, p in enumerate(points):\n",
    "                (\n",
    "                    u, \n",
    "                    v,\n",
    "                    _,\n",
    "                    s,\n",
    "                    _,\n",
    "                    _\n",
    "                ) = project_points_onto_image(\n",
    "                    p, \n",
    "                    fx, fy, cx, cy, img_width, img_height, distortion\n",
    "                )\n",
    "                if idx==0 and lanes_2d is not None:\n",
    "                    plt.scatter(u, v, s=s, color=solution_color, zorder=3,  label=\"Output Points\")\n",
    "                    plt.plot(u, v, color=line_color, linewidth=2, zorder=1, label=\"Solution Line\")\n",
    "                else:\n",
    "                    plt.scatter(u, v, s=s, color=solution_color, zorder=3)\n",
    "                    plt.plot(u, v, color=line_color, linewidth=2, zorder=1)\n",
    "\n",
    "            if lanes_2d is not None:\n",
    "                for idx, lane in enumerate(lanes_2d):\n",
    "                    if idx == 0:\n",
    "                        plt.scatter(lane[:,0], lane[:,1], color=gt_color, s=2, label=\"Ground Truth Points\")\n",
    "                    else:\n",
    "                        plt.scatter(lane[:,0], lane[:,1], color=gt_color, s=2)\n",
    "                plt.legend(\n",
    "                    loc='upper right',\n",
    "                    facecolor='#aaa',   # legend background color\n",
    "                    edgecolor='black',   # border color\n",
    "                    framealpha=1\n",
    "                )\n",
    "        elif lanes_2d is not None:\n",
    "            for lane in lanes_2d:\n",
    "                plt.plot(\n",
    "                    lane[:, 0],\n",
    "                    lane[:, 1],\n",
    "                    color=line_color,\n",
    "                    linewidth=2,   \n",
    "                    marker='.',\n",
    "                    markersize=2,\n",
    "                    markerfacecolor=gt_color,\n",
    "                    markeredgecolor=gt_color\n",
    "                )\n",
    "        plt.title(title)\n",
    "        plt.xlim([0, img_width])\n",
    "        plt.ylim([0, img_height])\n",
    "        plt.grid(False)\n",
    "        plt.gca().set_aspect('equal', adjustable='box')\n",
    "        plt.axis('off')\n",
    "        if outfile is not None:\n",
    "            fig_path = f\"{outfile}.png\"\n",
    "            plt.savefig(fig_path, dpi=300)      \n",
    "        plt.show()\n",
    "    \n",
    "    plot_lane_over_image(points=output_lanes, lanes_2d=lanes, outfile=outfilename)  \n",
    "    # plot_lane_over_image(points=output_lanes)\n",
    "    # plot_lane_over_image(lanes_2d=lanes)\n",
    "\n",
    "\n",
    "display_2d_aligmnent(\"000076\", \"1616343539199\", thesis_solution)\n",
    "# display_2d(\"000027\", \"1616101262900\", thesis_solution)\n",
    "# display_2d(\"000027\", \"1616100803399\", thesis_solution)\n",
    "# display_2d(\"000027\", \"1616100953900\", thesis_solution)\n",
    "# display_2d(\"000076\", \"1616344463199\", thesis_solution)\n",
    "# display_2d(\"000076\", \"1616343539199\", thesis_solution)\n",
    "# display_2d(\"000076\", \"1616343988199\", thesis_solution) # reflective bus\n",
    "# display_2d(\"000077\", \"1616344940400\", thesis_solution)\n",
    "# display_2d(\"000168\", \"1618716889299\", thesis_solution)\n",
    "# display_2d(\"000334\", \"1619406822299\", thesis_solution)\n",
    "\n",
    "# display_2d(\"000080\", \"1616348625300\", thesis_solution)\n",
    "# display_2d(\"000200\", \"1618797316299\", thesis_solution)\n",
    "\n",
    "\n",
    "# Failures\n",
    "# display_2d(\"000077\", \"1616344656900\", thesis_solution)\n",
    "# display_2d(\"000034\", \"1616175279299\", thesis_solution)\n",
    "# display_2d(\"000034\", \"1616175475800\", thesis_solution) #dataset failure\n",
    "# display_2d(\"000076\", \"1616343733200\", thesis_solution)\n",
    "# display_2d(\"000076\", \"1616343783200\", thesis_solution) #force filter on car\n",
    "# display_2d(\"000168\", \"1618716973799\", thesis_solution) #cant detect other ramp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa847b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def display_2d_batch(pairs, solution, n_cols=3):\n",
    "    \"\"\"\n",
    "    pairs: list of (seq_id, frame_id)\n",
    "    solution: solution folder name\n",
    "    n_cols: number of columns in the grid\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Compute Grid Size ---\n",
    "    n_items = len(pairs)\n",
    "    n_rows = math.ceil(n_items / n_cols)\n",
    "\n",
    "    # --- Create Output Folder ---\n",
    "    outfolder = os.path.join(\n",
    "        once_config[\"result_analytics\"][\"figure_output_base_path\"],\n",
    "        \"qualitative_fail\"\n",
    "    )\n",
    "    os.makedirs(outfolder, exist_ok=True)\n",
    "    outfile = os.path.join(outfolder, f\"batch_{solution}.png\")\n",
    "\n",
    "    # --- Create Figure ---\n",
    "    fig, axs = plt.subplots(\n",
    "        n_rows, n_cols,\n",
    "        figsize=(6*n_cols, 5*n_rows),\n",
    "        squeeze=False\n",
    "    )\n",
    "\n",
    "    # --- Helper: Single Subplot Drawing ---\n",
    "    def draw_single(ax, seq_id, frame_id):\n",
    "        # Load everything exactly as in original function\n",
    "        # (keeping original structure, only embedding locally)\n",
    "\n",
    "        # ---- Paths ----\n",
    "        base = once_config[\"data\"][\"base_path\"]\n",
    "        gt_2d_output_path = os.path.join(base, seq_id,\n",
    "                                         once_config[\"data\"][\"lane_detections_folder_path\"],\n",
    "                                         frame_id + \".txt\")\n",
    "\n",
    "        solution_output_folder_path = os.path.join(\n",
    "            once_config[\"output\"][\"base_path\"], seq_id, solution\n",
    "        )\n",
    "\n",
    "        solution_files = [str(f) for f in sorted(\n",
    "            Path(solution_output_folder_path).glob(f\"{frame_id}_*.bin\")\n",
    "        )]\n",
    "\n",
    "        solution_calib_file = os.path.join(base, seq_id,\n",
    "                                           once_config[\"data\"][\"calibration_path\"])\n",
    "\n",
    "        camera_file = os.path.join(base, seq_id,\n",
    "                                   once_config[\"data\"][\"camera_path\"],\n",
    "                                   frame_id + \".png\")\n",
    "\n",
    "        # ---- Load calibration + GT lanes ----\n",
    "        from main_runner import load_calibration, load_2d_lanes\n",
    "        (\n",
    "            T_camera_lidar,\n",
    "            _,\n",
    "            fx, fy, cx, cy,\n",
    "            img_width, img_height,\n",
    "            distortion\n",
    "        ) = load_calibration(solution_calib_file, log=False)\n",
    "\n",
    "        lanes = load_2d_lanes(gt_2d_output_path, once_config, img_width, img_height, log=False)\n",
    "\n",
    "        img = mpimg.imread(camera_file)\n",
    "\n",
    "        # ---- Load 3D solution lanes ----\n",
    "        output_lanes = []\n",
    "        for f in solution_files:\n",
    "            p = np.fromfile(f, dtype=np.float32).reshape(-1, 3)\n",
    "            output_lanes.append(p)\n",
    "\n",
    "        # ---- Project and Draw ----\n",
    "        ax.imshow(img)\n",
    "\n",
    "        def project_points(points):\n",
    "            pts_2d, _ = cv2.projectPoints(\n",
    "                points,\n",
    "                np.zeros((3, 1), dtype=np.float32),\n",
    "                np.zeros((3, 1), dtype=np.float32),\n",
    "                np.array([[fx, 0, cx],\n",
    "                          [0, fy, cy],\n",
    "                          [0, 0, 1]], dtype=np.float64),\n",
    "                distortion\n",
    "            )\n",
    "            pts_2d = pts_2d.reshape(-1, 2)\n",
    "            mask = (\n",
    "                (pts_2d[:,0] >= 0) & (pts_2d[:,0] < img_width) &\n",
    "                (pts_2d[:,1] >= 0) & (pts_2d[:,1] < img_height) &\n",
    "                (points[:,2] > 0)\n",
    "            )\n",
    "            return pts_2d[mask]\n",
    "        \n",
    "        \n",
    "\n",
    "       \n",
    "        # --- Draw 3D solution lanes ---\n",
    "        for lane3d in output_lanes:\n",
    "            pts2d = project_points(lane3d)\n",
    "            if pts2d.shape[0] > 1:\n",
    "                ax.scatter(pts2d[:,0], pts2d[:,1], color=\"red\", s=1, zorder=3,  label=\"Output Points\")\n",
    "                ax.plot(pts2d[:,0], pts2d[:,1], color=\"#2596be\", zorder=1, linewidth=2)\n",
    "\n",
    "        # --- Draw GT 2D lanes ---\n",
    "        for lane in lanes:\n",
    "            ax.scatter(lane[:,0], img_height - lane[:,1], s=1, color=\"#F0E442\")\n",
    "\n",
    "        ax.set_xlim([0, img_width])\n",
    "        ax.set_ylim([img_height, 0])  # invert y for images\n",
    "        ax.set_aspect(\"equal\")\n",
    "        ax.set_title(f\"{seq_id[-3:]} / {frame_id}\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    # ---- Draw all images into grid ----\n",
    "    idx = 0\n",
    "    for r in range(n_rows):\n",
    "        for c in range(n_cols):\n",
    "            if idx < n_items:\n",
    "                seq_id, frame_id = pairs[idx]\n",
    "                draw_single(axs[r, c], seq_id, frame_id)\n",
    "            else:\n",
    "                axs[r, c].axis(\"off\")\n",
    "            idx += 1\n",
    "\n",
    "    # ---- Final Save (only once) ----\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(outfile, dpi=200)\n",
    "    plt.close(fig)\n",
    "    print(f\"[SAVED] {outfile}\")\n",
    "\n",
    "pairs = [\n",
    "    (\"000027\", \"1616101761900\"),\n",
    "    (\"000027\", \"1616101262900\"),\n",
    "    (\"000027\", \"1616100803399\"),\n",
    "    (\"000027\", \"1616100953900\"),\n",
    "    (\"000076\", \"1616344463199\"),\n",
    "    (\"000076\", \"1616343539199\"),\n",
    "    (\"000076\", \"1616343988199\"),\n",
    "    (\"000077\", \"1616344940400\"),\n",
    "    (\"000080\", \"1616348625300\"),\n",
    "    (\"000168\", \"1618716889299\"),\n",
    "    (\"000200\", \"1618797316299\"),\n",
    "    (\"000334\", \"1619406822299\"),\n",
    "]\n",
    "pairs_fail = [\n",
    "    (\"000077\", \"1616344656900\"),\n",
    "    (\"000034\", \"1616175279299\"),\n",
    "    (\"000034\", \"1616175475800\"), #dataset failure\n",
    "    (\"000076\", \"1616343733200\"),\n",
    "    (\"000076\", \"1616343783200\"), #force filter on car\n",
    "    (\"000168\", \"1618716973799\")\n",
    "]\n",
    "display_2d_batch(pairs_fail, thesis_solution, n_cols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f14e8a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
