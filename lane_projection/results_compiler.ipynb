{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5970dac9",
   "metadata": {},
   "source": [
    "## Results Compiler\n",
    "Created by Jett Penner<br>\n",
    "December 2025 <br>\n",
    "\n",
    "\n",
    "Compiles all of the quantitative results of the proposed and alternative solutions; comparing outputs to the ground truth data and against each other. Compares against identified outliers (from postfiltering). Generates various metric aggregates or data lists, including dataset-wide, run-wide, framewise, lanewise, and pointwise information. Used as a preprocessing optimization step before running quantitative analysis (enabling easy generation of tables and graphs by not re-calculating all of the results). Outputs all of the metrics to a summary json file.\n",
    "\n",
    "Again, only needed for thesis analysis, not for real implementation. Run the files in order:\n",
    "1. Run the `ONCE-3DLanes Data Loader` for data loading and preprocessing.\n",
    "2. Run the `2D-to-3D Lanes Pipeline` for projection output (for proposed and alternate solutions).\n",
    "3. Run the `2D-to-3D Lanes Outlier Postfilter` for preprocessing outlier detection.\n",
    "4. Run this code to generate summary values of output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e05a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import open3d as o3d\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from scipy.optimize import minimize_scalar\n",
    "import json\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy import stats\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b5481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config loading and logger\n",
    "with open(\"once\" + \"_config.yaml\", \"r\") as f:\n",
    "    once_config = yaml.safe_load(f)\n",
    "\n",
    "from logger import setup_logger, start_timer, stop_timer, switch_log_file\n",
    "main_logger = setup_logger(\"analytics_builder_log\")\n",
    "switch_log_file(main_logger, once_config[\"output\"][\"base_path\"])\n",
    "main_logger.info(\"Starting Program\\n\")\n",
    "\n",
    "# Load invald lanes/points\n",
    "invalid_pts_path = Path(os.path.join(once_config[\"output\"][\"base_path\"], once_config[\"result_analytics\"][\"posfilter_eval_path\"] + \".json\"))\n",
    "filter_invalid = False\n",
    "if invalid_pts_path.exists():\n",
    "    with open(invalid_pts_path, 'r') as f:\n",
    "        invalid_pts_dict = json.load(f)\n",
    "    invalid_lanes = set(tuple(x) for x in invalid_pts_dict.get(\"lanes\", []))\n",
    "    invalid_points = set(tuple(x) for x in invalid_pts_dict.get(\"points\", []))\n",
    "    filter_invalid = once_config[\"result_analytics\"][\"filter_invalid\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794a0c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_i(a, b, c, d=None, e=None):\n",
    "    ''' \n",
    "    Multipurpose function. \n",
    "\n",
    "    Op Mode 1:\n",
    "        Determins whether a given lane is valid.\n",
    "\n",
    "        Args:\n",
    "            a (int): lane id,\n",
    "            b (int/string): frame id,\n",
    "            c (int/string): sequence/run id.\n",
    "            d: None\n",
    "            e: None\n",
    "\n",
    "        Returns:\n",
    "            (bool), true if lane is invalid, false otherwise. \n",
    "\n",
    "    Op Mode 2:\n",
    "        Determines whether point sets contain invalid points and filter them from both sets.\n",
    "\n",
    "        Args:\n",
    "            a (N,3) np array: Point set 1.\n",
    "            b (N,3) np array: Point set 2.\n",
    "            c (int): lane id,\n",
    "            d (int/string): frame id,\n",
    "            e (int/string): sequence/run id.\n",
    "    \n",
    "        Returns:\n",
    "            a (M,3) np array, point set 1 with outliers removed,\n",
    "            b (M,3) np array, point set 2 with outliers removed.\n",
    "    '''\n",
    "    if d is None:\n",
    "        if not filter_invalid:\n",
    "            return False\n",
    "        else:\n",
    "            return (c, b, a) in invalid_lanes\n",
    "    else:\n",
    "        if not filter_invalid:\n",
    "            return a, b\n",
    "        else:\n",
    "            N = a.shape[0]\n",
    "            # Precompute all invalid indices for this lane/frame/seq\n",
    "            invalid_indices = {i for s, f, l, i in invalid_points if s == e and f == d and l == c}\n",
    "            if not invalid_indices:\n",
    "                return a, b  # nothing to remove\n",
    "            \n",
    "            # Create a boolean mask: True if index is valid\n",
    "            mask = np.ones(N, dtype=bool)\n",
    "            mask[list(invalid_indices)] = False\n",
    "            \n",
    "            return a[mask], b[mask]\n",
    "    \n",
    "    \n",
    "    \n",
    "def load_pointcloud_from_bin(file_path):\n",
    "    '''\n",
    "    Load a point cloud from a .bin file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the .bin file.\n",
    "\n",
    "    Returns:\n",
    "        (N,3) np array: Points in the file (XYZ), or None if invalid file.\n",
    "    '''\n",
    "    if not os.path.exists(file_path):\n",
    "        main_logger.error(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        points = np.fromfile(file_path, dtype=np.float32)\n",
    "        if points.size % 3 != 0:\n",
    "            main_logger.error(f\"Invalid point cloud size in file {file_path} ({points.size} floats).\")\n",
    "            return None\n",
    "        return points.reshape(-1, 3)\n",
    "    except Exception as e:\n",
    "        main_logger.error(f\"Failed to load point cloud from {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def load_pointcloud_from_pcd(pcd_path):\n",
    "    '''\n",
    "    Load a point cloud from a .pcd file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the .pcd file.\n",
    "\n",
    "    Returns:\n",
    "        (N,3) np array: Points in the file (XYZ), or None if invalid file.\n",
    "    '''\n",
    "    pcd = o3d.io.read_point_cloud(str(pcd_path))\n",
    "    \n",
    "    if not pcd.has_points():\n",
    "        main_logger.warning(f\"No points found in PCD file: {pcd_path}\")\n",
    "        return np.empty((0, 3), dtype=np.float32)\n",
    "    \n",
    "    return np.asarray(pcd.points, dtype=np.float32)\n",
    "\n",
    "\n",
    "\n",
    "def fit_line_on_plane(points, precalc_values, curvature_threshold=0.05):\n",
    "    \"\"\"\n",
    "    Fit a 3D line (or quadratic curve if curvature is high) through points known to lie on a plane.\n",
    "\n",
    "    Args:\n",
    "        points (N,3) np array: 3D points (already on plane).\n",
    "        precalc_values (dict): dict containing plane_x, plane_y, origin (see fit_line_on_plane_precalc()).\n",
    "        curvature_threshold (float, optional): RMS threshold to switch to quadratic fitting. Default is 0.05.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (\n",
    "            model_type (str): the used fitting model, either \"linear\" or \"quadratic\",\n",
    "            model_params (dict): {\n",
    "                coeffs (tuple) of floats: \n",
    "                    Linear: (a,b) satisfying a·x + b = 0,\n",
    "                    Quadratic: (a,b,c) satisfying a·x^2 + b·x + c = 0.\n",
    "                z_intercept (3,) np array: 3D point on plane for the y-intercept.\n",
    "                \n",
    "                line_dir:\n",
    "                    Linear: (3,) np array: Unit direction vector along the fitted line.\n",
    "                    Quadratic: None\n",
    "                quad_firstorder_dir:\n",
    "                    Linear: None\n",
    "                    Quadratic: (3,) np array: Unit direction vector for first-order change along the fitted line.\n",
    "                quad_secondorder_dir:\n",
    "                    Linear: None\n",
    "                    Quadratic: (3,) np array: Unit direction vector for second-order change along the fitted line.\n",
    "            }\n",
    "        )\n",
    "    \"\"\"\n",
    "    plane_x = precalc_values[\"plane_x\"]\n",
    "    plane_y = precalc_values[\"plane_y\"]\n",
    "    origin = precalc_values[\"origin\"]\n",
    "\n",
    "    # Convert points to 2D local coordinates on plane\n",
    "    pts = np.asarray(points)\n",
    "    local_pts = pts - origin\n",
    "    x = local_pts @ plane_x\n",
    "    y = local_pts @ plane_y\n",
    "\n",
    "    # Fit linear model y = a*x + b\n",
    "    A = np.vstack([x, np.ones_like(x)]).T\n",
    "    a, b = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "    y_pred = a * x + b\n",
    "    linear_rms = np.sqrt(np.mean((y - y_pred) ** 2))\n",
    "\n",
    "    # Quadratic fallback if large rms error\n",
    "    if linear_rms > curvature_threshold:\n",
    "        a2, b2, c2 = np.polyfit(x, y, 2)\n",
    "\n",
    "        # Fit quadratic model y = a*(x^2) + b*x + c\n",
    "        quad_origin = origin + c2 * plane_y\n",
    "        quad_firstorder_dir = plane_x + b2 * plane_y\n",
    "        quad_secondorder_dir = a2 * plane_y\n",
    "\n",
    "        if np.dot(quad_firstorder_dir, np.array([0, 0, 1])) < 0:\n",
    "            quad_firstorder_dir *= -1\n",
    "\n",
    "        if np.dot(quad_secondorder_dir, np.array([0, 0, 1])) < 0:\n",
    "            quad_secondorder_dir *= -1\n",
    "\n",
    "        return \"quadratic\", {\n",
    "            \"coeffs\": (a2, b2, c2),\n",
    "            \"z_intercept\": quad_origin,\n",
    "            \"line_dir\": None,\n",
    "            \"quad_firstorder_dir\": quad_firstorder_dir,\n",
    "            \"quad_secondorder_dir\": quad_secondorder_dir\n",
    "        }\n",
    "\n",
    "    # Return linear\n",
    "    line_dir = plane_x + a * plane_y\n",
    "    if np.dot(line_dir, np.array([0, 0, 1])) < 0:\n",
    "        line_dir *= -1\n",
    "    line_origin = origin + b * plane_y\n",
    "\n",
    "    return \"linear\", {\n",
    "        \"coeffs\": (a, b),\n",
    "        \"z_intercept\": line_origin,\n",
    "        \"line_dir\": line_dir / np.linalg.norm(line_dir),\n",
    "        \"quad_firstorder_dir\": None,\n",
    "        \"quad_secondorder_dir\": None\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def project_point_onto_curve(P, model_type, model_params):\n",
    "    ''' \n",
    "    Project a set of points onto a function curve (closest distance).\n",
    "\n",
    "    Args:\n",
    "        P (N,3) np array: The points.\n",
    "        model_type (str): The used fitting model, either \"linear\" or \"quadratic\".\n",
    "        model_params (dict): Various linear and quadratic model parameters.\n",
    "\n",
    "    Returns:\n",
    "        (N,3) np array, the points projected on the curve.\n",
    "    '''\n",
    "    P = np.asarray(P)\n",
    "    if model_type == \"linear\":\n",
    "        t = np.dot(P - model_params['z_intercept'], model_params['line_dir'])\n",
    "        closest = model_params['z_intercept'] + t * model_params['line_dir']\n",
    "    else:  # quadratic\n",
    "        a = model_params['quad_firstorder_dir']\n",
    "        b = model_params['quad_secondorder_dir']\n",
    "        p0 = model_params['z_intercept']\n",
    "\n",
    "        def f(t):\n",
    "            X = p0 + a * t + b * t**2\n",
    "            return np.sum((X - P)**2)\n",
    "\n",
    "        # initial guess from linear projection\n",
    "        res = minimize_scalar(f, bounds=(-100, 100), method='bounded')\n",
    "        closest = p0 + a * res.x + b * res.x**2\n",
    "\n",
    "    return closest\n",
    "\n",
    "\n",
    "\n",
    "def per_point_errors_and_curve_dist(P_sol, P_gt, curve_model_type, curve_model_params):\n",
    "    '''\n",
    "    Input:\n",
    "        P_sol (3,) np array: solution point\n",
    "        P_gt (3,) np array: ground truth point\n",
    "        curve_model_type (str): \"linear\" or \"quadratic\"\n",
    "        curve_model_params (dict): Various linear and quadratic model parameters.\n",
    "    Returns:\n",
    "        dict: {\n",
    "            'point_dist': float,        # euclidean distance between P_sol and P_gt\n",
    "            'curve_dist': float,        # euclidean distance from P_sol to the fitted curve (point-to-curve)\n",
    "            'gt_to_curve_dist': float   # optional: distance from P_gt to curve (diagnostic)\n",
    "        }\n",
    "    Notes:\n",
    "        Uses project_point_onto_curve(P, model_type, model_params) which should return the closest 3D point on the curve.\n",
    "    '''\n",
    "    point_dist = float(np.linalg.norm(P_sol - P_gt))\n",
    "\n",
    "    # project solution point onto curve\n",
    "    try:\n",
    "        closest_on_curve_sol = project_point_onto_curve(P_sol, curve_model_type, curve_model_params)\n",
    "        curve_dist = float(np.linalg.norm(P_sol - closest_on_curve_sol))\n",
    "    except Exception as e:\n",
    "        # fallback: large error if projection fails\n",
    "        curve_dist = float(np.nan)\n",
    "\n",
    "    # optional: distance of GT to curve (useful to measure GT fit quality)\n",
    "    try:\n",
    "        closest_on_curve_gt = project_point_onto_curve(P_gt, curve_model_type, curve_model_params)\n",
    "        gt_to_curve_dist = float(np.linalg.norm(P_gt - closest_on_curve_gt))\n",
    "    except Exception:\n",
    "        gt_to_curve_dist = float(np.nan)\n",
    "\n",
    "    return {'point_dist': point_dist, 'curve_dist': curve_dist, 'gt_to_curve_dist': gt_to_curve_dist}\n",
    "\n",
    "\n",
    "\n",
    "def compute_chamfer_and_hausdorff(ptsA, ptsB):\n",
    "    ''' \n",
    "    Computes and returns the chamfer and hausdorff distances between two point sets.\n",
    "\n",
    "    Args:\n",
    "        ptsA (N,3) np array: First point set.\n",
    "        ptsB (M,3) np array: Second point set.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (\n",
    "            chamfer (float), chamfer distance,\n",
    "            hausdorff (float), hausdorff distance.\n",
    "        )\n",
    "    '''\n",
    "    if ptsA.size == 0 or ptsB.size == 0:\n",
    "        return float(np.nan), float(np.nan)\n",
    "    treeA = cKDTree(ptsA)\n",
    "    treeB = cKDTree(ptsB)\n",
    "    dA, _ = treeA.query(ptsB)\n",
    "    dB, _ = treeB.query(ptsA)\n",
    "    chamfer = float(np.mean(dA**2) + np.mean(dB**2))\n",
    "    hausdorff = float(max(np.max(dA), np.max(dB)))\n",
    "    return chamfer, hausdorff\n",
    "\n",
    "\n",
    "\n",
    "def per_lane_metrics(solution_filepath, gt_filepath, lane_id, frame_id, seq_id):\n",
    "    '''\n",
    "    Load matching solution and ground truth files (corresponding to a sequence, frame, and lane). Calculate and return\n",
    "    various per-lane metrics.\n",
    "\n",
    "    Args:\n",
    "       solution_filepath (str): path to solution file.\n",
    "       gt_filepath (str): path to ground truth file.\n",
    "       lane_id (int): lane id.\n",
    "       frame_id (int/str): frame id.\n",
    "       seq_id (int/str): sequence/run id.\n",
    "\n",
    "    Returns:\n",
    "        {\n",
    "            'lane_id' (int): lane id,\n",
    "            'file_id' (int/str): file id (aka frame id),\n",
    "            'n_points' (int): number of valid points in lane,\n",
    "            'model_type' (str): 'linear'or 'quadratic',\n",
    "            'metrics_point' (dict of floats): {MAE, MSE, RMSE, chamfer, hausdorff},\n",
    "            'metrics_curve' (dict of floats): {MAE, MSE, RMSE},\n",
    "            'per_point' (dict of arrays of floats): { 'point_distances': [...], 'curve_distances': [...], 'gt_to_curve_distances': [...] }\n",
    "        }\n",
    "    '''\n",
    "    sol_pts = load_pointcloud_from_bin(solution_filepath)   \n",
    "    gt_pts  = load_pointcloud_from_pcd(gt_filepath)        \n",
    "\n",
    "    file_id = Path(solution_filepath).stem\n",
    "\n",
    "    out = {\n",
    "        'file_id': file_id,\n",
    "        'lane_id': None,\n",
    "        'n_points': 0,\n",
    "        'model_type': None,\n",
    "        'metrics_point': {},\n",
    "        'metrics_curve': {},\n",
    "        'per_point': {}\n",
    "    }\n",
    "\n",
    "    if sol_pts is None or gt_pts is None:\n",
    "        out['error'] = \"missing_data\"\n",
    "        return out\n",
    "\n",
    "    sol_pts = np.asarray(sol_pts, dtype=float)\n",
    "    gt_pts  = np.asarray(gt_pts, dtype=float)\n",
    "\n",
    "    if sol_pts.shape != gt_pts.shape or sol_pts.ndim != 2 or sol_pts.shape[1] != 3:\n",
    "        out['error'] = f\"shape_mismatch {sol_pts.shape} vs {gt_pts.shape}\"\n",
    "        return out\n",
    "\n",
    "    # Fit parametric line/curve on GT lane\n",
    "    try:\n",
    "        model_type, model_params = fit_line_on_plane(gt_pts, once_config[\"projection_mapping\"][\"snap_curvature_threshold\"])\n",
    "    except Exception as e:\n",
    "        model_type, model_params = \"unknown\", None\n",
    "\n",
    "    sol_pts, gt_pts = c_i(sol_pts, gt_pts, lane_id, frame_id, seq_id)\n",
    "    \n",
    "    N = sol_pts.shape[0]\n",
    "\n",
    "    out['n_points'] = int(N)\n",
    "    out['model_type'] = model_type\n",
    "\n",
    "    # per-point distances\n",
    "    point_dists = np.linalg.norm(sol_pts - gt_pts, axis=1)  # Euclidean distance\n",
    "    curve_dists = np.empty(N, dtype=float)\n",
    "    gt_curve_dists = np.empty(N, dtype=float)\n",
    "    for i in range(N):\n",
    "        res = per_point_errors_and_curve_dist(sol_pts[i], gt_pts[i], model_type, model_params)\n",
    "        curve_dists[i] = res['curve_dist']\n",
    "        gt_curve_dists[i] = res['gt_to_curve_dist']\n",
    "\n",
    "    # Basic point metrics\n",
    "    mse_points = float(np.mean(np.sum((sol_pts - gt_pts)**2, axis=1)))\n",
    "    mae_points = float(np.mean(point_dists))\n",
    "    rmse_points = float(np.sqrt(np.mean(np.sum((sol_pts - gt_pts)**2, axis=1))))\n",
    "\n",
    "    chamfer_pts, hausdorff_pts = compute_chamfer_and_hausdorff(sol_pts, gt_pts)\n",
    "\n",
    "    out['metrics_point'] = {\n",
    "        'MAE_point': mae_points,\n",
    "        'MSE_point': mse_points,\n",
    "        'RMSE_point': rmse_points,\n",
    "        'Chamfer': chamfer_pts,\n",
    "        'Hausdorff': hausdorff_pts\n",
    "    }\n",
    "\n",
    "    # Curve / structure metrics (per-point to curve)\n",
    "    # Some curve_dists can be nan if projection failed; ignore those in stats but keep raw values\n",
    "    valid_curve_mask = ~np.isnan(curve_dists)\n",
    "    if np.any(valid_curve_mask):\n",
    "        mae_curve = float(np.nanmean(curve_dists))\n",
    "        mse_curve = float(np.nanmean(curve_dists**2))\n",
    "        rmse_curve = float(np.sqrt(np.nanmean(curve_dists**2)))\n",
    "    else:\n",
    "        mae_curve = mse_curve = rmse_curve = float(np.nan)\n",
    "\n",
    "    out['metrics_curve'] = {\n",
    "        'MAE_curve': mae_curve,\n",
    "        'MSE_curve': mse_curve,\n",
    "        'RMSE_curve': rmse_curve\n",
    "    }\n",
    "\n",
    "    # Save per-point raw arrays (convert to lists for JSON compatibility)\n",
    "    out['per_point'] = {\n",
    "        'point_distances': point_dists.tolist(),\n",
    "        'curve_distances': [None if np.isnan(x) else float(x) for x in curve_dists.tolist()],\n",
    "        'gt_to_curve_distances': [None if np.isnan(x) else float(x) for x in gt_curve_dists.tolist()]\n",
    "    }\n",
    "\n",
    "    # parse lane id if available in filename: expecting \"<frame_id>_<lane_id>\"\n",
    "    try:\n",
    "        stem = Path(solution_filepath).stem\n",
    "        lane_id = int(stem.rsplit('_', 1)[1])\n",
    "        out['lane_id'] = lane_id\n",
    "    except Exception:\n",
    "        out['lane_id'] = None\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def per_frame_aggregate(frame_id, solution_files_for_frame, gt_files_for_frame, seq_id):\n",
    "    '''\n",
    "    Iterate through a frame, load lane data as per_lane_metrics(), combine and return frame aggregates.\n",
    "\n",
    "    Args:\n",
    "       frame_id (int/str): frame id.\n",
    "       solution_files_for_frame (dict): { lane_id (int) : solution_filepath }\n",
    "       gt_files_for_frame (dict): { lane_id (int) : gt_filepath }\n",
    "       seq_id (int/str): sequence/run id.\n",
    "\n",
    "    Returns:\n",
    "        {\n",
    "            'frame_id' (str): frame id,\n",
    "            'n_points' (int): number of valid points in frame,\n",
    "            'n_lanes' (int): number of valid lanes in frame,\n",
    "            'n_linear' (int): number of lanes with a linear model in frame,\n",
    "            'n_quadratic' (int): number of lanes with a quadratic model in frame,\n",
    "            'lanes' (dict): { lane_id : lane_dict }, where lane_dict is the result of per_lane_metrics(),\n",
    "            'frame_metrics' (dict of floats): { '<metric>_mean', '<metric>_median' }, median and mean values for:\n",
    "                MAE_point, MSE_point, RMSE_point, Chamfer, Hausdorff, MAE_curve, MSE_curve, RMSE_curve\n",
    "        }\n",
    "    '''\n",
    "\n",
    "    lane_results = {}\n",
    "    n_points = 0\n",
    "    n_linear = 0\n",
    "    n_quadratic = 0\n",
    "    all_metrics = {\n",
    "        \"MAE_point\": [],\n",
    "        \"MSE_point\": [],\n",
    "        \"RMSE_point\": [],\n",
    "        \"Chamfer\": [],\n",
    "        \"Hausdorff\": [],\n",
    "        \"MAE_curve\": [],\n",
    "        \"MSE_curve\": [],\n",
    "        \"RMSE_curve\": []\n",
    "    }\n",
    "\n",
    "    # iterate over the intersection of lane ids present in both\n",
    "    lane_ids = sorted(set(solution_files_for_frame.keys()) & set(gt_files_for_frame.keys()))\n",
    "    n_lanes = 0\n",
    "    for lane_id in lane_ids:\n",
    "        if c_i(lane_id, frame_id, seq_id):\n",
    "            continue\n",
    "        sol_fp = solution_files_for_frame[lane_id]\n",
    "        gt_fp = gt_files_for_frame[lane_id]\n",
    "        lane_res = per_lane_metrics(sol_fp, gt_fp, lane_id, frame_id, seq_id)\n",
    "        \n",
    "        lane_results[str(lane_id)] = lane_res\n",
    "        n_points += lane_res.get('n_points', 0)\n",
    "\n",
    "        mt = lane_res.get('model_type')\n",
    "        if mt == \"linear\":\n",
    "            n_linear += 1\n",
    "        elif mt == \"quadratic\":\n",
    "            n_quadratic += 1\n",
    "\n",
    "        # get all metrics\n",
    "        for key in [\"MAE_point\",\"MSE_point\",\"RMSE_point\",\"Chamfer\",\"Hausdorff\"]:\n",
    "            val = lane_res.get(\"metrics_point\", {}).get(key)\n",
    "            if val is not None and not np.isnan(val):\n",
    "                all_metrics[key].append(float(val))\n",
    "\n",
    "        for key in [\"MAE_curve\",\"MSE_curve\",\"RMSE_curve\"]:\n",
    "            val = lane_res.get(\"metrics_curve\", {}).get(key)\n",
    "            if val is not None and not np.isnan(val):\n",
    "                all_metrics[key].append(float(val))\n",
    "        n_lanes += 1\n",
    "\n",
    "    # compute summary statistics for all metrics\n",
    "    summary_stats = {}\n",
    "    for metric_name, values in all_metrics.items():\n",
    "        values = np.asarray(values, dtype=float)\n",
    "\n",
    "        if values.size > 0:\n",
    "            summary_stats[f\"{metric_name}_mean\"] = float(np.mean(values))\n",
    "            summary_stats[f\"{metric_name}_median\"] = float(np.median(values))\n",
    "        else:\n",
    "            summary_stats[f\"{metric_name}_mean\"] = float(np.nan)\n",
    "            summary_stats[f\"{metric_name}_median\"] = float(np.nan)\n",
    "\n",
    "    frame_summary = {\n",
    "        \"frame_id\": frame_id,\n",
    "        \"n_points\": n_points,\n",
    "        \"n_lanes\": n_lanes,\n",
    "        \"n_linear\": n_linear,\n",
    "        \"n_quadratic\": n_quadratic,\n",
    "        \"lanes\": lane_results,\n",
    "        \"frame_metrics\": summary_stats\n",
    "    }\n",
    "\n",
    "    return frame_summary\n",
    "\n",
    "\n",
    "\n",
    "def map_files_by_frame(files):\n",
    "    '''\n",
    "    Map files by stem (thus frame id and lane id).\n",
    "\n",
    "    Args:\n",
    "       files (arr[str]): input files\n",
    "\n",
    "    Returns:\n",
    "        mapping (dict): {'frame_id': { 'lane_id': filepath (str) } }\n",
    "    '''\n",
    "    mapping = defaultdict(dict)  # frame_id -> { lane_id: filepath }\n",
    "    for fp in files:\n",
    "        stem = fp.stem  # expected \"<frame_id>_<lane_id>\"\n",
    "        if \"_\" not in stem:\n",
    "            mapping[stem][None] = str(fp)\n",
    "            continue\n",
    "        frame_id, lane_id_str = stem.rsplit('_', 1)\n",
    "        try:\n",
    "            lane_id = int(lane_id_str)\n",
    "        except ValueError:\n",
    "            lane_id = lane_id_str\n",
    "        mapping[frame_id][lane_id] = str(fp)\n",
    "    return mapping\n",
    "\n",
    "\n",
    "\n",
    "def summarize_numeric_list(arr):\n",
    "    '''\n",
    "    Ccalculates a variety of metrics from an input array.\n",
    "\n",
    "    Args:\n",
    "        arr (arr[int/float]): array of data.\n",
    "\n",
    "    Returns\n",
    "        {\n",
    "            'n' (int): number of items,\n",
    "            'mean' (float): mean value of the data,\n",
    "            'median' (float): median value of the data,\n",
    "            'std' (float): standard deviation of the data,\n",
    "            'min' (float): min value of the data,\n",
    "            'max' (float): max value of the data,\n",
    "            'skew' (float): skew of the data,\n",
    "            'kurtosis' (float): kurtosis of the data,\n",
    "            'p<#>' (float): #th percentile of the data (by global config percentiles)\n",
    "            'mean_bootstrap_95ci' [(float), (float)]: mean 95 confidence interval bootstrap of the data (if global config file)\n",
    "        }\n",
    "\n",
    "    Note: calculating 95ci greatly increases runtime.\n",
    "    '''\n",
    "    arr = np.asarray(arr, dtype=float)\n",
    "    arr = arr[~np.isnan(arr)]\n",
    "    summary = {}\n",
    "    if arr.size == 0:\n",
    "        return {'n': 0}\n",
    "    summary['n'] = int(arr.size)\n",
    "    summary['mean'] = float(np.mean(arr))\n",
    "    summary['median'] = float(np.median(arr))\n",
    "    summary['std'] = float(np.std(arr, ddof=0))\n",
    "    summary['min'] = float(np.min(arr))\n",
    "    summary['max'] = float(np.max(arr))\n",
    "    summary['skew'] = float(stats.skew(arr))\n",
    "    summary['kurtosis'] = float(stats.kurtosis(arr, fisher=True))\n",
    "    for p in once_config[\"result_analytics\"][\"percentiles\"]:\n",
    "        summary[f'p{p}'] = float(np.percentile(arr, p))\n",
    "    if once_config[\"result_analytics\"][\"bootstrap_ci\"]:\n",
    "        boots = []\n",
    "        rng = np.random.default_rng(0)\n",
    "        for _ in range(once_config[\"result_analytics\"][\"bootstrap_n\"]):\n",
    "            sample = rng.choice(arr, size=arr.size, replace=True)\n",
    "            boots.append(np.mean(sample))\n",
    "        summary['mean_bootstrap_95ci'] = [float(np.percentile(boots, 2.5)), float(np.percentile(boots, 97.5))]\n",
    "    return summary\n",
    "\n",
    "\n",
    "\n",
    "def process_run_and_save(solution_folder, gt_folder, output_json_path, solution_name, seq_id, overwrite=False, verbose=True):\n",
    "    '''\n",
    "    Process an individual run / sequence. Group items by frame and compute per-lane metrics as per_lane_metrics(), per-frame metrics as\n",
    "    per_frame_metrics(), and per-run metrics. Saves all run aggregates to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        solution folder (str): File path to the generated solution output.\n",
    "        gt_folder (str): Flie path to the 3D ground truth folder.\n",
    "        output_json_path (str): File path to save the JSON results data.\n",
    "        solution_name (str): Method name for debug.\n",
    "        seq_id (int/str): run / sequence id.\n",
    "        overwrite (bool): If true, overwrites existing analytics data.\n",
    "        verbose (bool): If true, prints descriptive loading metrics.\n",
    "\n",
    "    Output:\n",
    "        Generates a JSON file of the analytics data, as described by the return.\n",
    "\n",
    "    Returns\n",
    "        {\n",
    "        'run_info' (dict): {\n",
    "            'solution_folder' (str): filepath of solution folder\n",
    "            'gt_folder' (str): filepath of ground truth folder\n",
    "            'n_frames' (int): number of frames in run/sequence,\n",
    "            'n_lanes': (int): number of lanes in run/sequence,\n",
    "            'n_points' (int): number of points in run/sequence\n",
    "        },\n",
    "        'frames' (dict): { frame_id : frame_dict }, where frame_dict is the result of per_frame_aggregate(),\n",
    "        'frame_aggregates' (dict): aggregates of all frames dictionaries,\n",
    "        'lane_aggregates' (dict): aggregates of all lane dictionaries,\n",
    "        'point_aggregates' (dict): aggregates of all point dictionaries.\n",
    "        \n",
    "        }\n",
    "    '''\n",
    "    solution_folder = Path(solution_folder)\n",
    "    gt_folder = Path(gt_folder)\n",
    "    out_path = Path(output_json_path)\n",
    "\n",
    "    if out_path.exists() and not overwrite:\n",
    "        if verbose:\n",
    "            main_logger.info(f\"Found existing output at {out_path}, loading and returning it.\")\n",
    "        with open(out_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    # Determine frames to process\n",
    "    sol_files = sorted(solution_folder.glob(\"*.bin\"))\n",
    "    gt_files = sorted(gt_folder.glob(\"*.pcd\"))\n",
    "\n",
    "    sol_map = map_files_by_frame(sol_files)\n",
    "    gt_map = map_files_by_frame(gt_files)\n",
    "\n",
    "    frame_ids = sorted(set(sol_map.keys()) & set(gt_map.keys()))\n",
    "    if verbose:\n",
    "        iterator = tqdm(frame_ids, desc=f\"Processing output{' for ' + solution_name if solution_name else ''}{' seq ' + str(seq_id) if seq_id else ''}\")\n",
    "    else:\n",
    "        iterator = frame_ids\n",
    "\n",
    "    # Dynamically define keys (from other function return keys)\n",
    "    run_results = {\n",
    "        'run_info': {\n",
    "            'solution_folder': str(solution_folder),\n",
    "            'gt_folder': str(gt_folder),\n",
    "            'n_frames': len(frame_ids),\n",
    "            'n_lanes': 0,\n",
    "            'n_points': 0\n",
    "        },\n",
    "        'frames': {},\n",
    "        'frame_aggregates': {},\n",
    "        'lane_aggregates': {},\n",
    "        'point_aggregates': {}\n",
    "    }\n",
    "\n",
    "    lane_metric_keys = [\"MAE_point\", \"MSE_point\", \"RMSE_point\", \"Chamfer\", \"Hausdorff\",\n",
    "                        \"MAE_curve\", \"MSE_curve\", \"RMSE_curve\"]\n",
    "    lane_metric_lists = {k: [] for k in lane_metric_keys}\n",
    "    per_lane_point_counts = []\n",
    "    lane_type_counts = defaultdict(int)\n",
    "\n",
    "    point_metric_keys = [\"point_distances\", \"curve_distances\"]\n",
    "    point_metric_lists = {k: [] for k in point_metric_keys}\n",
    "\n",
    "    frame_metric_keys = []  # dynamic dictionary for per-frame metrics, will auto-populate from first frame\n",
    "    frame_metric_lists = defaultdict(list)\n",
    "\n",
    "    for frame_id in iterator:\n",
    "        sol_files_for_frame = sol_map.get(frame_id, {})\n",
    "        gt_files_for_frame = gt_map.get(frame_id, {})\n",
    "\n",
    "        frame_res = per_frame_aggregate(frame_id, sol_files_for_frame, gt_files_for_frame, seq_id)\n",
    "        run_results['run_info']['n_lanes'] += frame_res['n_lanes']\n",
    "        run_results['run_info']['n_points'] += frame_res['n_points']\n",
    "        run_results['frames'][frame_id] = frame_res\n",
    "\n",
    "        # Per-lane metrics\n",
    "        for _, lane_res in frame_res['lanes'].items():\n",
    "            if lane_res.get('error') is not None:\n",
    "                continue\n",
    "\n",
    "            mp = lane_res.get('metrics_point', {})\n",
    "            mc = lane_res.get('metrics_curve', {})\n",
    "            npts = lane_res.get('n_points', 0)\n",
    "\n",
    "            for k in [\"MAE_point\", \"MSE_point\", \"RMSE_point\", \"Chamfer\", \"Hausdorff\"]:\n",
    "                val = mp.get(k)\n",
    "                if val is not None and np.isfinite(val):\n",
    "                    lane_metric_lists[k].append(float(val))\n",
    "\n",
    "            for k in [\"MAE_curve\", \"MSE_curve\", \"RMSE_curve\"]:\n",
    "                val = mc.get(k)\n",
    "                if val is not None and np.isfinite(val):\n",
    "                    lane_metric_lists[k].append(float(val))\n",
    "\n",
    "            per_lane_point_counts.append(int(npts))\n",
    "            lane_type_counts[lane_res.get('model_type', 'unknown')] += 1\n",
    "\n",
    "            per_point_data = lane_res.get('per_point', {})\n",
    "            for k in point_metric_keys:\n",
    "                if k in per_point_data:\n",
    "                    point_metric_lists[k].extend([float(v) for v in per_point_data[k] if np.isfinite(v)])\n",
    "\n",
    "        # Per-frame metrics\n",
    "        if not frame_metric_keys and 'frame_metrics' in frame_res:\n",
    "            frame_metric_keys = list(frame_res['frame_metrics'].keys())\n",
    "\n",
    "        for k in frame_metric_keys:\n",
    "            val = frame_res['frame_metrics'].get(k)\n",
    "            if val is not None and np.isfinite(val):\n",
    "                frame_metric_lists[k].append(float(val))\n",
    "\n",
    "    # Dynamic aggregates\n",
    "    run_results['frame_aggregates'] = {k: summarize_numeric_list(v, k) for k, v in frame_metric_lists.items()}\n",
    "\n",
    "    run_results['lane_aggregates'] = {k: summarize_numeric_list(v, k) for k, v in lane_metric_lists.items()}\n",
    "    run_results['lane_aggregates']['per_lane_point_counts'] = summarize_numeric_list(per_lane_point_counts)\n",
    "    run_results['lane_aggregates']['lane_type_counts'] = dict(lane_type_counts)\n",
    "\n",
    "    run_results['point_aggregates'] = {k: summarize_numeric_list(v, k) for k, v in point_metric_lists.items()}\n",
    "\n",
    "    # Save JSON\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(out_path, 'w') as f:\n",
    "        json.dump(run_results, f, indent=2)\n",
    "\n",
    "    return run_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa57e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seqs():\n",
    "    '''\n",
    "    Get all of the run / sequence ids.\n",
    "\n",
    "    Returns:\n",
    "        (arr): An array of all of the ids.\n",
    "    '''\n",
    "    base_path = once_config[\"output\"][\"base_path\"]\n",
    "    seq_id = once_config[\"runtime\"][\"seq_id\"]\n",
    "    seq_ids = []\n",
    "    if seq_id is None:\n",
    "        # Get all sequences\n",
    "        for name in os.listdir(base_path):\n",
    "            full_path = os.path.join(base_path, name)\n",
    "            if os.path.isdir(full_path):\n",
    "                seq_ids.append(name)\n",
    "        \n",
    "        main_logger.info(f\"Running all run ids: {len(seq_ids)} found.\\n\\n\\n\\n\")\n",
    "    else:\n",
    "        full_path = os.path.join(base_path, seq_id)\n",
    "        if os.path.exists(full_path) and os.path.isdir(full_path):\n",
    "            seq_ids.append(seq_id)\n",
    "            main_logger.info(f\"Running prespecified run id: {seq_id}\")\n",
    "        else:\n",
    "            main_logger.error(f\"Prespecified run id {seq_id} is not found, or not a run folder.\")\n",
    "            sys.exit(1)\n",
    "    return seq_ids\n",
    "\n",
    "\n",
    "\n",
    "def main_analysis_per_seq(seq_id):\n",
    "    '''\n",
    "    Run all analysis for a given sequence for all solutions, calculating and saving per-sequence per-solution metrics.\n",
    "\n",
    "    Args:\n",
    "        seq_id (int/str): sequence/run id.\n",
    "\n",
    "    Output:\n",
    "        Writes per-solution JSON files as process_runs_and_save.\n",
    "    '''\n",
    "\n",
    "    base_path = once_config[\"output\"][\"base_path\"]\n",
    "\n",
    "    ground_truth_base_folder = once_config[\"data\"][\"base_path\"]\n",
    "    ground_truth_folder = once_config[\"data\"][\"lane_position_ground_truth_folder_path\"]\n",
    "    grounds_truth_folderpath = Path(os.path.join(ground_truth_base_folder, seq_id, ground_truth_folder))\n",
    "\n",
    "    evaluation_folderpath = Path(os.path.join(base_path, seq_id, \"evaluation\"))\n",
    "    evaluation_extension = once_config[\"result_analytics\"][\"evaluation_extension\"]\n",
    "\n",
    "    if once_config[\"output\"][\"calc_cl_intrinsic\"]:\n",
    "        cl_intr_solution_folderpath = Path(os.path.join(base_path, seq_id, once_config[\"output\"][\"cl_intrinsic_path\"]))\n",
    "        cl_intr_eval_path = Path(os.path.join(evaluation_folderpath, once_config[\"output\"][\"cl_intrinsic_path\"] + evaluation_extension))\n",
    "        results = process_run_and_save(\n",
    "            cl_intr_solution_folderpath, \n",
    "            grounds_truth_folderpath, \n",
    "            cl_intr_eval_path, \n",
    "            solution_name=\"Cl Intrinsic\",\n",
    "            seq_id=seq_id,\n",
    "            overwrite=once_config[\"result_analytics\"][\"override_existing_output\"]\n",
    "        )\n",
    "\n",
    "    if once_config[\"output\"][\"calc_cl_intrinsic_ground\"]:\n",
    "        cl_intr_base_solution_folderpath = Path(os.path.join(base_path, seq_id, once_config[\"output\"][\"cl_intrinsic_ground_path\"]))\n",
    "        cl_intr_base_eval_path = Path(os.path.join(evaluation_folderpath, once_config[\"output\"][\"cl_intrinsic_ground_path\"] + evaluation_extension))\n",
    "        results = process_run_and_save(\n",
    "            cl_intr_base_solution_folderpath, \n",
    "            grounds_truth_folderpath, \n",
    "            cl_intr_base_eval_path, \n",
    "            solution_name=\"Cl Intrinsic Ground\",\n",
    "            seq_id=seq_id,\n",
    "            overwrite=once_config[\"result_analytics\"][\"override_existing_output\"]\n",
    "        )\n",
    "\n",
    "    if once_config[\"output\"][\"calc_cl_depth\"]:\n",
    "        cl_depth_solution_folderpath = Path(os.path.join(base_path, seq_id, once_config[\"output\"][\"cl_depth_path\"]))\n",
    "        cl_depth_eval_path = Path(os.path.join(evaluation_folderpath, once_config[\"output\"][\"cl_depth_path\"] + evaluation_extension))\n",
    "        results = process_run_and_save(\n",
    "            cl_depth_solution_folderpath, \n",
    "            grounds_truth_folderpath, \n",
    "            cl_depth_eval_path, \n",
    "            solution_name=\"Cl Depth\",\n",
    "            seq_id=seq_id,\n",
    "            overwrite=once_config[\"result_analytics\"][\"override_existing_output\"]\n",
    "        )\n",
    "\n",
    "    if once_config[\"output\"][\"calc_cl_intrinsic_depth\"]:\n",
    "        cl_intr_depth_solution_folderpath = Path(os.path.join(base_path, seq_id, once_config[\"output\"][\"cl_intrinsic_depth_path\"]))\n",
    "        cl_intr_depth_eval_path = Path(os.path.join(evaluation_folderpath, once_config[\"output\"][\"cl_intrinsic_depth_path\"] + evaluation_extension))\n",
    "        results = process_run_and_save(\n",
    "            cl_intr_depth_solution_folderpath, \n",
    "            grounds_truth_folderpath, \n",
    "            cl_intr_depth_eval_path, \n",
    "            solution_name=\"Cl Intrinsic + Depth\",\n",
    "            seq_id=seq_id,\n",
    "            overwrite=once_config[\"result_analytics\"][\"override_existing_output\"]\n",
    "        )\n",
    "\n",
    "    if once_config[\"output\"][\"calc_thesis_solution\"]:\n",
    "        thesis_solution_folderpath = Path(os.path.join(base_path, seq_id, once_config[\"output\"][\"thesis_solution_path\"]))\n",
    "        thesis_eval_path = Path(os.path.join(evaluation_folderpath, once_config[\"output\"][\"thesis_solution_path\"] + evaluation_extension))\n",
    "        results = process_run_and_save(\n",
    "            thesis_solution_folderpath, \n",
    "            grounds_truth_folderpath, \n",
    "            thesis_eval_path, \n",
    "            solution_name=\"Thesis Solution\",\n",
    "            seq_id=seq_id,\n",
    "            overwrite=once_config[\"result_analytics\"][\"override_existing_output\"]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0944623",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_ids = get_seqs()\n",
    "\n",
    "# Run all sequences\n",
    "for seq_id in seq_ids:\n",
    "    main_logger.info(f\"Running seq_id: {seq_id}\")\n",
    "    start_timer(main_logger)\n",
    "    main_analysis_per_seq(seq_id)\n",
    "    stop_timer(main_logger, f\"Seq {seq_id}\", calc_lane_time=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883a0cda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
